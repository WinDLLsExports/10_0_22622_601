!This program cannot be run in DOS mode.
3o$z]<$z]<$z]<v
Y=,z]<v
^=(z]<v
X=;z]<v
\="z]<B
<&z]<-
<mz]<$z\<v{]<
]=%z]<
<%z]<
_=%z]<Rich$z]<
.text
`.rdata
@.data
.pdata
@_RDATA
@.rsrc
@.reloc
UWAVH
t$`E3
Ct$`H
T$@H+T$8H
L$8H+
UAVAWH
Ct$ H
A_A^]
UAVAWH
Ct$`H
Ct$@H
Ct$ H
A_A^]
UATAUAVAWH
ukL9-
A_A^A]A\]
VAVAWH
)D$ f
0A_A^^
D$PE3
(D$ f
t$ WATAUAVAWH
tkfff
A_A^A]A\_
@SWAUAVH
8A^A]_[
SUVAUH
L$ H+
HA]^][
L$(H3
L$0H3
UVWAVAWH
A_A^_^]
@SVWH
VWAVH
0A^_^
T$ Ic
L$(H3
@SVWH
L$`H3
L$pH3
@SUVWAWH
 A__^][
 A__^][
t$ WH
\$ VH
\$ E3
VWATAVAWH
AXHc8H
 A_A^A\_^
|$ AV
L9Qhs
I9Jhs
L$ SUVWH
8_^][
L$ SVWH
@SVWATAUAVAWH
PA_A^A]A\_^[
@SWAWH
0A__[
UVATAVAWH
D+3L9c0u
Hcl$ H
HcD$ H
L$0H3
@A_A^A\^]
UVWAVAWH
L9{0u
Hc|$ L
HcD$ H
D8{8u;H
L$0H3
@A_A^_^]
|$ AVH
VAVAWH
|$@Hc
|$@Hc
 A_A^^
t$ WH
t$0H;
|$ AVH
\$ WH
@SUVWH
8_^][
8_^][
8_^][
@SVWH
@SUVWAVH
`A^_^][
@SVWH
L$HH3
l$ VWAVH
D$(eH
L$(H3
0A^_^
@SVWAVAWH
L$XH3
`A_A^_^[
WAVAWH
 A_A^_
UVWAVAWH
A_A^_^]
\$ WH
\$ WH
|$ ATAVAWH
 A_A^A\
|$ ATAVAWH
 A_A^A\
@SVAVH
D$ Hc
L$ Hc
T$ H+
L$@H3
PA^^[
@SVAVH
D$ Hc
L$ Hc
T$ H+
L$@H3
PA^^[
L$0H3
L$0H3
\$ WH
@SUVWAVH
 A^_^][
 A^_^][
@SUATAUAWH
t*HcC
t^HcC
L$(H3
PA_A]A\][
teHcL$ )KTH
L$0H3
@SUVH
@SUAVH
t*HcA
taHcC
L$(H3
@A^][
\$ WH
@SUVWAVH
 A^_^][
 A^_^][
L$(H3
t$ WATAUAVAWH
 A_A^A]A\_
@SUVAWH
(A_^][
(A_^][
u HcI(
t$ WH
\$p9Y0u
H9Y uRA
;w,~PA
t$ WH
G(9G,tPA
;w,~PA
HcQ0H
HcA,H
|$$9y0tAA
~,HcK,H+
HcC,H
C(+C,H
t$ WH
@SVWH
D$0Ic
;Y(|0
tAHcD$ H
HcL$ L
L$0H3
HcC,H
|$x@8y
|$x@8y
h VWATAVAWH
A_A^A\_^
VWATAVAWH
0A_A^A\_^
t'HcS
L$0H3
t$ WAVAWH
 A_A^_
@SWAVH
D$0Hc
|$@E3
L$0H3
`A^_[
\$ WH
D$(HcA
D$$A;
l$`A;
L$(H3
\$0Hc
\$0Hc
L$0H3
L$0H3
t$ WH
t$ WH
WATAUAVAWH
0A_A^A]A\_
@SWAUAVH
8A^A]_[
UVWATAUAVAWH
 A_A^A]A\_^]
@SUVWATAVAWH
 A_A^A\_^][
t$ WATAUAVAWH
 A_A^A]A\_
v?fD;
|$ AV
H9Qhs
I9Khs
t$ WH
L$(H3
L$0H3
L$0H3
r!fff
|$ AVH
VWAVH
@A^_^
x AVH
\$ UH
M H1E
 H3E H3E
ntelA
GenuD
D$0E3
L$XH3
L$XH3
L$XH3
L$XH3
@SVWAVH
\$ E3
L$XH3
hA^_^[
VWAVH
L$XH3
`A^_^
@SVWATAUAVAWH
fffffff
fffffff
A_A^A]A\_^[
L$8H3
P(H;P0t
\$ VWATAVAWH
t$ E3
L$pH3
A_A^A\_^
\$ WH
L$XH3
t$ WH
L$HH3
\$ WH
L$XH3
\$ WH
L$XH3
\$ WH
L$XH3
\$ WH
L$XH3
\$ WH
L$XH3
@SVWATAUAVAWH
L$pH#
d$HI;
D$`H+
A_A^A]A\_^[
@SVWAVAWH
L$HH3
PA_A^_^[
@SVWATAUAVAWH
L$XH3
`A_A^A]A\_^[
WAVAWH
0A_A^_
|$ AVH
T$8H;
L$@H3
L$0H+
VWATAVAWH
\$0H+
L$@H3
PA_A^A\_^
L$ H+
SVWATAUAVAWH
A_A^A]A\_^[
SVWATAUAVAWH
A_A^A]A\_^[
@SVWATAUAVAWH
L$@H3
PA_A^A]A\_^[
@SVWH
L$HH;
L$HH;
L$HH3
@SVWH
L$XH3
@SVWH
L$XH3
@SVWH
L$XH3
@SVWATAUAVAWH
D$ H;
T$ H;
T$ H;
L$ L;
L$ L;
A_A^A]A\_^[
@SVWATAUAVAWH
gfffffffH
L$ L;
L$ L;
A_A^A]A\_^[
t$ WATAUAVAWH
A_A^A]A\_
VWATAVAWH
D$HH+
L$PH3
`A_A^A\_^
WATAUAVAWH
D$`HcH
D$`HcH
D$hE3
CT$(A
D$`HcH
D$`HcH
A_A^A]A\_
@SVWAVAWH
\$ E3
L$XH3
`A_A^_^[
@SVWAVAWH
L$XH3
`A_A^_^[
@SVWAVAWH
L$PH;
L$XI+
D$XH+
L$pH3
A_A^_^[
SVATAUAVAWH
A_A^A]A\^[
SWATAUAVAWH
A_A^A]A\_[
SVWATAUAVAWH
A_A^A]A\_^[
@SVWATAUAVAWH
L$XH;
L$`I+
D$xH+
D$`H+
D$xH+
A_A^A]A\_^[
)D$0L
)L$PL
@SVWAVH
A^_^[
VWATAVAWH
0A_A^A\_^
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
UWAVH
D$PHcH
D$PHcP
D$PHcH
L$PHcQ
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
\$ UVWATAUAVAWH
)D$0L
A_A^A]A\_^]
\$ UVWATAUAVAWH
)D$0L
A_A^A]A\_^]
\$ UVWATAUAVAWH
)D$0L
A_A^A]A\_^]
\$ UVWATAUAVAWH
)D$0L
A_A^A]A\_^]
\$ UVWATAUAVAWH
UUUUUUU
D$0H9P }
H;Q }kM9O
)D$0L
UUUUUUU
A_A^A]A\_^]
\$ UVWATAUAVAWH
UUUUUUU
D$0H9P }
H;Q }kM9N
)D$0L
UUUUUUU
A_A^A]A\_^]
\$ UVWATAUAVAWH
\$X8P
D$0H9X }
H;Y |
)D$0L
A_A^A]A\_^]
\$ UVWATAUAVAWH
UUUUUUU
D$0H9P }
H;Q }kM9N
)D$0L
UUUUUUU
A_A^A]A\_^]
@SVWH
|$ E3
@SVWH
|$ E3
SUVWATAVAWH
A_A^A\_^][
SUVWATAVAWH
A_A^A\_^][
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
D$@L;
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
D$@L;
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
D$@H;
D$@H;
A_A^A]A\_^]
UVWATAUAVAWH
D$@L;
A_A^A]A\_^]
UVWATAUAVAWH
D$@H;
D$@H;
A_A^A]A\_^]
\$ WH
L$0H3
\$ WH
L$0H3
t$ WATAUAVAWH
A_A^A]A\_
VWATAVAWH
@A_A^A\_^
t$ WATAUAVAWH
A_A^A]A\_
SVWATAUAVAWH
0A_A^A]A\_^[
SVWATAUAVAWH
0A_A^A]A\_^[
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
@SVWATAUAVAWH
tofff
|$0I;
PA_A^A]A\_^[
t$ WH
@UVWH
t$ E3
@SUVH
@SVWH
@SUVH
VWAVH
 A^_^
 A^_^
t$ WATAUAVAWH
d$ Hk
t$ I;
t$(Hk
A_A^A]A\_
t$ WATAUAVAWH
)t$`I
m fff
(D$ f
(t$`I
A_A^A]A\_
t$ WATAUAVAWH
)t$pI
3333333
(D$ f
3333333
(t$pI
A_A^A]A\_
\$ UVWH
@SUVWAVAWH
HA_A^_^][
@SUVWAVAWH
XA_A^_^][
t$ WH
S H+S
t$0ff
UVWAVAWH
PA_A^_^]
@USVWATAUAVAWH
L$HE3
D$PHcH
D$PHcH
FPI9FHtIH
D$PHcH
L$PHcQ
A_A^A]A\_^[]
VWAVH
 A^_^
VWAVH
L$8H3
@A^_^
l$ VWATAVAWH
UUUUUUU
A_A^A\_^
VWAVH
 A^_^
VWAVH
 A^_^
t$@H+
t$@H+
t$8H+
t$ WH
@USVWATAUAVAWH
A_A^A]A\_^[]
@SUVWAVH
A^_^][
@SUVWH
T$PH+
L$XH3
h_^][
@USVWAVAWH
L$hH;
L$XE3
H9|$X
T$pH+
A_A^_^[]
@SUVWAVAWH
A_A^_^][
L$@H3
@SVWH
L$0H3
L$@H3
L$HH3
\$ UVWATAUAVAWH
pA_A^A]A\_^]
\$ UH
@SUVWAVH
L$ 9L$$u H
T$8H+
L$@H3
PA^_^][
\$ UVWATAUAVAWH
L9a0u(H
A_A^A]A\_^]
T$8H+
L$@H3
@SUVWH
L$(H3
8_^][
@USVWAVH
A^_^[]
@SUVWH
T$0H+
L$8H3
H_^][
@SUVWH
t$ UWATAUAVH
T$hE3
D$pHcH
D$pHcH
L$pHcQ
L$pHcQ
A^A]A\_]
t$ WH
t$ WH
l$ VWAWH
t$HH+
 A__^
l$ VAVAWH
|$HH+
 A_A^^
l$ WAVAWH
t$HH+
 A_A^_
\$0ff
@SAUH
|$0fff
I#E0H
VWAVH
@A^_^
VWAVH
@A^_^
VWAVH
@A^_^
t$ WATAUAVAWH
|$HI;
A_A^A]A\_
t$ WATAUAVAWH
|$HI;
A_A^A]A\_
gfffffffH
t$8H+
t$8H+
L$0I;
L$0I;
L;AhL
BAhL+
@SVWATAUAVAWH
UUUUUUU
PA_A^A]A\_^[
l$ VWAVH
0A^_^
@SVWH
@SVWH
L$(H3
L$(H3
l$ VWAVH
\$(E3
0A^_^
@SVWH
@SVWH
t$ WATAUAVAWH
A_A^A]A\_
SVWATAUAVAWH
|$ Mi
0A_A^A]A\_^[
@SUVH
@UVWH
t$ E3
@UVWH
t$ E3
@UVWH
t$ E3
SWAVAWH
HA_A^_[
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
UUUUUUU
d$ E3
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
L$=H;
L$@H3
L$=H;
L$@H3
t$ WATAUAVAWH
)t$PI
(D$ f
(t$PI
A_A^A]A\_
t$ WATAUAVAWH
)t$pI
(D$ f
(t$pI
A_A^A]A\_
VWAVH
 A^_^
S H+S
l$ VWAVH
|$ AVH
L$8H3
L$0H3
|$ AVH
L$8H3
VWAVH
 A^_^
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WH
t$8H+
t$ WH
\$ UVWATAUAVAWH
C\$pH
D$ E3
C\$PH
D$ E3
C\$pH
D$ E3
C\$pH
D$ E3
V H;V(t
C\$PH
D$ E3
C\$PH
D$ E3
C\$PH
D$ E3
A_A^A]A\_^]
L$PH3
@SVWH
T$0H+
L$8H3
@USVWAVH
pA^_^[]
@USVWAVH
pA^_^[]
\$ WH
L$HH3
\$ WH
L$HH3
@USVWH
x_^[]
l$ WAVAWH
t$HH+
 A_A^_
H#E0L
@SAVH
I#F0M
L$0I;
L$0I;
@SVWH
L$HH3
L$(H3
L$(H3
L$(H3
L$(H3
L$8H3
L$(H3
L$(H3
L$(H3
L$(H3
D;B(|
L$ SH
L$(H3
t$ WATAUAVAWH
D$ H9X s
H;Y r
UUUUUUU
)D$ H
A_A^A]A\_
@SVWH
@SVWH
L$pH3
L$@H3
UVWAVAWH
A_A^_^]
@SVWH
L$0H3
L$@H3
L$ WH
t$ WH
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
t$ WATAUAVAWH
t$8E3
d$@H;
D$ L)`
A_A^A]A\_
@SVWATAUAVAWH
D$0E3
D$0E3
PA_A^A]A\_^[
@SVWATAUAVAWH
|$0Lk
t$ H;
<$HkL$@XI
`A_A^A]A\_^[
L$=H;
L$@H3
\$ UVWATAUAVAWH
d$PE3
(D$ f
pA_A^A]A\_^]
\$ UVWATAUAVAWH
d$PE3
(D$ f
`A_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
l$ VWAVH
D$(Hc
l$8@8h
D$0H9H s
H;K r
UUUUUUU
)D$ H
t$ WAVAWH
@A_A^_
t$ WH
t$ WH
@SUVWATAUAVAWH
xA_A^A]A\_^][
t$ WH
@SVWH
@SUVWAVAWH
HA_A^_^][
@SUVWH
H_^][
UVWATAUAVAWH
 A_A^A]A\_^]
UVWATAUAVAWH
 A_A^A]A\_^]
|$ AVH
t$8H+
t$ WH
UWAVH
|$ UAVAWH
|$ E3
A_A^]
t$ WH
t$ WH
L$@H3
t$ WH
L$@H3
t$ WH
L$@H3
AUAVH
I#E0H
tEfff
L$0H3
hA^A]
t$8H+
UAVAWH
I#F0H
H;|$0tHH;
L9|$(u
PA_A^]
L9|$(u
I#F0L
T$8L;
SVWATAUAVAWH
PA_A^A]A\_^[
WATAUAVAWH
0A_A^A]A\_
l$ WH
Q +Q0
O +O0
8OPti
H+G8H
G D+G0D
\$ UVWAVAWH
D$ H;
A_A^_^]
@USVWATAUAVAWH
D$HH;
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
@USVWATAUAVAWH
D$PHcH
D$PHcH
L$PHcQ
L$PHcQ
A_A^A]A\_^[]
H+C8H
C(+C0
t$ UWAVH
t$ UWAVH
t$ H9q
D$@HcH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
|$ ATAVAWH
 A_A^A\
t$ WATAUAVAWH
t$8E3
d$@H;
D$ H)x
A_A^A]A\_
t$ WATAUAVAWH
l$8E3
L$@H;
A_A^A]A\_
t$ WATAUAVAWH
l$8H;
A_A^A]A\_
@SUVWAVH
t$0H;
@A^_^][
SVWATAUAVAWH
gfffffffI
fffffff
@A_A^A]A\_^[
@SVWATAUAVAWH
d$8L;
PA_A^A]A\_^[
@SVWATAUAVAWH
D$(E3
D$(E3
D$(E3
T$0I;
PA_A^A]A\_^[
SVWATAUAVAWH
@A_A^A]A\_^[
@SUVH
@SVWH
@SUAVH
0A^][
@SUAVH
|$ E3
0A^][
@SUVH
@UVWH
t$ E3
@SUVH
@UAVAWH
d$ E3
@A_A^]
@SVWH
L$=H;
L$@H3
t$ WAVAWH
@A_A^_
\$ UVWATAUAVAWH
d$PE3
(D$ f
`A_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
UUUUUUU
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
t$ WATAUAVAWH
\$$@2
A_A^A]A\_
UVWATAUAVAWH
UUUUUUU
\$ E3
(D$ f
UUUUUUU
`A_A^A]A\_^]
t$ WATAUAVAWH
UUUUUUU
(D$ f
UUUUUUU
A_A^A]A\_
VWAVH
L$8H3
@A^_^
t$ WH
VWAVH
L$8H3
L$8H3
L$8H3
|$ AVH
u4A8F
WAVAWH
 A_A^_
L$0H3
L$0H3
L$0H3
|$ UATAUAVAWH
\$@E3
L$XH;
A_A^A]A\]
W H+W
VWAVH
L$8H3
@A^_^
l$ VWAVH
UVWATAUAVAWH
D$@H;
A_A^A]A\_^]
@USVWATAVAWH
A_A^A\_^[]
L$8H+
t$ WH
L$8H3
UVWATAUAVAWH
A_A^A]A\_^]
VWATAVAWH
L$ E3
L$8H3
@A_A^A\_^
L$0H3
|$ AVH
t$ WH
t$ WAVAWH
 A_A^_
\$ WH
t$@H+
t$ WH
t$ WH
|$8H;
t$ WH
t$ WH
UWATAVAWH
t$ E3
A_A^A\_]
|$ UH
t$ UWAVH
UVWATAUAVAWH
L$PE3
D$@H+
L;l$(
A_A^A]A\_^]
VWAVH
 A^_^
l$ WAVAWH
t$HH+
 A_A^_
@USVWATAVAWH
L$8H+
G H;G(t
A_A^A\_^[]
\$ UVWH
UVWATAUAVAWH
pA_A^A]A\_^]
@SVWH
L$8H3
@USVWATAUAVAWH
A_A^A]A\_^[]
UVWATAUAVAWH
t$`L;
A_A^A]A\_^]
@USVWATAVAWH
L$HE3
|$ I;
D$PHcH
D$PHcH
D$PHcH
D$PHcH
A_A^A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
@SVWAVAWH
t$ E3
A_A^_^[
|$ UH
@SUVAVAWH
H+C8H;
D$XD+
L$Xf;
D+k0E
|$PD;
 A_A^^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
E0HcH
E0HcH
E0HcH
E0HcH
t$ UWAVH
t$ UWAVH
t$ UWAVH
t$ UWAVH
s WATAUAVAWH
A_A^A]A\_
|$ AVH
SVWATAUAVAWH
A_A^A]A\_^[
\$ UVWAVAWH
A_A^_^]
@USVWATAVAWH
d$@E3
A_A^A\_^[]
(D$ H
(D$0H
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWAVAWH
D$(E3
L$ H;
A_A^_^]
t$ UWATAVAWH
A_A^A\_]
@SUVWATAVAWH
L$`H3
pA_A^A\_^][
\$ UVWATAUAVAWH
D$ H;8t
A_A^A]A\_^]
@SVWATAUAVAWH
A_A^A]A\_^[
WATAUAVAWH
@A_A^A]A\_
@SUVWATAVAWH
)t$@I
H;W8v
(t$@H
PA_A^A\_^][
\$ UVWATAUAVAWH
T$@E3
T$p+U
\$p+]
|$p+}
T$p+U
\$p+]
D$pD+E
T$p+U
\$p+]
D$pD+E
D$p+E
ORTMH
T$p+U
|$p+}
D$p+E
D$xLc
A_A^A]A\_^]
|$ UAVAWH
A_A^]
t$ UWAUAVAWH
E@HcH
E@HcH
D$PHcH
D$PHcH
D$PHcH
D$PHcH
M@HcQ
M@HcQ
A_A^A]_]
C@f99H
@USVWATAUAVAWH
D$`fff
t$`H;
T$hH+
t$`H;
T$hH+
A_A^A]A\_^[]
L$@H3
@VWAWH
@A__^
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
gfffffffH
gfffffffH
|$0E3
gfffffffH
A_A^A]A\_^[]
@USVWATAUAVAWH
T$HE3
gfffffffH
D$`HcH
D$`HcH
gfffffffH
D$`HcH
D$`HcH
|$ L;
A_A^A]A\_^[]
|$ AVH
WATAUAVAWH
t?fff
 A_A^A]A\_
WAVAWH
 A_A^_
|$ AVH
WAVAWH
 A_A^_
\$ UVWATAUAVAWH
|$ E3
A_A^A]A\_^]
UVWATAUAVAWH
t$pL;
CD$Hf
C8H;C@t
A_A^A]A\_^]
|$ AVH
|$ ATAVAWH
 A_A^A\
t$ ATAVAWH
gfffffffH
|$HH+
 A_A^A\
l$ VAVAWH
t#fff
|$HH+
 A_A^^
t$ WH
UUUUUUU
L$8H3
@SVWH
L$XH3
D$8H+
L$XH3
@SAUH
I#E0M
L;d$ u
H;t$ 
VWAVH
gfffffffI
fffffff
 A^_^
t$ WH
VWAVH
 A^_^
t$8H+
D$ I;
L$ H3
H#C0H
H9t$xu>M
9H9t$xu
H#A0H
UAVAWH
I#F0H
H;|$0tHH;
L9|$(u
PA_A^]
L9|$(u
I#F0L
UWAWH
H#G0H
H;|$0t
L9|$(
L9|$(u
tnfff
|$@H#A0H
`A__]
H#C0H
H9t$xu>M
9H9t$xu
H#A0H
t$PH;
\$Hfff
|$8H;
|$8H;
\$ UVWH
|$ UATAUAVAWH
C@H;}
tEH;U
C@H;U
A_A^A]A\]
H+A8H;
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SVWH
L$@H3
\$ WH
D$XH+
H9D$H
L$xH3
y(+y0A
q8+q(M
|$ AVH
@SUVWH
L$(H3
8_^][
@SVWH
D$ tp
L$(H3
L$8H3
L;AhL
BAhL+
@UVAVH
0A^^]
0A^^]H
|$ Hc
0A^^]
|$ AVH
l$0H+
t$ WATAUAVAWH
A_A^A]A\_
@UVWH
t$ E3
@USVWATAVAWH
unD8e
W(H;W0tWL
A_A^A\_^[]
@SUVWAVH
G@H;GHt
OhH;Wxt
0A^_^][
@SWAVH
t$`H;
0A^_[
0A^_[
OxH;Oxu
@SVAVH
l$HH+
 A^^[
\$ UVWATAUAVAWH
|$ E3
|$ E3
d$ E3
A_A^A]A\_^]
CL$@H
CT$`H
L$(L;
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
|$0I;
A_A^A]A\_
t$ WATAUAVAWH
|$ I;
A_A^A]A\_
@SVWATAUAVAWH
|$ M;
PA_A^A]A\_^[
t$ WATAUAVAWH
|$ I;
A_A^A]A\_
t$ WATAUAVAWH
|$ I;
A_A^A]A\_
t$ WATAUAVAWH
|$ I;
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
t$(I;
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
\$ UVWAVAWH
u;H;C
A_A^_^]
UVWAVAWH
`A_A^_^]
UVWAVAWH
`A_A^_^]
\$ UVWAVAWH
`A_A^_^]
UVWAVAWH
`A_A^_^]
UVWAVAWH
`A_A^_^]
UVWAVAWH
`A_A^_^]
UVWAVAWH
`A_A^_^]
UVWAVAWH
D$pE3
T$(H;
A_A^_^]
UVWATAUAVAWH
|$ E3
CD$pf
L$pE3
A_A^A]A\_^]
UVWATAUAVAWH
|$ E3
L$8E3
A_A^A]A\_^]
t$ WH
L$8H3
l$ VWATAVAWH
L$`H3
A_A^A\_^
SUVWAVAWH
(A_A^_^][
t$ WH
L$8H3
t$ WAVAWH
\$0E3
3333333
)D$ L
A_A^_
UWATAVAWH
A_A^A\_]
VWAUAVAWH
Ic@8H
A_A^A]_^
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWAVAWH
A_A^_^]
\$ UVWAVAWH
A_A^_^]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWAVAWH
A_A^_^]
\$ UVWAVAWH
A_A^_^]
t$ AVH
u.H;P
M90u7
@SUVH
(D$ L
(L$0A
L$0M;
t$ WH
\$ UVWH
\$ UVWH
@USVWATAUAVAWH
A_A^A]A\_^[]
\$ UVWH
|$ UAVAWH
txH+A
u7H;H
A_A^]
WAVAWH
)D$0L
\$ E3
D$0M+
t$ I+
(D$ f
(D$ f
D$@M;
PA_A^_
@USVWATAUAVAWH
t$8L;
CD$8f
T$`fH
C\$8H
CD$`f
C\$8H
t$ E3
C\$8H
t$ E3
A_A^A]A\_^[]
L$0H;SHt
t$ WH
T$ H;CHt
D$8H;
L$8H3
UVWATAUAVAWH
D$8L;
L$HE3
L;l$8
L$XH3
`A_A^A]A\_^]
S H;S(t
L$`H3
3333333
VWAVH
C(D8s
L$@H;SHt
 A^_^
t$ UWATAVAWH
A_A^A\_]
(D$ I
UVWAVAWH
t$ E3
A_A^_^]
WAVAWH
(D$ f
0A_A^_
L$0H3
C(@8{
L$ H;SHt
D$$trueA
D$$falsH
D$(eH
D$$nullA
L$0H3
L$8H;SHt
C(@8{
D$8H;SHt
C(@8{
L$8H;SHt
t$ WAVAWH
C(D8{
L$PH;SHt
 A_A^_
t$ WAVAWH
D$ H;QHt
S@H;SHt
S@H;SHt
S@H;SHt
S@H;SHt
L$0H3
@A_A^_
UVWATAUAVAWH
EgH;QHt
S@H;SHt
C@H;CHt
}offf
S@H;SHt
A_A^A]A\_^]
 !!"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$%&&&&&&&&&&&&'&&()))*f
C(@8{
L$0H;SHt
t$ WH
t$ WH
L$ SUVWH
8_^][
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A^_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
T$ H;
T$ H;
T$ H;
T$ H;
T$ H;
@SVWATAUAVAWH
l$8L;
PA_A^A]A\_^[
@SVWATAUAVAWH
L$pI+
H+T$`H
t$XI;
A_A^A]A\_^[
t$XI;
\$ UVWATAUAVAWH
d$PE3
(D$ f
pA_A^A]A\_^]
\$ UVWATAUAVAWH
D$PE3
(D$ f
pA_A^A]A\_^]
L$8H3
@SAUAVH
|$@I;
`A^A][
t$XL+
`A^A][
`A^A][
t$ WATAUAVAWH
(D$ f
A_A^A]A\_
@SUVWAWH
8striu
t$pH;
8striu
L$ H3
0A__^][
UVWATAUAVAWH
PA_A^A]A\_^]
t$0H;
\$ UVWAVAWH
L$HH3
PA_A^_^]
WATAUAVAWH
S H+S
D$0D9x }
D;y }mH
)D$ L
A_A^A]A\_
L$0H3
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
\$ UVWAVAWH
L$0H;
L$@H3
PA_A^_^]
UVWAVAWH
(D$ f
A_A^_^]
SVWATAUAVAWH
A_A^A]A\_^[
\$ VWAVH
L$PH3
`A^_^
@SVAVAWH
8A_A^^[
d$0E3
8A_A^^[
t$ WH
[ UVWH
[ UVWH
l$ VWAVH
@USVWAVAWH
A_A^_^[]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
0A_A^A]A\_^]
UUUUUUU
|$ E3
(D$ f
UVWATAUAVAWH
D$0Ic
@8|$@t
D$8;0
L$PH3
`A_A^A]A\_^]
@SUVWATAUAVAWH
NPH;NP
t$ L;
L$pH3
A_A^A]A\_^][
L#^0I
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
)t$PI
(D$ f
(t$PI
A_A^A]A\_
|$ UATAUAVAWH
A_A^A]A\]
\$ UVWATAUAVAWH
|$HL;
A_A^A]A\_^]
@USVWATAUAVAWH
\$D8YhtuH
H9y s
H;z r
H9x s
H;y suH
UUUUUUU
u:fff
H9x s
UUUUUUU
H9x s
H;y suH
UUUUUUU
H9x s
H;y suH
UUUUUUU
H9x s
H;y suH
UUUUUUU
|$hff
t$XH;
A_A^A]A\_^[]
@USVWATAUAVAWH
D9|$`~
H#M`H
t$HH;
\$xI;
\$xI;
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
tensor(bH
ool)u
tensor(iH
nt16u
nt32u
nt64u
tensor(uH
int1u
6)t|L
int3u
2)tRL
int6u
4)t(L
int8u
float16)M9H
tensor(dM9
oublu
e)tTL
tensor(fM9
loatu
AVAWH
CPUExecuH9
tionProvH9H
(D$ f
D$ H;
HcK,I
HcK(I
8A_A^
(D$ f
|$0H;
@SVWATAUAVAWH
T$0I;
PA_A^A]A\_^[
UVWATAUAVAWH
PA_A^A]A\_^]
UVWATAUAVAWH
PA_A^A]A\_^]
UVWATAUAVAWH
PA_A^A]A\_^]
UVWATAUAVAWH
PA_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
|$ UATAUAVAWH
A_A^A]A\]
@USVWATAVAWH
A_A^A\_^[]
UVWATAUAVAWH
PA_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
PA_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
PA_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
PA_A^A]A\_^]
(D$ f
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
PA_A^A]A\_^]
UVWATAUAVAWH
PA_A^A]A\_^]
UVWATAUAVAWH
PA_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
PA_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
UVWATAUAVAWH
PA_A^A]A\_^]
L$HH+
UVWATAUAVAWH
PA_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
PA_A^A]A\_^]
UVWATAUAVAWH
PA_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
|$ UATAUAVAWH
A_A^A]A\]
\$ UVWH
UVWATAUAVAWH
PA_A^A]A\_^]
UVWATAUAVAWH
PA_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
S H+S
X UVWATAUAVAWH
PA_A^A]A\_^]
VWAUAVAWH
|$XH+
A_A^A]_^
VWAUAVAWH
|$XH+
A_A^A]_^
@SUVWAVH
L$8H3
@A^_^][
t$ WH
UVWATAUAVAWH
A_A^A]A\_^]
@SUVWAVAWH
L$pH3
A_A^_^][
t$ UWATAVAWH
t$ E3
A_A^A\_]
@USVWATAUAVAWH
H98u@H;
A_A^A]A\_^[]
l$ WAVAWH
t$HH+
 A_A^_
@SUAVH
L$ E3
L$`H3
pA^][
@SVWH
@VAVAWH
0A_A^^
t$ WH
@ H;}
H9r s/H
I;p rdH
L$(8H
D$ H9P s
H;u r
t$ AWH
\$ UVWAVAWH
l$8@8k
fffffff
)D$ L
PA_A^_^]
\$ UVWATAUAVAWH
\$0E3
l$8D8k
fffffff
)D$ H
PA_A^A]A\_^]
\$ UVWAVAWH
fffffff
)D$ H
`A_A^_^]
VWAVH
 A^_^
VWAVH
D$0E3
D$0L9@ s
)D$ L
PA^_^
\$ UVWATAUAVAWH
8L$@L
D$HE3
D$xH+
D$XH+
UUUUUUU
uUL9}P
L9p s
L9p s
L;s rwH;
A_A^A]A\_^]
UVWATAUAVAWH
|$pH;}
A_A^A]A\_^]
\$ UVWATAUAVAWH
H9P s
H;Q r
A_A^A]A\_^]
\$ UVWAVAWH
L$HH3
PA_A^_^]
@SVWH
L$(H3
@SVWH
L$hH3
UVWATAUAVAWH
t"fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
L9p s
L;q r
fffffff
fffffff
A_A^A]A\_^]
UVWATAUAVAWH
D$@L9x s
L;y sdH
UUUUUUU
)D$@L
A_A^A]A\_^]
L9P s
L;R r
L9@ s
L;A r
VWAWH
@A__^
VWAVH
H;H s
L$ H3
0A^_^
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
@USVWATAUAVAWH
D$XL;
\$@H;
L;|$X
A_A^A]A\_^[]
UVWATAUAVAWH
L$hH3
pA_A^A]A\_^]
\$ UVWAVAWH
l$HH;
H;Wxt
|$HH;
T$PH+
L$XH3
`A_A^_^]
D$ L;
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
l$ VAVAWH
|$PL+
d$XL+
0A_A^^
l$ VAVAWH
|$PL+
d$XL+
0A_A^^
VWAVH
 A^_^
VWAVH
 A^_^
@SVWH
L$@H3
t$ WH
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
SVWATAUAVAWH
L$0H+
PA_A^A]A\_^[
PA_A^A]A\_^[
SVWATAUAVAWH
L$0I+
`A_A^A]A\_^[
`A_A^A]A\_^[
H;APuS
@SUVWATAVAWH
\$0E3
u?fff
)D$ H
PA_A^A\_^][
t$ WH
@UVAVH
 A^^]
l$ VWAVH
 A^_^
l$ VWAVH
 A^_^
l$ VWAVH
t$0L;
l$ VWAVH
 A^_^
VWAVH
 A^_^
\$ UVWATAUAVAWH
W0H;W8t
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
A_A^A]A\_^]
t$ WH
@USVWATAUAVAWH
A_A^A]A\_^[]
t$HI;
\$ UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UWATAVAWH
A_A^A\_]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAVAWH
A_A^A\_^[]
@SUVWATAUAVAWH
u0fff
hA_A^A]A\_^][
t$ UH
@USVWATAUAVAWH
|$ E3
8\$QH
T$`D8t$hH
ET$pH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
t>fff
A_A^A]A\_^[]
@SUVWATAUAVAWH
hA_A^A]A\_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
UVWATAUAVAWH
F(9_(
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
UVWATAUAVAWH
|$8D9
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
D$hH+
D$hH+
A_A^A]A\_^[]
D$8H;S
L$8H;S
L$8H;S
L$8H;S
L$8H;S
L$8H;S
L$8H;S
L$8I;P
L$8H;S
L$8H;S
L$8H;S
L$8H;S
L$8H;S
UATAUAVAWH
A_A^A]A\]
\$ UVWATAUAVAWH
A_A^A]A\_^]
t$ WH
\$ VH
t$ WH
t$8H+
@SVWH
L$ H3
@USVWATAUAVAWH
L$pH;M
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
H9A u
@USVWATAUAVAWH
A_A^A]A\_^[]
\$ UVWATAUAVAWH
|$`L;
C\$`H
C\$@H
D$pH+
D$PH+
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
UVWATAUAVAWH
\$@D;
A_A^A]A\_^]
Q HcZ 3
t$ WH
t$ WH
D$ H;D$(t H
D$ H;D$(u
L$0H3
\$ WH
t$ WATAUAVAWH
A_A^A]A\_
@SVWATAUAVAWH
T$0I;
PA_A^A]A\_^[
UAVAWH
 A_A^]
 A_A^]
\$ UVWATAUAVAWH
(D$ f
PA_A^A]A\_^]
t$ WH
\$ UVWAVAWH
0A_A^_^]
t$8H+
t$ H9Ax
B`9A`
Bp9Ap
BhH9Ah
@USVWATAUAVAWH
UUUUUUU
l$DE3
UUUUUUU
t$XE3
L$XH;
\$@E3
H;D$X
A_A^A]A\_^[]
t$0Hc
l$PL;
WATAUAVAWH
~;I;_
0A_A^A]A\_
|$ H9A
t$ WH
l$ WAVAWH
t$HH+
 A_A^_
UVWATAUAVAWH
0A_A^A]A\_^]
L#o0M
tkK9<
VWAVH
@A^_^
VWAVH
@A^_^
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
\$ WH
L$@H3
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WH
t$ WH
@USVWATAUAVAWH
D$`H+
L$DH;
D$PL;
CT$PL
d$ E3
gfffffffI
|$pE3
gfffffffH
|$HE3
A_A^A]A\_^[]
UVWATAUAVAWH
D$(H;
t$@H+
A_A^A]A\_^]
l$ VWAVH
 A^_^
VWAVH
 A^_^
@USVWAVH
A^_^[]
USVWATAUAVAWH
t$`L;
CD$`f
A_A^A]A\_^[]
UVWAVAWH
PA_A^_^]
UVWATAUAVAWH
t$0L;
t$0L;
A_A^A]A\_^]
l$ VWAVH
GPH9GHtOH
L$`H3
H9_@~
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
VWAWH
)t$@I+
IHL;IPu
L;FPuS
IHL;IPu
L;FPuS
IHL;IPu
L;FPuS
IHL;IPu
L;FPuS
L$0H3
PA__^
VWATAVAWH
@A_A^A\_^
\$ UVWH
UVWATAUAVAWH
D$HH;
L$PH;
A_A^A]A\_^]
k VWAVH
PA^_^
VWAVH
)|$PD
)D$@H
L$0H3
(|$PD
(D$@H
pA^_^
\$ WAVAWH
)t$@L+
L$0H3
PA_A^_
\$ WAVAWH
)t$@L+
L$0H3
PA_A^_
@SVATH
T$0L;
l$`Hc
)t$@H
L$8H3
pA\^[
|$ AVH
L$0H3
\$ WAVAWH
)t$@L+
L$0H3
PA_A^_
UVWATAUAVAWH
H;8uiH
A_A^A]A\_^]
@SUVWAVH
0A^_^][
t$ UWAVH
zIuGI
@USVWATAUAVAWH
D$xL;
tpfff
B H9A
L;l$x
A_A^A]A\_^[]
L$(H3
L$(H3
L$(H3
L$(H3
\$ UVWATAUAVAWH
|$8I;
PA_A^A]A\_^]
t$ WATAUAVAWH
)t$pI
(D$ f
(t$pI
A_A^A]A\_
@USVWATAUAVAWH
A_A^A]A\_^[]
t$`H;
T$hH+
\$ UVWATAUAVAWH
D$xH+
A_A^A]A\_^]
\$ UVWATAUAVAWH
D$`E3
D$pH+
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
L$@H;
L$@H;
A_A^A]A\_^[]
r1w/H
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
D$8I;V
A_A^A]A\_^[]
UVWATAUAVAWH
t$ E3
A_A^A]A\_^]
@SUVWAVH
sHL;sPu
H9D$Ht
L$XH3
`A^_^][
WAVAWH
 A_A^_
WAVAWH
 A_A^_
USVWATAUAVAWH
|$HE3
|$HE3
MPH;M`
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
CPUExecuH9
tionProvH9P
ideru
UVWATAUAVAWH
D$PH;
)D$0H
0H;t$P
\$0E3
)D$0L
A_A^A]A\_^]
UVWATAUAVAWH
d$@E3
t$(I;~ht
t=8D$ t
E9}(u
|$P;G
t$0I;
A_A^A]A\_^]
l$ VWAVH
0A^_^
@USVWATAUAVAWH
D$HL;
L;d$H
A_A^A]A\_^[]
WAVAWH
 A_A^_
USVWATAUAVAWH
D$hH+
D$hH+
A_A^A]A\_^[]
|$ ATAVAWH
 A_A^A\
@USVWATAUAVAWH
D$hH;
t$HL;
t$HL;
H;D$h
D$xH+
A_A^A]A\_^[]
|$ UH
D$pE3
UVWATAUAVAWH
H;U t
H;U t
H;U t
H;U t
A_A^A]A\_^]
UWAVH
]'H+]
@UVATAVAWH
T$ I;
@A_A^A\^]
9Yielu
tfD9P(u
l$ VWAVH
0A^_^
t$ WH
@USVWATAUAVAWH
d$XE3
A_A^A]A\_^[]
@USVWATAUAVAWH
D$HD8`h
CL$XH
|$@E3
MpH;MX
A_A^A]A\_^[]
|$ ATAVAWH
 A_A^A\
t$8H+
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
H;]Pt
|$PE3
U H;U(t
D$pH;U(t
d$pH;U(t
l$pH;U(t
t$pH;U(t
A_A^A]A\_^[]
UVWAVAWH
pA_A^_^]
WATAUAVAWH
 A_A^A]A\_
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
t$ WATAUAVAWH
A_A^A]A\_
@SUVH
WAVAWH
t$(@8w
@A_A^_
\$ UVWATAUAVAWH
d$PE3
(D$ f
pA_A^A]A\_^]
S H+S
@USVWATAUAVAWH
|$xI;
\$pE3
A_A^A]A\_^[]
@SUVWATAVAWH
A_A^A\_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWAVH
D$HH+
A^_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
x UATAUAVAWH
A_A^A]A\]
t$hH;
D$0ff
t$PH;
|$8H;
|$@H;
T$HH+
|$XH;
T$`H+
@USVWATAUAVAWH
A_A^A]A\_^[]
@SUAUAVAWH
@A_A^A]][
t$ WAVAWH
\$ I;
@A_A^_
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
d$ E3
H#U0H
(D$ f
H#}0H
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
H#U0H
(D$ f
H#}0H
H#C0H
t$ WH
|$0u5H
@USVWATAUAVAWH
|$pE3
D$@L;
L;t$@H
A_A^A]A\_^[]
UVWATAUAVAWH
SAME_UPPL9
ERt)H
SAME_LOWH9
L)|$(M
A_A^A]A\_^]
@USVWATAVAWH
A_A^A\_^[]
UVWATAUAVAWH
D$`E3
D$pH+
D$@H;
CT$@L
A_A^A]A\_^]
@SVWH
L$XH3
t$ UWATAVAWH
D$pH+
D$@H;
CT$@L
A_A^A\_]
UVWATAUAVAWH
A_A^A]A\_^]
H#C`H
t$ WH
l$ VWATAVAWH
A_A^A\_^
UVWATAUAVAWH
D$PH;
CT$PL
A_A^A]A\_^]
UVWATAUAVAWH
L$`H#
T$8H;
D$@M;
9H(u]I
~TH;H uNL
uB9H(u=H
l$xM;
D8d$0
|$HH;|$x
|$0E3
t6fff
M+<$I
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
D$PH;
CT$PL
A_A^A]A\_^]
UVWATAUAVAWH
D$PH;
CT$PL
A_A^A]A\_^]
\$ UVWATAUAVAWH
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
t$ WH
@USVWATAUAVAWH
D$@L;
L;t$@H
A_A^A]A\_^[]
WAVAWH
0A_A^_
@USVWATAVAWH
A_A^A\_^[]
UVWATAUAVAWH
Lch M
D$`E3
D$pH+
D$@H;
CT$@L
A_A^A]A\_^]
t$ WH
L$8H3
\$ UVWATAUAVAWH
D$pH+
A_A^A]A\_^]
H#C8H
\$ UVWH
L$8H3
UVWATAUAVAWH
D$@H;
CT$@L
A_A^A]A\_^]
UVWATAUAVAWH
D$xH+
A_A^A]A\_^]
|$ AVH
UVWATAUAVAWH
I#F8H
pA_A^A]A\_^]
UVWATAUAVAWH
D$HH;
CT$HL
A_A^A]A\_^]
l$ VWAVH
UVWAVAWH
LcK A
PA_A^_^]
@USVWATAVAWH
D$hH;D$p
D$hH;D$p
D$hH;D$pu}
D$hH;D$pum
D$hH;D$puL
A_A^A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWAVH
`A^_^[]
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
r3Hc>H
s HcD$ H
UVWATAUAVAWH
D$8L;
A_A^A]A\_^]
UVWATAUAVAWH
D$0E2
t$`L;
C\$`H
D$pH+
uTH;V
A_A^A]A\_^]
@UVWAVAWH
\$hL;
 A_A^_^]
 A_A^_^]
@SUVWAVH
 A^_^][
 A^_^][
@SUVWAVH
 A^_^][
 A^_^][
@SUVWAVH
 A^_^][
 A^_^][
 A^_^][
@SUVWAVH
 A^_^][
 A^_^][
@UVAVH
 A^^]
@USVWATAUAVAWH
D$PL;
tzfff
L;l$PtPH
A_A^A]A\_^[]
\$ UVWATAUAVAWH
L$hH;
A_A^A]A\_^]
T$0H+
@USVWATAUAVAWH
|$ E3
;|$H|
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
t$PE3
A_A^A]A\_^[]
@USVWATAVAWH
A_A^A\_^[]
WAVAWH
 A_A^_
@USVWATAUAVAWH
L$PH;
A_A^A]A\_^[]
@SWAVH
 A^_[
 A^_[
t$0ux
WAVAWH
 A_A^_
\$ UVWAVAWH
\$xH;]
|$xH;}
A_A^_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
t$8H+
@SUVWATAUAVAWH
D$HL;
L;t$H
A_A^A]A\_^][
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
L$@E2
A_A^A]A\_^]
\$ UVWATAUAVAWH
d$ E3
D$ E3
A_A^A]A\_^]
\$ UVWATAUAVAWH
D$@E3
|$0I;
L$HH3
PA_A^A]A\_^]
@USVWATAUAVAWH
L$xH;M
A_A^A]A\_^[]
UVWAVAWH
D$xH;
D$xH;
A_A^_^]
UVWATAUAVAWH
)t$pM
(D$ f
(t$pH
A_A^A]A\_^]
VWAVH
 A^_^
t$ WH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
L$xH+
A_A^A]A\]
|$ UATAUAVAWH
D$PfD
D$PfD
D$`I;
D$xH+
A_A^A]A\]
|$ UATAUAVAWH
L$xH+
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
t$ WAVAWH
\$ I;
@A_A^_
@SUVWATAVAWH
I#V0H
0A_A^A\_^][
I#V0H
(D$ f
I#~0H
@USVWATAUAVAWH
T$hH#
L$hH#
A_A^A]A\_^[]
T$(H+
T$0H+
L$8H3
t$ WATAUAVAWH
D$8H;
A_A^A]A\_
@USVWATAUAVAWH
|$PL;
A_A^A]A\_^[]
\$ UVWAVAWH
A_A^_^]
@USVWATAUAVAWH
UHH;UPt
UHH;UPt
H;UPt
UhH;Upt
H;Upt
H;UPt
H;UPt
|$HH;
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
(D$`f
A_A^A]A\_^[]
UVWATAUAVAWH
)t$pM
(D$ f
(t$pH
A_A^A]A\_^]
\$ UVWH
|$ AVH
N H;H u
VWATAVAWH
 A_A^A\_^
X UVWH
D$xH;E
D$xH;E
D$xH;E
WAVAWH
0A_A^_
l$ VH
D$@H9
L$PH3
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
UVWATAUAVAWH
M;F u
E0H#D$0H
(D$ f
E0H#D$0H
@A_A^A]A\_^]
@SVWH
L$0H3
UVWATAUAVAWH
L$pL;
L$pL;
T$pH;
T$pH;
A_A^A]A\_^]
@SVWH
D$@H+
|$PH;
L$XH+
gfffffffH
\$ UVWATAUAVAWH
A_A^A]A\_^]
VWAVH
L$`H3
pA^_^
\$ UVWAVAWH
A_A^_^]
@USVWATAUAVAWH
|$ E3
A_A^A]A\_^[]
H#E0L
VWAVH
t$ WATAUAVAWH
)t$PI
H#E0H
(t$PI
A_A^A]A\_
H#U0H
(D$ f
H#u0H
@SUVWH
@USVWATAVAWH
A_A^A\_^[]
UVWAVAWH
D$ E3
L$`H3
pA_A^_^]
@SUVWATAUAVAWH
(D$ f
XA_A^A]A\_^][
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
p WATAUAVAWH
(D$0f
A_A^A]A\_
@SUVWATAVAWH
V I+V
PA_A^A\_^][
\$ UVWATAUAVAWH
t$PH+
A_A^A]A\_^]
@USVWATAUAVAWH
D$`E3
L;t$`
\$pE3
L;t$`
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
SUVWAVH
A^_^][
@SAUH
|$0fff
I#E0H
@SUWH
t$PHk
L$8I+
L$XI+
D$ E3
@SVWH
L$8I+
L$8I+
T$@H+
T$@H+
UVWATAUAVAWH
A_A^A]A\_^]
@SUVWAVAWH
HA_A^_^][
t$@ub
|$ AVH
;h u=H
p ;n 
t$ WH
(D$ f
D$ H;
@USVWATAUAVAWH
D$0H;
D$0L;
A_A^A]A\_^[]
\$0H+
t$ WAVAWH
V H;V(t
V H;V(t
V H;V(t
0A_A^_
t$ UWAVH
@A^_]
UVWATAUAVAWH
D$@L;
Ic<$A
L;d$@
L;d$@
L;d$@
A_A^A]A\_^]
@SUVWATAUAVAWH
D$H8G
t$@H;
T$HH+
T$HH+
L$PH3
hA_A^A]A\_^][
UVWATAUAVAWH
t$ E3
t$ E3
A_A^A]A\_^]
UVWATAUAVAWH
D$HL;
L;d$H
L;d$H
L;d$H
A_A^A]A\_^]
@SUVWAVH
D9H,tcH
D$@Mc@
D$0L;
|$8L;
L$@I+
L$HH3
PA^_^][
@SVWATAUAVAWH
D$0E3
D$0E3
PA_A^A]A\_^[
L$0H3
t$ WH
t$ WH
L$8H3
t$ UWATAVAWH
A_A^A\_]
t$ UWATAVAWH
A_A^A\_]
@SUVWAVH
L$@H3
PA^_^][
@USWH
@USVWAUAVAWH
A_A^A]_^[]
UWAVH
UWAVH
USVWH
D$@I;
T$pH;
USVWH
T$pH;
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
t$ WH
[ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
~ I+~
E I+E
D$XH+
A_A^A]A\_^[]
\$0A+
\$0A+
D$xE3
D$xE3
@SVWAVAWH
L$HH3
PA_A^_^[
UVWATAUAVAWH
u I+u
A_A^A]A\_^]
t$ UWATAVAWH
A_A^A\_]
t$ UWATAVAWH
A_A^A\_]
t$ UWATAVAWH
A_A^A\_]
UWAVH
UWAVH
D$0H+
D$HH+
D$xE3
UVWAVAWH
A_A^_^]
UVWAVAWH
T$II+
A_A^_^]
UVWAVAWH
T$II+
A_A^_^]
USVWAVH
A^_^[]
UVWAVAWH
D$pH+
A_A^_^]
UVWAVAWH
D$pH+
A_A^_^]
t$ UWATAVAWH
A_A^A\_]
t$ WH
L$XH3
D$xE3
D$xE3
D$xE3
D$xE3
D$xE3
D$xE3
D$xE3
D$xE3
D$xE3
D$xE3
D$xE3
WAVAWH
A_A^_
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
@SUVWAUAVAWH
PA_A^A]_^][
A H9A
A H9A
A u`H9A
A H9A
A H9A
|$ UH
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
M;A M
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
VWATAVAWH
\$ I;
@A_A^A\_^
D$ H;
CT$ L
L$hH3
D$ H;
CT$ L
@SUVWH
H_^][
l$(H+
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
\$ UVWATAUAVAWH
D$@H98uHA
D$PL;D$p
L$HH;Q
L$HH;Q
FHH;Q
D$PL;D$p
T$hL;
D$Hfff
FHH;Q
A_A^A]A\_^]
SVWAVH
A^_^[
)t$ I
(t$ H
)t$ I
(t$ H
)t$ I
.5Wv0
(t$ H
)t$ M
(t$ H
)t$ I
.5j%0
(t$ H
D$1H+
)t$ M
(t$ H
)t$ M
(t$ H
)t$ I
(t$ H
)t$ I
z)u'H;
z.u,H;
(t$ H
)t$ M
(t$ H
t\fff
)t$ M
(t$ H
)t$ I
z(u&H;
z-u+H;
(t$ H
D$1H+
)t$ M
(t$ H
)t$ M
(t$ H
)t$ M
(t$ H
)t$ I
(t$ H
H;C(t
S H;S(t
S8H;S@H
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
\$ WH
L$@H3
\$ WH
L$@H3
A uWH9A
A H9A
A H9A
S H;S(t
S8H;S@t
\$ UVWATAUAVAWH
D$0E3
L$@I+
L$PH;
l$ E3
A_A^A]A\_^]
UVWATAUAVAWH
D;|$0L
t$PM;
L$PI+
t$hM;
D$hH+
|$4D;|$8
A_A^A]A\_^]
UVWATAUAVAWH
t$ E3
D$@H+
A_A^A]A\_^]
D$ M+
BPH98H
BPH98H
D$ M+
BPH98H
BPH98H
t$ UWAUAVAWH
A_A^A]_]
D$ M+
BPH98H
BPH98H
)D$0D
)L$ D
(L$ D
(t$PL
)T$pD
)\$`D
)d$PD
)l$@D
)t$0D
)|$ D
(|$ D
(t$0D
(l$@D
(d$PD
(\$`D
(T$pD
L$XH3
\$ UVWATAUAVAWH
A_A^A]A\_^]
ExH+EhH
H;}xt
D$pH+
|$DE3
D$xE3
D$xE3
D$xE3
D$xE3
t$ WH
L$XH3
t$ WH
L$XH3
|$ ATAVAWH
@A_A^A\
|$ ATAVAWH
@A_A^A\
WATAUAVAWH
@A_A^A]A\_
WATAUAVAWH
@A_A^A]A\_
@USVWATAUAVAWH
d$PI;
D$hH+
A_A^A]A\_^[]
@USVWATAUAVAWH
d$PI;
D$hH+
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A\_^[]
UVWATAUAVAWH
E I9E
EPI9EH
A_A^A]A\_^]
t$@I+
X UVWATAUAVAWH
A_A^A]A\_^]
av_H+
^v\H+
^v\H+
I;_(HcM
@USVWATAUAVAWH
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
t$ E3
@USWH
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
UVWATAUAVAWH
D$XH+
D$pH+
A_A^A]A\_^]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$PH;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$@H;
A_A^A]A\_^[]
@USVWATAUAVAWH
G8L+G0I
T$PH;
A_A^A]A\_^[]
@USVWATAUAVAWH
F8L+F0I
T$PH;
~%fff
A_A^A]A\_^[]
USVWATAUAVAWH
F8M+F0I
T$PH;
A_A^A]A\_^[]
USVWATAUAVAWH
F8M+F0I
T$PH;
A_A^A]A\_^[]
UWAVH
L$xH3
SUAWH
UWAVH
L$xH3
SUAWH
SATAWH
A_A\[
SATAWH
A_A\[
SATAWH
A_A\[
SATAWH
A_A\[
SATAWH
A_A\[
SATAWH
A_A\[
L$xH3
SATAWH
A_A\[
L$xH3
SATAWH
A_A\[
}'fff
}'fff
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
l$0M;
l$0M;
\$ UVWATAUAVAWH
D$hH+
A_A^A]A\_^]
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
@VAVA
@VAVA
VWATAUAVH
)|$@D
)D$0H
M;up|-I
|$(H;
(t$PL
A^A]A\_^
VWATAUAVH
)|$@D
)D$0H
M;up|-I
|$(H;
(t$PL
A^A]A\_^
@VAVA
@VAVA
VATAVAWH
GPfff
L$ ff
M;_p|)I
t$8L;
xA_A^A\^
l$ VWAVH
@A^_^
UVWATAUAVAWH
A_A^A]A\_^]
T$pH;
T$pH;
T$pH;
T$pH;
T$pH;
T$pH;
T$pH;
T$pH;
T$pH;
T$pH;
T$pH;
T$pH;
T$pH;
T$pH;
@SUVWAVAWH
D$PH+
A_A^_^][
@SUVWAVAWH
D$PH+
A_A^_^][
@SUVWAVAWH
D$PH+
A_A^_^][
@SUVWAVAWH
D$PH+
A_A^_^][
@SUVWAVAWH
D$PH+
A_A^_^][
@SUVWAVAWH
D$PH+
A_A^_^][
@SUVWAVAWH
D$PH+
A_A^_^][
@SUVWAVAWH
D$PH+
A_A^_^][
@SUVWAVAWH
D$PH+
A_A^_^][
@SUVWAVAWH
D$PH+
A_A^_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
|$ AVH
T$PH;
\$ UVWATAUAVAWH
MhI+MXH
U`I;Uht
U`I;Uht
A_A^A]A\_^]
@USVWATAUAVAWH
fffffff
D$`H9P }
H;y }tL9
)D$`L
fffffff
H9X }
H;Y }xL9
D$@H;x
H9X }
H;Z }
A_A^A]A\_^[]
HcD$(H
A H+A
A8H+A0H
L;I }PL+
M;J |
l$ VAUAVAWH
CPfff
I;kp|
l$@A_A^A]^
l$ VAUAVAWH
CPfff
I;kp|
l$@A_A^A]^
l$ VATAVAWH
CPfff
M;{p| I
l$@A_A^A\^
UWATAUAWH
t$@fff
KPfff
L;{p| H
\$HA_A]A\_]
UVWATAWH
A_A\_^]
l$ VATAVAWH
CPfff
M;{p| I
l$@A_A^A\^
*H;y 
H;{ |
:L;Q }TH
M;Q |
:L;Q }TH
M;Q |
UVWATAWH
_Pfff
H;op|
A_A\_^]
l$ VAUAVAWH
CPfff
I;kp|
l$@A_A^A]^
:L;Q }WH
M;Q |
:L;Y }I
M;Z |
*H;y 
H;{ |
UVWATAWH
_Pfff
H;op|
A_A\_^]
UVWATAWH
A_A\_^]
:L;Q }WH
M;Q |
UVWATAWH
A_A\_^]
UWATAUAWH
t$@fff
L;cp| H
\$HA_A]A\_]
*H;y 
H;{ |
l$ VAUAVAWH
CPfff
I;kp|
l$@A_A^A]^
UWATAUAWH
t$@fff
KPfff
L;{p| H
\$HA_A]A\_]
:L;Y }I
M;Z |
l$ VAUAVAWH
I;kp|
l$@A_A^A]^
UVWATAWH
A_A\_^]
l$ VAUAVAWH
I;kp|
l$@A_A^A]^
t$ WH
oD$0L
t$ WH
oD$0L
@SUVWAVAWH
L$(E3
T$@H;
A_A^_^][
@SUVWAVAWH
L$(E3
T$@H;
A_A^_^][
|$ UH
@SUVWAVAWH
A_A^_^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SUVWAVH
T$8H+
L$@H3
PA^_^][
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
\$ UVWAVAWH
L$xE3
T$0H;
A_A^_^]
\$ UVWAVAWH
L$xE3
T$0H;
A_A^_^]
@SVWH
SWAWH
0Hc\$pE
T$PE;
0A__[
t$ WH
t$ WH
UVWATAUAVAWH
t+LcN
 A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
D$0Lc
D$@Lc
D$PLc
D$`Lc
X UVWATAUAVAWH
D8n,tEH
D8n t
t(HcF
)E@Ic
8^,t3HcN
)E@LcF
A_A^A]A\_^]
@SVWH
\$ WH
gfffffffH+
t$ WH
|$ UH
@SVWATAUAVAWH
D$0E3
D$0E3
PA_A^A]A\_^[
UVWATAUAVAWH
L$xE3
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SUVWATAVAWH
S H;S(H
L$@H3
PA_A^A\_^][
@SUVWATAUAVAWH
A_A^A]A\_^][
UWAVH
UWAVH
@SVWH
@SVWH
@SVWH
@SVWH
@USVWH
@SVWH
@SUVWH
@SUVWH
@SVWH
l$ VWAVH
l$ VWAVH
L$(H3
@UVWH
l$huNI
@UVWH
@UVWH
@UVWH
@SUVH
@SUVH
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAVAWH
fC9tE
A_A^A\_^[]
@USVWATAVAWH
fC9tE
A_A^A\_^[]
@USVWATAVAWH
A_A^A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
\$8E3
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
PA_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
\$ I;
\$ I;
\$ I;
\$ I;
\$ I;
L$pH3
L$pH3
L$pH3
L$pH3
L$pH3
L$pH3
L$pH3
\$ I;
\$ I;
\$ I;
\$ I;
)t$0H
L$(H3
(t$0H
t$ WH
WAVAWH
0A_A^_
@USVWAVH
A^_^[]
(%)B,
t$ WH
L$ H;
>"t(H
L$(H3
\$ UVWH
L$ H;
>"t%H
L$(H3
\$ UVWH
L$ H;
>"t%H
L$(H3
|$ AVH
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
T$`H;
A_A^A]A\_^[]
@USVWATAUAVAWH
T$`H;
A_A^A]A\_^[]
@USVWATAUAVAWH
T$`H;
A_A^A]A\_^[]
@USVWATAUAVAWH
T$`H;
A_A^A]A\_^[]
@USVWATAUAVAWH
T$`H;
A_A^A]A\_^[]
t$ WATAUAVAWH
A_A^A]A\_
UVWAVAWH
A_A^_^]
|$ AVH
@SUVWATAVAWH
A_A^A\_^][
s WATAUAVAWH
H;l$HuuH
A_A^A]A\_
@SUVWATAVAWH
A_A^A\_^][
s WATAUAVAWH
H;l$HuuH
A_A^A]A\_
l$ VWATAVAWH
A_A^A\_^
s WATAUAVAWH
H;l$HuuH
A_A^A]A\_
s WATAUAVAWH
H;l$HuuH
A_A^A]A\_
@SUVWATAVAWH
A_A^A\_^][
s WATAUAVAWH
H;l$HuuH
A_A^A]A\_
@SUVWATAVAWH
}7fff
A_A^A\_^][
@USVWATAVAWH
A_A^A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
D$PI;
H;V0t
HcF0L
L$PH;
L$PH;
H0I9H0
VAVAWH
 A_A^^
|$ AVH
VWAVH
@A^_^
|$ UH
t$ WH
UVWATAUAVAWH
A_A^A]A\_^]
D$@H+
UVWATAUAVAWH
D$@H+
A_A^A]A\_^]
D$xE3
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
t$ WH
Et$PH
L$XH3
UVWAVAWH
A_A^_^]
UVWATAUAVAWH
D$8E3
D$HH+
A_A^A]A\_^]
UVWAVAWH
PA_A^_^]
@SUWATAVAWH
x H+x
HA_A^A\_][
L$(H3
L$(H3
L$(H3
UWAVH
D$0H+
UWAVH
D$0H+
UWAVH
D$0H+
|$ UH
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
L$(H3
L$(H3
@USVWATAUAVAWH
A_A^A]A\_^[]
>v<I+
(t$@f
|$`H+
(D$0f
(t$@f
|$`H+
(D$Pf
@USVWATAUAVAWH
A_A^A]A\_^[]
>v<I+
(t$@f
|$`H+
(D$0f
(t$@f
|$`H+
(D$Pf
@USVWATAUAVAWH
A_A^A]A\_^[]
>v<I+
(t$@f
|$`H+
(D$0f
(t$@f
|$`H+
(D$Pf
@USVWATAUAVAWH
A_A^A]A\_^[]
>v<I+
(t$@f
|$`H+
(D$0f
(t$@f
|$`H+
(D$Pf
@USVWATAUAVAWH
A_A^A]A\_^[]
>v<I+
(t$@f
|$`H+
(D$0f
(t$@f
|$`H+
(D$Pf
@SUVWATAVAWH
I#W0H
0A_A^A\_^][
I#W0H
(D$ f
I#w0H
UVWAVAWH
 A_A^_^]
UVWATAUAVAWH
C(H+C H
C@H+C8H
A_A^A]A\_^]
@SUVWATAUAVAWH
\$8I+7H
A_A^A]A\_^][
\$ UVWATAUAVAWH
D$xH+
D$xH+
D$xH+
L$`H;
L$`H;
A_A^A]A\_^]
l$ VWAVH
C8H9C0u
C8H9C0u
C8H9C0u
C8H9C0u
H9q8vb
C8H9C0u
@SUWAVAWH
 A_A^_][
@USVWATAUAVAWH
A_A^A]A\_^[]
@WATAUH
|$0L+
PA]A\_
PA]A\_
\$ UVWATAUAVAWH
A_A^A]A\_^]
L$8H3
L$8H3
UVWATAUAVAWH
Bv@L+
A_A^A]A\_^]
UVWATAUAVAWH
NvLL+
A_A^A]A\_^]
UWAVH
D$0H+
D$HH+
D$`H+
UWAVH
D$0H+
D$HH+
D$`H+
@USVWATAUAVAWH
L$pI+
A_A^A]A\_^[]
@USVWATAUAVAWH
L$pI+
A_A^A]A\_^[]
@USVWATAUAVAWH
L$pI+
A_A^A]A\_^[]
@USVWATAUAVAWH
L$pI+
A_A^A]A\_^[]
@USVWATAUAVAWH
L$pI+
A_A^A]A\_^[]
@USVWATAUAVAWH
L$pI+
A_A^A]A\_^[]
|$(Mc
|$(Hc
@SVWATH
XA\_^[
XA\_^[
|$(Hc
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
UVWAVAWH
L$XE3
A_A^_^]
@USVWAVH
T$@E3
A^_^[]
@USVWATAUAVAWH
Lct$h3
D$xL;
D$pH+
HcL$hH;
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@SUVWAVAWH
(A_A^_^][
(A_A^_^][
UVWATAUAVAWH
D$@H+
D$0E3
A_A^A]A\_^]
@USVWATAVAWH
\$@I;
A_A^A\_^[]
|$ UH
@SVWAVAWH
0A_A^_^[
UVWATAUAVAWH
A_A^A]A\_^]
SATAUAVAWH
F I+F
0A_A^A]A\[
|$ UH
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
VWAWH
l$hH+
 A__^
|$ AVH
|$(A^
|$ AVH
|$(A^
VWAWH
l$hH+
 A__^
|$ AVH
|$(A^
|$ AVH
|$(A^
@USVWAVH
A^_^[]
@USVWAVH
A^_^[]
@USVWAVH
A^_^[]
@USVWAVH
A^_^[]
UVWATAUAVAWH
 A_A^A]A\_^]
t$ UWAVH
\$ UVWATAUAVAWH
p H+p
A_A^A]A\_^]
UVWATAUAVAWH
X I+X
A_A^A]A\_^]
D$0E3
@USVWATAUAVAWH
A_A^A]A\_^[]
@SVWH
@USVWATAVAWH
A_A^A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
xcfff
A_A^A]A\_^]
@SVWH
@USVWATAUAVAWH
A_A^A]A\_^[]
l$ VWATAVAWH
A_A^A\_^
T$ M;
@SUVWAUAVAWH
0A_A^A]_^][
0A_A^A]_^][
0A_A^A]_^][
0A_A^A]_^][
0A_A^A]_^][
@SUVWAUAVAWH
0A_A^A]_^][
0A_A^A]_^][
0A_A^A]_^][
0A_A^A]_^][
0A_A^A]_^][
ATAUAWH
t$ fff
0A_A]A\
ATAUAWH
t$ fff
0A_A]A\
ATAUAWH
t$ fff
0A_A]A\
H;t$p
H;t$p
H;t$p
H;t$p
ATAUAWH
t$ fff
0A_A]A\
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
UVWATAUAVAWH
uiI;F
A_A^A]A\_^]
@SVWATAUAVAWH
T$HM+
t#fff
L$pH3
A_A^A]A\_^[
UWAVH
T$hH;
D$8H+
D$PH+
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
|$ UH
@SUVWAVH
L$`H3
pA^_^][
@USVWAVH
@ H+A
A^_^[]
|$ UH
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A\_^[]
@SVWATAUAVAWH
tofff
|$0I;
PA_A^A]A\_^[
SVWATAUAVAWH
0A_A^A]A\_^[
@SVWATAUAVAWH
t$0Mi
t$ I;
`A_A^A]A\_^[
@SUVWAVH
@A^_^][
l$ VWAVH
0A^_^
IhH+KXH
gfffffffH
fffffff
CPH+C@H
t$8H+
t$8H+
t$8H+
UWAVH
t$HH+
 A^_]
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWAVAWH
A_A^_^]
@USVWATAVAWH
\$0E9`
A_A^A\_^[]
\$ UVWATAUAVAWH
E H;E(t
E H;E(t
A_A^A]A\_^]
UVWATAUAVAWH
EPI+EHH
t$@E3
D$HH+
EhI+E`H
T$`H;
T$`H;
A_A^A]A\_^]
D$HH+
t$ UWAVH
UVWATAUAVAWH
T$@E3
V`I;VhtgL
D$XH+
D$HE3
V`I;VhtzL
A_A^A]A\_^]
@SUVWATAVAWH
A_A^A\_^][
UVWATAUAVAWH
T$HE3
U I+U
t$@E3
A_A^A]A\_^]
UVWAVAWH
P H+P
WHH;WPt
A_A^_^]
\$ UVWAVAWH
L$XHc
A_A^_^]
l$ WAVAWH
t$HH+
 A_A^_
l$ WAVAWH
t$HH+
 A_A^_
t$ WATAUAVAWH
|$HI;
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
\$ WH
D$ L;
T$ H;
L$`H3
L$0I;
L$0I;
L$ H3
(D$ f
L$hH3
L$hH3
L$pH3
L$xH3
L$xH3
L$xH3
l$ VH
T$ H;
T$ H;
T$`H;
T$`H;
VWATAVAWH
\$ H;
D$HH;
A_A^A\_^
VWATAVAWH
d$ H;
D$HH;
A_A^A\_^
UAVAWH
J0L9rPH
A_A^]
VWATAVAWH
D$dfff
A_A^A\_^
t$ UH
VWATAVAWH
L$1B8
A_A^A\_^
D$ H;
VWATAVAWH
L$1B8
A_A^A\_^
UAVAWH
J0L9rPH
A_A^]
D$PA8
L$pH3
L$pH3
T$HA8
L$`H3
L$`H3
s WAVAWH
D$IL+
A_A^_
D$ H;
L$ H;
CT$ H
UAVAWH
J0L9rPH
A_A^]
VWATAVAWH
A_A^A\_^
UAVAWH
J0L9rPH
A_A^]
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
@USVWATAVAWH
D$0E3
L$@I+
d$ E3
A_A^A\_^[]
@USVWATAUAVAWH
D$HH+
\$ E3
A_A^A]A\_^[]
t$ UH
t$ UH
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
t$ UWAVH
UWATAVAWH
A_A^A\_]
\$ UVWATAUAVAWH
I9uHt
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
T$@H;
T$@H;
p AWH
(t$`H
p AWH
(t$`H
@SUVWATAUAVAWH
hA_A^A]A\_^][
\$ UVWAVAWH
S H;S(t
L$@H3
PA_A^_^]
|$ UH
|$ UH
@USVWATAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A\_^[]
UVWAVAWH
PA_A^_^]
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
H9C8u
E I+E
d$`E3
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
D$PH+
D$PH+
|$8I;
A_A^A]A\_^[]
@SVWH
H+Q H
GhL;O
\$ UVWAVAWH
L9yPA
S H;S(t
L$@H3
PA_A^_^]
@SUVWH
8_^][
t$xE3
H;T$`|
8_^][
\$ UVWH
t$ WH
t$ WH
t$ WH
@SUVWATAVAWH
`A_A^A\_^][
@SUVWATAVAWH
`A_A^A\_^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
UWAVH
@USVWATAUAVAWH
A_A^A]A\_^[]
\$ UVWATAUAVAWH
H9C@u
Dt$PH
f M+f
3333333
\$HE3
\$HE3
gfffffffH
A_A^A]A\_^]
\$ UVWATAUAVAWH
W I;W(t
A_A^A]A\_^]
t$ AWH
gfffffffH+
UWAVH
\$ UVWATAUAVAWH
A_A^A]A\_^]
av_H+
\vZH+
\vZH+
L$(H3
L$(H3
UWAVH
UWAVH
UWAVH
UWAVH
x UATAUAVAWH
(t$@f
l$0H+
(D$Pf
(D$Pf
(L$@f
(D$0f
A_A^A]A\]
x UATAUAVAWH
(t$@f
l$0H+
(D$Pf
(D$Pf
(L$@f
(D$0f
A_A^A]A\]
x UATAUAVAWH
(t$@f
l$0H+
(D$Pf
(D$Pf
(L$@f
(D$0f
A_A^A]A\]
x UATAUAVAWH
(t$@f
l$0H+
(D$Pf
(D$Pf
(L$@f
(D$0f
A_A^A]A\]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
x UATAUAVAWH
(t$@f
l$`H+
(D$0f
(D$0f
(L$@f
(D$`f
(t$@f
l$`H+
(D$Pf
E H;E(u_L
tBfff
A_A^A]A\]
x UATAUAVAWH
(t$@f
l$`H+
(D$0f
(D$0f
(L$@f
(D$`f
(t$@f
l$`H+
(D$Pf
E H;E(u`L
A_A^A]A\]
x UATAUAVAWH
(t$@f
l$`H+
(D$0f
(D$0f
(L$@f
(D$`f
(t$@f
l$`H+
(D$Pf
E H;E(u`L
A_A^A]A\]
x UATAUAVAWH
(t$@f
l$`H+
(D$0f
(D$0f
(L$@f
(D$`f
(t$@f
l$`H+
(D$Pf
E H;E(u`L
A_A^A]A\]
\$ UH
(D$0f
(L$@f
\$ UH
(D$0f
(L$@f
\$ UH
(D$0f
(L$@f
\$ UH
(D$0f
(L$@f
@SUVWATAVAWH
)D$0A
)L$PL
)D$PA
)L$0L
A_A^A\_^][
@SUVWATAVAWH
)D$0A
)L$PL
)D$PA
)L$0L
A_A^A\_^][
@SUVWATAVAWH
)D$0A
)L$PL
)D$PA
)L$0L
A_A^A\_^][
@SUVWATAVAWH
)D$0A
)L$PL
)D$PA
)L$0L
A_A^A\_^][
UVWATAUAVAWH
p L+p
A_A^A]A\_^]
HcD$@L
D$ E3
UVWATAUAVAWH
p L+p
A_A^A]A\_^]
HcD$@L
D$ E3
UVWATAUAVAWH
p L+p
A_A^A]A\_^]
HcD$@L
D$ E3
UVWATAUAVAWH
p L+p
A_A^A]A\_^]
HcD$@L
D$ E3
B H+B
UWAWH
 A__]
@USVWATAUAVAWH
L$0I+
A_A^A]A\_^[]
@USVWATAUAVAWH
L$0I+
A_A^A]A\_^[]
@USVWATAUAVAWH
L$0I+
A_A^A]A\_^[]
@USVWATAUAVAWH
L$0I+
A_A^A]A\_^[]
l$ VWAVH
l$ VWAVH
l$ VWAVH
UWAVH
USVWAVAWH
T$`H;
A_A^_^[]
UVWATAUAVAWH
A_A^A]A\_^]
|$ UH
D$0H+
D$HH+
@USVWAUAVAWH
A_A^A]_^[]
@USVWAUAVAWH
A_A^A]_^[]
USVWAWH
A__^[]
USVWAWH
A__^[]
@USVWAUAVAWH
A_A^A]_^[]
@USVWAVH
`A^_^[]
L$hH3
\$ UVWAVAWH
pA_A^_^]
\$ UVWAVAWH
pA_A^_^]
\$ UVWAVAWH
pA_A^_^]
\$ UVWAVAWH
pA_A^_^]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
l$ AVAWH
l$0A_A^
t$ A^
t$ A^
l$ AVAWH
l$0A_A^
l$ AVAWH
l$0A_A^
t$ A^
t$ A^
l$ AVAWH
l$0A_A^
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
VWATAVAWH
D$(H;
|$ H;
0A_A^A\_^
VWATAVAWH
D$(H;
|$ H;
0A_A^A\_^
VWATAVAWH
D$(H;
|$ H;
0A_A^A\_^
VWATAVAWH
D$(H;
|$ H;
0A_A^A\_^
@USVWATAUAVAWH
eoL9 
A_A^A]A\_^[]
@USVWATAUAVAWH
eoL9 
A_A^A]A\_^[]
@USVWATAUAVAWH
eoL9 
A_A^A]A\_^[]
@USVWATAUAVAWH
eoL9 
A_A^A]A\_^[]
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
z3u1I;
z5u3I;
z3u1I;
z5u3I;
@SVATAUAWH
|$8H+
sXfff
@A_A]A\^[
@SVATAUAWH
|$8H+
s\fff
@A_A]A\^[
@SVATAUAWH
|$8H+
sXfff
@A_A]A\^[
@SVATAUAWH
|$8H+
s\fff
@A_A]A\^[
\$ UVWAVAWH
\$HA_A^_^]
\$HA_A^_^]
A_A^_^]
\$ UVWAVAWH
\$HA_A^_^]
\$HA_A^_^]
A_A^_^]
\$ UVWAVAWH
\$HA_A^_^]
\$HA_A^_^]
A_A^_^]
\$ UVWAVAWH
\$HA_A^_^]
\$HA_A^_^]
A_A^_^]
@SUVWAUAVH
sJfff
L$8H3
HA^A]_^][
\$ UVWAVAWH
0A_A^_^]
0A_A^_^]
\$ UVWAVAWH
0A_A^_^]
0A_A^_^]
@SUVWAUAVH
sLfff
L$8H3
HA^A]_^][
@SUVWAUAVH
sJfff
L$8H3
HA^A]_^][
\$ UVWAVAWH
0A_A^_^]
0A_A^_^]
\$ UVWAVAWH
0A_A^_^]
0A_A^_^]
@SUVWAUAVH
sLfff
L$8H3
HA^A]_^][
WAVAWH
l$PH+
sJfff
L$ H3
0A_A^_
WAVAWH
l$PH+
sLfff
L$ H3
0A_A^_
WAVAWH
l$PH+
sJfff
L$ H3
0A_A^_
WAVAWH
l$PH+
sLfff
L$ H3
0A_A^_
VWAVH
\$PI;
D9G vu
T$XH+
L$`H3
@VATAVH
\$ A^A\^
VWAVH
|$PI;
D9K vr
T$XH+
L$`H3
@VATAVH
\$ A^A\^
t$(M;
k0L9{
L$@H3
VWAVH
\$PI;
D9G vu
T$XH+
L$`H3
VWAVH
\$PI;
D9G vu
T$XH+
L$`H3
t$(M;
L$@H3
t$(M;
L$@H3
@VATAVH
\$ A^A\^
VWAVH
\$PI;
D9G vu
T$XH+
L$`H3
@VATAVH
\$ A^A\^
t$(M;
tufff
L$@H3
VWAVH
|$PI;
D9K vs
T$XH+
L$`H3
t$(M;
k0L9{
tufff
L$@H3
t$(M;
k0L9{
L$@H3
t$(M;
k0L9{
tufff
L$@H3
VWAVH
|$PI;
D9K vr
T$XH+
L$`H3
VWAVH
|$PI;
D9K vs
T$XH+
L$`H3
t$(M;
L$@H3
@USVWATAVAWH
A_A^A\_^[]
@VATAVL
\$ A^A\^
@VATAVL
\$ A^A\^
@VATAVL
\$ A^A\^
@VATAVL
\$ A^A\^
D$xE3
UVWAVAWH
A_A^_^]
@SUAVH
@A^][
\$ UVWATAUAVAWH
F H+F
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
L$0L;
D$hH;
\$ UVWAVAWH
A_A^_^]
UWAVH
UWAVH
SVWATAUAVAWH
UUUUUUU
@A_A^A]A\_^[
t$8H+
\$ UVWATAUAVAWH
H9w@t
A_A^A]A\_^]
\$ UVWATAUAVAWH
8T$aL
A_A^A]A\_^]
\$ UVWATAUAVAWH
\$ I+\$
~ H+~
t$hE2
D$HH;
UUUUUUU
3333333
L$`E3
gfffffffH
A_A^A]A\_^]
t$ UWAUAVAWH
A_A^A]_]
|$ E3
l$ WAVAWH
t$HH+
 A_A^_
VWAVH
UUUUUUU
 A^_^
UWAVH
@USVWATAUAVAWH
D$@HcH
D$@HcH
D$@HcH
L$@HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
\$ UVWATAUAVAWH
L9qXt
A_A^A]A\_^]
@SUVWATAVAWH
S H;S(H
L$PH3
`A_A^A\_^][
@SUVWATAUAVAWH
A_A^A]A\_^][
UWAVH
H;]'|
H;E'|
SUVWATAUAVAWH
T$ H;
T$pH;
A_A^A]A\_^][
SUVWATAUAVAWH
T$ H;
T$pH;
A_A^A]A\_^][
SUVWATAUAVAWH
T$PH;
A_A^A]A\_^][
SUVWATAUAVAWH
T$PH;
A_A^A]A\_^][
t$ WATAUAVAWH
D$0Hc
A_A^A]A\_
t$ UWAVH
t$ UWAVH
t$ UWAVH
t$ UWAVH
(t$0L
WAVAWH
)t$ L
0A_A^_
WAVAWH
)t$ L
W(fff
0A_A^_
ATAVH
)D$0H
F(fff
(t$PL
|$ ATAVAWH
)t$ L
0A_A^A\
(t$0L
|$ ATAVAWH
)t$ L
0A_A^A\
ATAVH
)D$0H
(t$PL
\$ UVWATAUAVAWH
D$HH+
D$8E3
A_A^A]A\_^]
\$ UVWATAUAVAWH
D$HH+
D$`H+
D$PE3
A_A^A]A\_^]
\$ UVWATAUAVAWH
D$HH+
D$8E3
A_A^A]A\_^]
\$ UVWATAUAVAWH
D$HH+
D$`H+
D$PE3
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
(t$ H
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@SVWATAUAVAWH
gfffffffI
fffffff
D$0I;
t$pI;
gfffffffH
A_A^A]A\_^[
UVWATAUAVAWH
)t$`M
(D$ f
(t$`H
pA_A^A]A\_^]
UVWATAUAVAWH
)t$`M
(D$ f
(t$`H
pA_A^A]A\_^]
t$ UWATAVAWH
A_A^A\_]
gfffffffH
t$ WH
X UVWATAUAVAWH
D$8Lc
HcD$8H
A_A^A]A\_^]
@SUVWH
t$ WH
t$ WH
t$ WH
@SUVWATAVAWH
tfH;=
T$PH;
T$PH;
A_A^A\_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
D$0Hc
(|$PH
UVWAVAWH
)|$PM
|$0Lc
(|$PH
pA_A^_^]
VWATAVAWH
)|$`D
)D$PM
|$0E3
(|$`E
A_A^A\_^
Lc\$@E3
)D$pD
)L$`D
)T$PD
)\$@D
)d$0D
)l$ D
(l$ D
(d$0D
(\$@D
(T$PD
(L$`D
)D$pD
)L$`D
)T$PD
)\$@D
)d$0D
)l$ D
(l$ D
(d$0D
(\$@D
(T$PD
(L$`D
UVWAVAWH
)|$PM
|$0Mc
(|$PH
pA_A^_^]
)l$ D
)<$Mc
)4$Mc
(|$pL
HcT$xL
d$`Mc
t$ WHc|$0E3
D$@Hc
D$ E3
L$@H3
HcL$0M
 Hcl$PI
 Hcl$PI
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
t$ WAVAWH
 A_A^_
UVWAVAWH
L$(E3
D$(I+
T$8I+
L$@H3
PA_A^_^]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
SVWATAUAVAWH
gfffffffI
fffffff
0A_A^A]A\_^[
@SVWATAUAVAWH
t$pI;
A_A^A]A\_^[
\$ UH
|$@fff
SVWAVAWH
fffffff
gfffffffI
0A_A^_^[
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
t$ WAVAWH
D$0A9
F8I+F(H
FPI+F@H
F0I;F8t
FHI;FPt
A_A^_
VWAVH
t$ WAVAWH
D$@H+
L$PH3
A_A^_
A`H9Ah
H;C`t
AhH;A`}p
\$ UVWATAUAVAWH
f9PNu$
L$HH3
PA_A^A]A\_^]
UVWATAUAVAWH
t$0E3
A_A^A]A\_^]
@USVWAVH
A^_^[]
@USVWATAUAVAWH
u/H;u
A_A^A]A\_^[]
t$ WAVAWH
t$@I;
\$@H;W
 A_A^_
t$ WAVAWH
t$@H;S
D$@H;S
t$@H;S
 A_A^_
s WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
A_A^A]A\_^]
t$ UWATAVAWH
A_A^A\_]
@USVWATAUAVAWH
t$PHc
t$PE3
d$xL9
H;C`t
(L;|$`L
gfffffffH
t$PE3
|$xH;
A_A^A]A\_^[]
\$ VWAVH
`A^_^
@SUVWAVH
D$HH;
A^_^][
L$0I;
UAUAVH
H#E0H
L;|$8t
L9l$(
L9l$(u
H#E0L
`A^A]]
\$ VH
gfffffffI
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SUVWAVAWH
L$(E3
T$@H;
A_A^_^][
L$PMc
X UVWATAUAVAWH
)D$pf
LcG$A
A_A^A]A\_^]
X UVWATAUAVAWH
)D$pf
LcG$A
A_A^A]A\_^]
\$ UVWAVAWH
L$xE3
T$0H;
A_A^_^]
UVWAVAWH
0A_A^_^]
@SUVWAUAWH
C(D98
u[G9<3uUH
D;8|tH
D;<)|dH
C(D;8
A_A]_^][
@SUVWAUAWH
C(D98
u[G9<3uUH
D;8|tH
D;<)|dH
C(D;8
A_A]_^][
LcA$H
D$PLc
D$`Lc
D$pLc
@SUWAWH
D$xLc
D$@D9
HcW$C
HcO$L
Hc_$H
LcG$H
Hc_$H
LcG$H
Hc_$H
LcG$H
HcO$H
A__][
D$8H+
D$8H+
E;X$|
LcI$L
t$ WL
VWATAVAWH
@A_A^A\_^
VATAUAVAWH
 A_A^A]A\^
@SUVWAVAWH
HA_A^_^][
)D$ A
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SLcT$pLc\$XHc\$HL
t$ WH
L$hH3
@UVATAWH
l$8M9L$
L$(fH
T$(H+
T$HE3
A_A\^]
@SVWATAUAVAWH
L$(H3
@A_A^A]A\_^[
@SVWATAUAVAWH
L$(H3
@A_A^A]A\_^[
l$ AVL
l$(A^
l$(A^
l$ AVL
l$(A^
l$(A^
@UWAVH
e`A^_]
@UAVAWH
A_A^]
@UAVAWH
A_A^]
t$ UWAVH
t$ UWAVH
@SUVWAVH
Authu
entiu
cAMDt
AMDiuE
sbetu=
ter!u53
0A^_^][
UVWATAUAVAWH
t$0L;
A_A^A]A\_^]
@SUVATAUAVAWH
A_A^A]A\^][
UVWATAUAVAWH
|$xL+
D$PH+
t$0H;
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
t$(L;
t$(L;
@VWAVH
|$0ff
t$ H;
\$pI;
PA^_^
ATAVAWH
\$0M;
A_A^A\
\$8H;
H9l$@}
t$(H;
|$PM;
\$ WH
BA99u
@USVWAVH
A^_^[]
A^_^[]
@UVWATAUAVAWH
A_A^A]A\_^]
@UVWATAUAVAWH
A_A^A]A\_^]
WATAUAVAWH
L$(E3
L+d$0
L+l$0L
T$(L+
$L;l$P
|$8I;
|$8I;
A_A^A]A\_
AUAVAWH
D$ L;T$8
L;T$X
$$L;T$`
L;T$h
l$pM;
\$(L;
A_A^A]
WATAUAVAWH
L$8E3
H+L$ f
l$ L;
L+\$ I
$L;t$8
D$XL+
l$XL;t$`
L;t$h
l$0L;t$h
L;t$p
d$pM+
A_A^A]A\_
@SVAVH
D$PfE
|$(I+
L;\$P
L;\$`
L;\$h
L;\$p
H+D$8
L;\$x
|$(I+
L;\$@
t$0L;
L;\$@
L$XL;
WATAUAVAWH
T$ I;
L+,$L+
T$ L;l$0
L+4$H
l$8I;
0L+4$L+
L;l$H
L$(I;
t$PL;l$H
A_A^A]A\_
AUAVAWH
D$ L;T$8
L;T$X
$$L;T$`
L;T$h
l$pM;
\$(L;
A_A^A]
L$hH3
t$ WH
|$ UH
L$@H3
|$ AVH
L$(H3
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@SUVWATAVH
(A^A\_^][
(A^A\_^][
@SVWATAUAVAWH
\$ I;
PA_A^A]A\_^[
@UVAVH
0A^^]
@SVWH
L+I L
t$ WH
UVWAVAWH
D$(E3
t$`H+
L$pH3
A_A^_^]
L$8H3
\$ WH
D$HH+
t$ WH
L$(H3
t$ WH
L$PH3
L$(H3
L$HH3
VWAVH
0A^_^
L$ E3
t$ AVH
D$0I;
L$(H3
D$0H;
\$0M;
VWAVH
CT$8L
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
t$ WATAUAVAWH
A_A^A]A\_
SVWATAUAVAWH
L$0I+
L+l$8I
`A_A^A]A\_^[
`A_A^A]A\_^[
@SUVWATAVAWH
I#W0H
0A_A^A\_^][
I#W0H
(D$ f
I#w0H
UVWATAUAVAWH
D$4fD
t$4fD
A_A^A]A\_^]
t$@H+
|$Hfff
l$@H+
H#G0H
L$(H3
B 9A 
A 9B 
L$`H3
L$`H3
L$`H3
L$`H3
L$`H3
L$`H3
L$`H3
L$`H3
L$`H3
L$`H3
L$`H3
L$`H3
L$`H3
L$`H3
L$`H3
H#C0H
L$`H3
T$ H;
\$ UVWH
UVWATAUAVAWH
D$(L;
@A_A^A]A\_^]
@USVWATAVAWH
\$PE3
A_A^A\_^[]
l$ VWATAVAWH
D$(L;
A_A^A\_^
\$ UVWAVAWH
A_A^_^]
L$@H3
@SVWH
L$8H3
@SUVWAVH
L$8H3
@A^_^][
@SUVWAVH
A^_^][
@SUVWAVH
L$8H3
@A^_^][
VWATAVAWH
0A_A^A\_^
L$(H3
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
\$ VWATAVAWH
T$@H;
A_A^A\_^
@SUVWAVAWH
HA_A^_^][
@SUVWAVH
@A^_^][
L$ H3
@SUVWATAVAWH
A_A^A\_^][
@SUVWAVAWH
8A_A^_^][
UVWAVAWH
 A_A^_^]
@USVWATAVAWH
L$HE3
A_A^A\_^[]
@USVWATAVAWH
A_A^A\_^[]
@USVWATAUAVAWH
D$PI;
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
t$ WH
|$ AVH
t9fff
UVWATAUAVAWH
A_A^A]A\_^]
L$HH3
@SVWH
L$8H3
@USVWATAVAWH
A_A^A\_^[]
@USVWATAVAWH
D$@H+
D$`H+
A_A^A\_^[]
@USVWATAVAWH
D$@H+
D$`H+
A_A^A\_^[]
@USVWATAVAWH
D$@H+
A_A^A\_^[]
@UVWATAUAVAWH
D$@H+
D$`H+
A_A^A]A\_^]
@USVWATAVAWH
D$@H+
D$`H+
A_A^A\_^[]
@USVWATAUAVAWH
T$@H+
A_A^A]A\_^[]
@UVWATAUAVAWH
D$Hff
L$`L;
D$@H+
A_A^A]A\_^]
@USVWATAUAVAWH
D$`H+
D$@H+
A_A^A]A\_^[]
t$ WH
L$(H3
@USVWAVAWH
A_A^_^[]
@USVWAVH
D$@H+
A^_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USWH
|$ AVH
t$@Ik
L$0M+
\$ UVWATAUAVAWH
3333333
d$8E3
(D$ f
PA_A^A]A\_^]
@USVWATAUAVAWH
I#M0H
A_A^A]A\_^[]
t)H;V
@USVWAVAWH
A_A^_^[]
@SVWATAUAVAWH
t$0Hk
t$ I;
|$PH+
pA_A^A]A\_^[
t$ WATAUAVAWH
A_A^A]A\_
t$ WH
UVWATAUAVAWH
|$ E3
A_A^A]A\_^]
|$ UATAUAVAWH
d$ E3
t$ E3
A_A^A]A\]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@SVWH
T$HH+
T$HI+
L$PH3
T$HI+
@SUVWATAUAVAWH
L$0E3
L$8H3
HA_A^A]A\_^][
t$ ATAVAWH
 A_A^A\
@USVWATAUAVAWH
gfffffffH
A_A^A]A\_^[]
@SUVWAVAWH
L$PH3
hA_A^_^][
@USVWATAUAVAWH
gfffffffH
A_A^A]A\_^[]
t$ WH
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
gfffffffI
fffffff
A_A^A]A\_^[]
\$ UVWATAUAVAWH
gfffffffH
x0M+x(I
A_A^A]A\_^]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWAVAWH
A_A^_^]
L9@ s
L;A r
tionProvH
CPUExecuH9
VitisAIEH9
xecutionH9H
ProviderH9H
ACLExecuH9
UWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
L$ H3
@SUVWH
|$ L;
(_^][
t"fff
(_^][
t$ WATAUAVAWH
A_A^A]A\_
VWATAVAWH
D$@L;
D$@H;
L$`H3
A_A^A\_^
UAUAVH
L$0M;
L$@H3
pA^A]]
@SVWH
@SUVWATAUAVAWH
L$ H+
8A_A^A]A\_^][
@SUVWATAUAVAWH
\$ L;
8A_A^A]A\_^][
@SUVWAVAWH
L$PH3
hA_A^_^][
t$ WAVAWH
\$0E3
)D$ L
A_A^_
|$ UAVAWH
A_A^]
\$ UVWH
\$ WH
WATAUAVAWH
0A_A^A]A\_
L9A s
uFL;B r@I
L9A s
L;B s
L$(9J(
L9A s
uKL;B rELcL$(I
L9I s
L;J s
t$ UWAVH
@A^_]
@SVWH
\$ WH
\$ WH
@SUVWH
t$0H;
8_^][
H;HHs`H
@SUVWAVH
D$ E3
T$0H+
@A^_^][
@SUVWAVH
T$0H+
@A^_^][
@SUVWAVH
A^_^][
@SVWH
@SVWH
@SVWH
@SVWH
@SVWH
\$ AVH
D$0H;S
@SUVWATAUAVAWH
XA_A^A]A\_^][
\$ AVH
L$0H;S
WAVAWH
 A_A^_
t$ WATAUAVAWH
t$pA8h
D9h0t
H,A;I
H(A;I
I;6ugD;j
T$ D9j0t
B,A;G
B(A;G
udE;n0t
A;F,t
A;F(t
A_A^A]A\_
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
fffffff
d$ E3
H#U0H
(D$ f
H#}0H
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
fffffff
d$ E3
H#U0H
(D$ f
H#}0H
@SUVWATAUAVAWH
XA_A^A]A\_^][
UVWAVAWH
\$XE3
A_A^_^]
H#C0H
UVWATAUAVAWH
$H9D$0
)D$pL
VXI;V`t)L
A_A^A]A\_^]
@UAVH
H#E0L
L$(H3
A9Y0t
A,A;@
A(A;@
A;C0t
A;C,t
A;C(t
@SUVWATAUAVAWH
A_A^A]A\_^][
\$ UVWATAUAVAWH
fD9IN
FM8AM
FL8AL
GNf9AN
GM8AM
GL8AL
A_A^A]A\_^]
@SUVWATAUAVAWH
A_A^A]A\_^][
\$ UVWATAUAVAWH
fD9IN
FM8AM
FL8AL
GNf9AN
GM8AM
GL8AL
A_A^A]A\_^]
@SVWH
L$(H3
T$0E3
T$0D9R0t
A;A0t
A;A,t
A;A(t
)D$ L
@SVWATAUAVAWH
t$0I;
`A_A^A]A\_^[
A,A;B
A(A;B
A;A,t
A;A(t
D;J0t
A9X0t
@,A;B
@(A;B
A;C0t
A;C,t
A;C(t
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
\$ VH
l$8H+
UVWAVAWH
|$ L;
PA_A^_^]
UVWAVAWH
|$ L;
PA_A^_^]
UVWAVAWH
|$ L;
PA_A^_^]
@SUVWH
L$@H3
X_^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWH
H#CXH
@USVWATAUAVAWH
A_A^A]A\_^[]
l$ VWATAVAWH
)D$pL
A_A^A\_^
t$ UWAVH
l$ VWAVH
t_fff
L$0H3
@A^_^
\$ UVWAVAWH
A_A^_^]
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
L$8L;l$P
t$HI+
A_A^A]A\_
@SUVWATAUAVAWH
L$ E3
)D$ L
XA_A^A]A\_^][
l$ WATAVH
u-fff
 A^A\_
\$ UVWATAUAVAWH
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
I#W0H
(D$ f
I#w0H
@SUVWAVH
PA^_^][
UVWATAUAVAWH
t$0L;
C\$0H
t$0L;
C\$0H
A_A^A]A\_^]
USVWAVH
A^_^[]
UWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
@SUVWATAUAVAWH
A_A^A]A\_^][
@USVWATAUAVAWH
t$hI;
D$PH;D$Xt
D$PH9D$H
|$PH;
T$XH+
|$PH;
T$XH+
A_A^A]A\_^[]
|$PH;
T$XH+
H#C@H
\$ UVWATAUAVAWH
D$pHcH
D$pHcH
D$pHcH
D$pHcH
L$hH;
|$hE3
D$pHcH
D$pHcH
D$pHcH
D$pHcH
A_A^A]A\_^]
@UAVH
H#E0L
L$(H3
t$ WI
@SUVWATAVAWH
H#U0H
0A_A^A\_^][
H#U0H
(D$ f
H#}0H
@USVWATAVAWH
T$0E3
L9H s
L;I r
A_A^A\_^[]
@USVWATAUAVAWH
L$hL;
T$hH;
L9p s
L;q r
A_A^A]A\_^[]
|$8H;
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
WATAUAVAWH
D$ H;S
l$0M;
L$8H3
@A_A^A]A\_
WATAUAVAWH
D$ H;S
l$0M;
L$8H3
@A_A^A]A\_
WATAUAVAWH
D$(H;S
l$(M;
L$0H3
@A_A^A]A\_
VWATAUAWH
l$(H;S
t$ M;
L$0H3
@A_A]A\_^
WATAUAVAWH
D$(H;S
l$ M;
L$0H3
@A_A^A]A\_
d$0I;Q
L$0H;W
D$0H;U
D$(H;S
D$0H;W
L$8H3
L$8H3
d$0I;Q
t$Hfff
L$0H;W
D$0H;U
D$(H;S
D$0H;W
L$8H3
L$8H3
d$(I;Q
t$Hfff
L$(H;W
D$(H;U
D$(H;S
D$ H;W
L$0H3
L$0H3
d$(I;Q
t$Hfff
L$(H;V
D$(H;U
|$(H;S
D$(H;V
L$0H3
L$0H3
d$(I;Q
t$Hfff
L$(H;W
D$(H;U
D$(H;S
D$(H;W
L$0H3
L$0H3
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
l$ VWAVH
0A^_^
@USVWATAUAVAWH
L$AE3
E I+E
A_A^A]A\_^[]
@USVWATAUAVAWH
@ I+@
L$AE3
A_A^A]A\_^[]
@USVWATAUAVAWH
D$hL;
T$hI;
A_A^A]A\_^[]
@USVWATAUAVAWH
D$`L;
A_A^A]A\_^[]
t$ WH
@SUVWAVH
L$ E3
L$(H3
0A^_^][
@SUVWAVH
L$ E3
L$(H3
0A^_^][
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
\$ UVWH
\$ UVWH
\$ UVWH
\$ UVWH
@SUVWH
L$`H3
x_^][
@SUVWH
L$`H3
x_^][
@SUVWH
L$`H3
x_^][
@SUVWH
L$`H3
x_^][
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SVWAVH
L$`H3
xA^_^[
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SUVWH
L$`H3
x_^][
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SVWAVH
L$`H3
xA^_^[
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SVWAVH
L$`H3
xA^_^[
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
\$ VH
l$hHc
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
\$ VH
l$hHc
\$ WH
H;L$xt
D$(I;
D$ I;
L$0H3
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SVWAVH
L$`H3
xA^_^[
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SVWAVH
L$`H3
xA^_^[
H;L$ht*
SVWATAUAVAWH
T$0I+
T$@I+
PA_A^A]A\_^[
PA_A^A]A\_^[
SVWATAUAVAWH
T$0I+
T$@I+
PA_A^A]A\_^[
PA_A^A]A\_^[
SVWATAUAVAWH
T$0I+
T$@I+
PA_A^A]A\_^[
PA_A^A]A\_^[
@WATAVAWH
l$ E3
8A_A^A\_
@SUVWAVH
@A^_^][
@SUVWAVH
 A^_^][
 A^_^][
9B(uzH
A H;B up
\$ 9B(uNH
L$0H3
@SUVWAVAWH
A_A^_^][
UVWATAUAVAWH
(D$@f
(D$@f
(D$@f
(D$@f
L;|$H
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
VWAVH
L$@H3
PA^_^
@USVWH
@USVWATAUAVAWH
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
D$PH;
A_A^A]A\_^[]
\$ UVWAVAWH
L$8H3
@A_A^_^]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWAVAWH
A_A^_^]
VWATAVAWH
L$`E3
H;|$`
L$hH3
A_A^A\_^
\$ UVWATAUAVAWH
d$8E3
v fff
(D$ f
PA_A^A]A\_^]
@USVWAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A__^[]
UVWAVAWH
A_A^_^]
VWAVH
t0H;E
@A^_^
UVWAVAWH
t$HH;
\$@@2
T$PH+
L$XH3
`A_A^_^]
t$ WH
L$8H3
t$ UWATAVAWH
A_A^A\_]
|$ AVH
@USVWATAUAVAWH
A_A^A]A\_^[]
VWATAVAWH
@A_A^A\_^
t$ WH
VWAVH
V H+V
 A^_^
@USVWAVH
A^_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
WAVAWH
A_A^_
|$ UH
UWATAVAWH
t$ E3
A_A^A\_]
@SVWATAUAVAWH
T$pE3
t$0L;
C\$0H
L$ E3
\$0E3
|$8D8{
A_A^A]A\_^[
UVWAVAWH
@A_A^_^]
\$ UVWH
@SWATH
O(+O0
H+G8H
H+G8H
O(+O0
PA\_[
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$PHcH
D$PHcH
L$PHcQ
L$PHcQ
A_A^A]A\_^[]
t$ WATAUAVAWH
l$(H9i
0A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
@SUWATAVAWH
L$ E8a
L$ I;
t$PD8c
XA_A^A\_][
"""""""
XA_A^A\_][
t$ WATAUAVAWH
A_A^A]A\_
@SVWATAUAVAWH
PA_A^A]A\_^[
A9X,t
@(A;B
A;C,t
A;C(t
l$0H;
l$0H;
\$8fff
L$HH;
L+t$P
9D$(I
L$ VWAVH
0A^_^
\$ UVWATAUAVAWH
L$`H+
|$(L;
D$0H+
|$0M;
H+L$(
t$ M;
|$0L;d$@
9D$ H
9D$ H
D$HL;
9D$ H
9D$ H
|$(L;
l$0uAL;d$@
l$0L;d$@u0H
pA_A^A]A\_^]
@SUVWATAUAVAWH
L9|$0
XA_A^A]A\_^][
t$ WATAUAVAWH
A_A^A]A\_
@SUVWAVAWH
(A_A^_^][
(A_A^_^][
\$ UVWAVAWH
L$HH3
PA_A^_^]
@SUVWATAVAWH
I#W0H
0A_A^A\_^][
fffffff
I#W0H
(D$ f
I#w0H
l$ VWAVH
T$0E3
T$0D9R,t
A;A,t
A;A(t
"""""""
)D$ L
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
H#U0H
@A_A^A]A\_^]
l$0E3
H#E0H
(D$ f
H#}0H
@UVAVH
 A^^]
@SUVWATAVAWH
I#W0H
0A_A^A\_^][
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
d$ E3
H#U0H
(D$ f
H#}0H
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
D$PE3
F0H#D$0H
(D$ f
F0H#D$0H
pA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
t$ WATAUAVAWH
(D$ f
A_A^A]A\_
t$ WATAUAVAWH
(D$ f
A_A^A]A\_
@SVWH
VWAVH
|$8H;
t$@I+
UVWATAUAVAWH
t$@I;
I#O0H
I#O0M
l$hH;
A_A^A]A\_^]
t$HH+
UVWATAUAVAWH
T$ I+T$
A_A^A]A\_^]
@USVWAVAWH
A_A^_^[]
@SUVWAVH
u$H;Q
A^_^][
uCH;Q
SUVWH
UVWATAUAVAWH
|$@H;|$x
\$`H;
T$pH+
H;|$x
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
t$ WAVAWH
D+z0A
N +N0
8NPtk
H+F8H
F D+F0D
N +N0
8NPtk
H+F8H
F D+F0D
 A_A^_
\$ UVWATAUAVAWH
NxI;Nxu
A_A^A]A\_^]
Q(+Q0
H+C8H
H+C8H;
H+C8H
C(+C0
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
L$pH+
A_A^A]A\_^[]
@USVWATAUAVAWH
T$xH;
I;\$xu
O H;O 
A_A^A]A\_^[]
@USVWAWH
D$PHcH
D$PHcH
L$PHcQ
L$PHcQ
A__^[]
\$ UVWH
fD9H6u
D8P5u
D8@4tqH
L$@H3
@SUVWAVH
@A^_^][
@A^_^][
@SUVWATAVAWH
|$ H;
@A_A^A\_^][
UVWATAUAVAWH
H9y }
D$@H9x }
vb'vb'v
)D$ L
pA_A^A]A\_^]
UVWATAUAVAWH
M(+M0
M(+M0
8MPtm
H+E8H
E(D+E0D
L$pH3
A_A^A]A\_^]
t$ WH
|$ L+
T$0H+
L$8H3
:Loopt
8Scanu
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
I#E0H
D$`E3
A_A^A]A\_^[]
UVWATAUAVAWH
D$0E3
L$pL;
T$pH;
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
H+G8H;
H+G8H;
A_A^A]A\_^[]
|$ UATAUAVAWH
T$ H;
A_A^A]A\]
Q +Q0
H;{Hv
@SUVWATAVAWH
H9q }
I;p |
D$0H9p }
H;r }cH
UUUUUUU
)D$ L
L$`H3
pA_A^A\_^][
UVWATAUAVAWH
A_A^A]A\_^]
t$8H;E
T$@H;
l$PI;
D$PH+
|$ AVH
\$ UVWH
HcT$0H
@SVWAVH
HcT$0H
A^_^[
@SAVH
I#F0M
VWAVH
 A^_^
SUAVH
H#C0I
L9t$xu?M
:L9t$xu
PA^][
H#A0H
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@SVWATAUAVAWH
gfffffffH
fffffff
gfffffffH
PA_A^A]A\_^[
WATAUAVAWH
 A_A^A]A\_
UVAWH
 A_^]
t$ WATAUAVAWH
|$ Ik
A_A^A]A\_
@USVWATAUAVAWH
A_A^A]A\_^[]
gfffffffH
t$8H+
t$ WAVAWH
 A_A^_
t$ WATAUAVAWH
A_A^A]A\_
\$ UVWH
gfffffffH
UVWATAUAVAWH
A_A^A]A\_^]
t$ WH
UWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
@USVWATAVAWH
D$PHcH
D$PHcH
L$PHcQ
L$PHcQ
A_A^A\_^[]
UVWATAUAVAWH
H9A s
UUUUUUU
HcS(H
HcC(H
A_A^A]A\_^]
X UVWATAUAVAWH
L$0L;
A_A^A]A\_^]
\$ UVWATAUAVAWH
\$0H;
A_A^A]A\_^]
L$0H3
t$ WAVAWH
fffffff
H9FDtzI
)D$0L
A_A^_
@SUVWAVH
W(H9h u0H
A^_^][
|$ UH
gfffffffH
UVWAVAWH
l$8H;
t_fff
A_A^_^]
@SVWH
UVWAVAWH
A_A^_^]
UVWATAUAVAWH
gfffffffH
D$8L;
gfffffffH
L;d$8
|$@Hc
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
u.H;C
UVWATAUAVAWH
L$@H;
ubE9g0
D$0H;D$@t
A_A^A]A\_^]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
\$HE3
@SVWATAUAVAWH
T$0I;
PA_A^A]A\_^[
\$ UVWH
t$ UWATAVAWH
A_A^A\_]
t$8H+
\$ VH
l$8H+
t$ WH
\$ UVWH
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@SUVWATAUAVAWH
L$XH3
hA_A^A]A\_^][
@USVWATAUAVAWH
T$xH+
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
t$ WH
@SVATAVAWH
l$XH+
 A_A^A\^[
VWAVH
@A^_^
VWAVH
@A^_^
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@SVWH
CD$Pf
@USVWH
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@VAVAWH
d$(E3
gfffffff
t fff
@A_A^^
@SUVH
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
l$ VWAVH
T$0E3
T$0D9R0t
A;A0t
A;A,t
A;A(t
3333333
)D$ L
@SVWATAUAVAWH
I#G0H
gfffffffH
D9J0t
A;@0t
A;@,t
A;@(t
D$PH;
A_A^A]A\_^[
UVWAVAWH
A_A^_^]
|$ UH
@USVWATAUAVAWH
C\$hH
|$ E3
A_A^A]A\_^[]
H9|$@
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
D$`I;
(D$@f
A_A^A]A\_^[]
@SUVWAVAWH
A_A^_^][
t$ WH
L$(H3
|$ AVH
H;A(s
H;H@s
@USVWATAUAVAWH
A_A^A]A\_^[]
\$ UVWATAUAVAWH
Y8H+Y0H
(H;l$0
A_A^A]A\_^]
gfffffffH
\$ UVWATAUAVAWH
gfffffffI
D$8I+D$0H
|$8I+|$0H
D$0Hc
A_A^A]A\_^]
@SVWH
L$8H3
@SVWH
L$PH3
@USVWAVH
A^_^[]
t$ WH
L$(H3
|$ UATAUAVAWH
A_A^A]A\]
t$ WH
\$ UVWATAUAVAWH
A_A^A]A\_^]
l$ VWATAVAWH
l$8H;
L$XH;
L$hH3
A_A^A\_^
l$ VWATAVAWH
D$0fH
D$xI;
A_A^A\_^
\$ UVWATAUAVAWH
A_A^A]A\_^]
UVAUI
VWATAVAWH
\$ I;
@A_A^A\_^
T$(H;
t$ WH
t$ WH
@USVWAUAVAWH
D$@H+
D$@H+
A_A^A]_^[]
@USVWAUAVAWH
D$@H+
D$@H+
A_A^A]_^[]
L$HH3
@USVWAVH
A^_^[]
@USVWAVH
A^_^[]
L$xH3
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@SVWATAUAVAWH
t$0I;
pA_A^A]A\_^[
@SUVWATAUAVAWH
XA_A^A]A\_^][
l$ VWATAVAWH
D$ I+
|$XI;
L$xH3
A_A^A\_^
t$8H+
|$8H+
@SVWH
WATAUAVAWH
L$`H;
nPM;nXtQ3
A_A^A]A\_
|$ UAVAWH
K8H9CHt
A_A^]
@USVWATAUAVAWH
E@HcH
E@HcH
E@HcH
E@HcH
M H;M(t
A_A^A]A\_^[]
@SVWATAUAVAWH
|$hE3
H9P s
H;Q r
H9P s
H;Q r
A_A^A]A\_^[
|$P@2
l$hff
|$pE3
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@SVWAVH
FXI+FHH
VPI;VXt
A^_^[
@SUVWATAUAVAWH
L$(H3
8A_A^A]A\_^][
VWAVH
SVWATAUAVAWH
L9A s
L;B r
L9A s
L;B r
d$LE3
A_A^A]A\_^[
@SUVWATAVAWH
L$0IcY
L$8H3
@A_A^A\_^][
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
|$ AVH
@USVWATAUAVAWH
t$0L;
C\$0H
|$pE3
A_A^A]A\_^[]
@USVWATAUAVAWH
t$0L;
C\$0H
A_A^A]A\_^[]
@USVWATAUAVAWH
|$PH;
|$PH;
T$PH;
T$PH;
T$PH;
A_A^A]A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@USWH
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
D$ I;
BPfff
A_A^A]A\_
VWATAVAWH
@A_A^A\_^
t$ WH
t$8H+
\$ UVWATAUAVAWH
L9x s
L;y r
L$@H9L$0u
A_A^A]A\_^]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
UVWATAUAVAWH
PA_A^A]A\_^]
UVWATAUAVAWH
I+AHH
L$xH;
T$<A;
N 9H u^
I+AHH
I+AHH
I;Q@t
I+AHH
I;QXt
I+AHH
I;QXt
I+AHH
I;QXt
A_A^A]A\_^]
UVWATAUAVAWH
L$PH;
T$PH;
D$4H;N
L9` s
L;a r
L;d$8
A_A^A]A\_^]
UVWAVAWH
A_A^_^]
UWATAVAWH
A_A^A\_]
L$ UVWATAUAVAWH
 A_A^A]A\_^]
VWATAVAWH
A_A^A\_^
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
D$hE3
|$HH;N
D$pt=
F8H;x
A_A^A]A\_^[]
S D9R0t
C A;A0t
A;A,t
A;A(t
UVWATAUAVAWH
T$PE3
I;]xtbL
I;]xt
`A_A^A]A\_^]
l$ VWAVH
|$ AVH
L$0H+
@SUVWATAVAWH
u-9H(u
O H;H tj2
L$0H3
@A_A^A\_^][
t$ WH
t$ WH
t$8H+
WAVAWH
)D$0L
T$ E3
D$0M+
)D$@I
L$@I+
(D$ f
(L$0f
\$ M;
PA_A^_
@SWAVH
(D$ H
`A^_[
(D$ L
(L$0H
`A^_[
A H+A
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
l$8E3
(D$ f
PA_A^A]A\_^]
@USVWAUH
A]_^[]
L$`L;
OPH;OPH
\$ WH
T$0E3
T$0D9R0t
A;A0t
A;A,t
A;A(t
)D$ L
@SVWH
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
|$ AVH
|$ AVH
l$ VWAVH
0A^_^
t$ WH
\$ UVWATAUAVAWH
Q0H+Q(H
d$`H;\$h
A_A^A]A\_^]
|$ E3
t$ WH
D$ H;
t$(H+
@SVWH
L$8H3
@USVWATAUAVAWH
M0I+M(H
L9x8t4H
xA_A^A]A\_^[]
@USVWAVH
pA^_^[]
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
d$ E3
H#U0H
(D$ f
H#}0H
t$ WATAUAVAWH
(D$ f
A_A^A]A\_
@SUVWAVH
PA^_^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
t$ UWATAVAWH
HcT$0H
fA9FNu
A8FMu
A8FLu
A_A^A\_]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SUVWAVAWH
L$@E3
L$HH3
XA_A^_^][
@USVWATAUAVAWH
|$ E3
A_A^A]A\_^[]
@USVWATAUAVAWH
|$XE3
t$PH;
|$`E3
A_A^A]A\_^[]
\$ UVWATAUAVAWH
D$@H;H
D$PL;
I#G0H
L;l$P
A_A^A]A\_^]
L$(H3
UVWAVAWH
T$0E3
T$0D9J0t
A;B0t
A;B,t
A;B(t
)D$ L
PA_A^_^]
t$ WATAUAVAWH
gfffffffI
fffffff
gfffffff
gfffffff
A_A^A]A\_
@SVWATAUAVAWH
t$ H;
`A_A^A]A\_^[
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
fffffff
d$ E3
I#W0H
(D$ f
I#w0H
t$ WH
@SUVWAVH
L$XH3
`A^_^][
gfffffffH+
UVWATAUAVAWH
G I;G(t
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
D$0H;
gfffffffH
t$ WH
L$0H;
@SUWH
L$ H;
@SWATH
l$@ff
O(+O0
H+G8H
H+G8H
G(+G0
 A\_[
|$ AVH
H+C8H;
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A\_^[]
@USVWATAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
|$ AVH
 HcD$PI
D$ HcA
L$ H3
D$ HcA
L$ H3
@SVWH
UVWATAUAVAWH
L$ E3
l$8D8h
H(;M(u
M,9H,
E(A;@(u
@,9E,
UUUUUUU
)D$ L
PA_A^A]A\_^]
D$0E3
A;@(u
UUUUUUU
)D$ L
t$ WATAUAVAWH
UUUUUUU
|$(I;
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
@SVWATAUAVAWH
UUUUUUU
|$(I;
`A_A^A]A\_^[
t$ WATAUAVAWH
UUUUUUU
A_A^A]A\_
@SVWATAUAVAWH
tofff
|$0I;
PA_A^A]A\_^[
@SVWATAUAVAWH
T$0I;
PA_A^A]A\_^[
A(A;@
A,A9@
A;A(u
A,A9@
@SWAVH
 A^_[
 A^_[
@SATAUAVH
(A^A]A\[
WATAUAVAWH
1M+0I
L$0I+
L+l$HI
A_A^A]A\_
\$ VWAVH
0A^_^
\$ UVWATAUAVAWH
PA_A^A]A\_^]
@SUVWATAUAVAWH
8A_A^A]A\_^][
WATAUAVAWH
\$ I;
L+l$8t
PA_A^A]A\_
t$ WATAUAVAWH
UUUUUUU
t$ I;
A_A^A]A\_
@SUVWAUAVAWH
L$8I;
L$XH3
`A_A^A]_^][
@SUVWAVAWH
(A_A^_^][
(A_A^_^][
\$ UVWATAUAVAWH
d$PE3
(D$ f
`A_A^A]A\_^]
\$ UVWATAUAVAWH
d$PE3
(D$ f
pA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
UVWATAUAVAWH
UUUUUUU
M;F u
E0H#D$0H
(D$ f
E0H#D$0H
@A_A^A]A\_^]
UVWATAUAVAWH
D$@fH
D$ H;
H;|$ 
A_A^A]A\_^]
UVAVH
PA^^]
PA^^]
t$ WATAUAVAWH
(D$ f
A_A^A]A\_
@SUVWATAUAVAWH
XA_A^A]A\_^][
t$ WH
@SUVWH
8_^][
VWAVH
L$ H3
0A^_^
S H+S
l$ VWAVH
UUUUUUU
@A^_^
|$ UH
SUVWAVH
 A^_^][
UVWATAUAVAWH
HcB H
HcAPH
HcA8H
D$8I;
H9D$8
HcAhH
HcA I
A_A^A]A\_^]
T$pH+
|$ ATAVAWH
 A_A^A\
SUVWAVH
 A^_^][
t$8H+
\$ VH
l$8H+
l$ VH
t$@I+
\$ UVWAVAWH
T$8H+
L$@H3
PA_A^_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
T$ E3
D$ L;
A_A^A]A\_^[]
@USVWATAVAWH
A_A^A\_^[]
UUUUUUU
@SVWH
t$ WH
l$ VWAVH
t$ WH
@USVWATAUAVAWH
H8H+H0H
A_A^A]A\_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
8v6H+U
A_A^A]A\_^[]
l$ VWAVH
\$ UVWH
L$0H3
\$ UVWATAUAVAWH
D$0L+
H;D$HM
t$xI;
upH;u0
D$HL;
L;|$H
H;u0t2M
A_A^A]A\_^]
@UWAVH
|$ E3
0A^_]
|$ UATAUAVAWH
A_A^A]A\]
t$ WH
AVAWH
(A_A^
\$ UVWATAUAVAWH
D$PI;
 H;|$@
t$HE3
D$@H;
t$HE3
A_A^A]A\_^]
@USVWATAUAVAWH
A0H;L$(
A_A^A]A\_^[]
@SUVWATAUAVAWH
L9yXuNA
e(D+e0D
)D$@L
A_A^A]A\_^][
l$ VWAVH
\$ UVWATAUAVAWH
L$pH;
D$0HcK,
|$0L;
D$8HcK(
D$hH;D$pt
A_A^A]A\_^]
@SVWATH
d$HI;
D$ H;V
L$hH3
xA\_^[
t$ WAVAWH
L$0H3
@A_A^_
@USVWATAVAWH
`A_A^A\_^[]
(HcA(
t$ WH
\$ UVWATAUAVAWH
d$ ff
d$ E3
D$0H;
A_A^A]A\_^]
\$ UVWATAUAVAWH
T$PE3
|$ E3
D$pHcH
D$pHcH
D$xE3
D$(L;
D$pHcH
D$pHcH
A_A^A]A\_^]
|$ AVH
@SVWH
\$ UVWATAUAVAWH
|$ H;
PA_A^A]A\_^]
t$ WH
t$ WH
t#Hc@(
@USVWATAUAVAWH
t$@H;
A_A^A]A\_^[]
@SVWATAUAVAWH
|$xL;
C\$xH
C\$PH
C\$xH
C\$PH
A_A^A]A\_^[
@SUVWATAVAWH
0A_A^A\_^][
t$ WATAUAVAWH
L$pE3
L$xH;
\$xH;
l$xI;
UUUUUUU
KH;|$@t
A_A^A]A\_
UVWATAUAVAWH
A_A^A]A\_^]
|$ UATAUAVAWH
HcB8H
HcBPH
H;t$ht
HcAhH
F0H;Q
D$8I;
A_A^A]A\]
\$ UVWATAUAVAWH
L$ fA
t$Dfff
|$PM;
|$PM;
L$@ H
L$@@L
D$HI;
D$HI;
A_A^A]A\_^]
(D$ f
t$XH;
|$ AVH
|$ UATAUAVAWH
L;t$0t
T$PH;
L$PL;
L;t$0t
T$PH;
|$@M;
|$@I;
A_A^A]A\]
@USVWAVH
A^_^[]
X UVWATAUAVAWH
A_A^A]A\_^]
@SUVWATAVAWH
`A_A^A\_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@SUVWATAVAWH
0A_A^A\_^][
UVWATAUAVAWH
)L$`L
H;\$0
H;\$0
H;Mxt.I
A_A^A]A\_^]
@SVWH
L$8H3
@SUVWATAVAWH
A_A^A\_^][
UVWATAUAVAWH
d$0I;
IcE8H
\$0H;
A_A^A]A\_^]
L9s }
t$ WH
uBfff
D$ L;
L$HH3
@USVWAVH
A^_^[]
@USVWATAUAVAWH
T$HH;
A_A^A]A\_^[]
T$0H;
UWAVH
L$ H;
@SUVWAVH
o(+o0
@8wPt
L$8I+
L$PI+
L$XH3
`A^_^][
@SUVWAVH
T$8H+
L$@H3
PA^_^][
@USVWATAUAVAWH
H;|$H
H;D$0
U(A+U0A
M(A+M0A
I+E8H
U(A+U0A
I+E8H
U(A+U0A
U(A+U0A
M(A+M0A
I+E8H
U(A+U0A
I+E8H
u(E+u0E
U(A+U0A
U(A+U0A
U(A+U0A
M(A+M0A
I+E8H
U(A+U0A
I+E8H
u(A+u0A
U(A+U0A
U(A+U0A
U(A+U0A
M(A+M0A
I+E8H
U(A+U0A
M(A+M0A
I+E8H
E(A+E0A
A_A^A]A\_^[]
@USVWATAUAVAWH
H+F8H;
|$Xff
V(+V0
N(+N0
H+F8H
V(+V0
H+F8H
^(+^0
A_A^A]A\_^[]
UVWATAUAVAWH
H#E@H
H;t$0t
|$@I;
C0H;U
D$0H+
\$8E3
D$0H+
A_A^A]A\_^]
l$ VWATAVAWH
A_A^A\_^
\$ UVWATAUAVAWH
W H+W
UUUUUUU
(D$@f
(D$Pf
D$PI;
A_A^A]A\_^]
l$PI+
L$(H3
tbHcH(
UVWATAUAVAWH
HcB8H
T$0L;
L9t$Hu
A_A^A]A\_^]
UVWAVAWH
tEfff
A_A^_^]
VWAVH
d$xH;
l$hH;
@A^_^
UVWATAUAVAWH
|$hL;
C\$hH
H;0uoA
A_A^A]A\_^]
WAVAWH
0A_A^_
UVWATAUAVAWH
d$ L;
L$PH3
`A_A^A]A\_^]
@USVWATAVAWH
A_A^A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
D$ E3
H;{HtdH
D$@E3
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
|$0L;
t$0L;
t$0L;
@SVWATAUAVAWH
D$HH#
UUUUUUU
(D$Pf
H;D$h
UUUUUUU
H#D$HH
|$XE3
|$PE3
(D$Pf
H#D$HH
H;D$h
UUUUUUU
D$PE3
H;D$h
D$hE3
\$HH;
A_A^A]A\_^[
|$ AVH
@SVATAVAWH
l$XH+
 A_A^A\^[
l$ VAVAWH
|$HH+
 A_A^^
@SAUH
I#E0M
L;d$ u
H;t$ 
t$ WH
t$ WH
UUUUUUU
t$8H+
@SVWH
L$ H3
H#C0H
H9t$xu>M
9H9t$xu
H#A0H
UAVAWH
I#F0H
H;|$0tHH;
L9|$(u
PA_A^]
L9|$(u
I#F0L
UVAVH
H#E0H
H;|$(t
L9t$ uzI
uL9t$ u
H#E0L
PA^^]
O(+O0
8OPtk
H+G8H
G(D+G0D
O(+O0
8OPtk
H+G8H
G(D+G0D
O(+O0
8OPtk
H+G8H
G(D+G0D
O(+O0
8OPtk
H+G8H
G(D+G0D
O(+O0
8OPtk
H+G8H
G(D+G0D
O(+O0
8OPtk
H+G8H
G(D+G0D
|$8H;
H#F0H
H9l$(u
H9l$(u
H#F0H
\$Hff
VWAVH
L$0H3
@A^_^
t$ WH
WpH;Wxt
UVWAVAWH
D$@D;
t$H9H(u
D$@H;
A_A^_^]
SVWATAUAVAWH
L$0I+
`A_A^A]A\_^[
`A_A^A]A\_^[
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
UWATAVAWH
t$ E3
A_A^A\_]
UVWATAUAVAWH
L$XH+
A_A^A]A\_^]
\$ UVWATAUAVAWH
T$(E3
J0;K0
A_A^A]A\_^]
VWATAVAWH
T$(E3
@A_A^A\_^
\$ UVWATAUAVAWH
T$(E3
J0;K4
A_A^A]A\_^]
@SUVWATAVAWH
MXH;MX
V8H;V8tiH
D$ H9
@A_A^A\_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
@SVWATAUAVAWH
D9p }
D$0D9p }
)D$`L
D$xH;XX
D$09H }
;J }wH
)D$`L
A_A^A]A\_^[
@SUVWAVH
T$0E3
L$8H3
@A^_^][
VWAVH
L$(H3
0A^_^
l$ VWAVH
H9Y0t
9{ ~h
@A^_^
t$ WAVAWH
MXH9MXt
0A_A^_
AUAVH
I#E0H
tEfff
L$0H3
hA^A]
H#C0E3
t$ WATAUAVAWH
(D$ f
A_A^A]A\_
\$ UVWATAUAVAWH
T$PH;
T$PH;
T$PH;
I+VHH
I+VHH
 H;|$8M
l$0I;
A_A^A]A\_^]
t$@H;
T$ tMH
L$(H3
|$ AVH
Fp;Gpt
H+C8H
C(D+C0D
VWAVH
L$xE3
@SVWAVAWH
L$xE3
A_A^_^[
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
\$ VWAVH
L$0E3
D$PH;
L$`H3
pA^_^
\$ UVWATAUAVAWH
3333333
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
3333333
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
IcE8H
D8D$@t
H;D$P
IcEhH
D$XH;
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
UWATAVAWH
t$ E3
A_A^A\_]
@SVWATAUAVAWH
A_A^A]A\_^[
@USVWAVH
A^_^[]
@USVWATAUAVAWH
D$`E3
A_A^A]A\_^[]
UVWATAUAVAWH
D$HE3
)D$`H
A_A^A]A\_^]
\$ UVWH
@USVWATAUAVAWH
IcE H
v D+v0D
V +V0
N +N0
H+F8H
V +V0
H+F8H
~ +~0
v(D+v0D
V +V0
V +V0
V +V0
N +N0
H+F8H
V +V0
H+F8H
^ +^0
F(+F0
W(+W0
O(+O0
8OPtk
H+G8H
G(D+G0D
W(+W0
O(+O0
8OPtk
H+G8H
G(D+G0D
A_A^A]A\_^[]
UVWATAUAVAWH
|$hL;
A_A^A]A\_^]
@SVWH
\$ WH
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
|$ AVH
 HcD$PI
@SVWATAUAVAWH
yxxxxxxxH
|$0Li
t$ H;
yxxxxxxxH
<$HiL$@
`A_A^A]A\_^[
p WATAUAVAWH
A_A^A]A\_
@SVWATH
A\_^[
@SUVWATAVAWH
D$ L;
L$@H3
PA_A^A\_^][
t$0H;
t$ WH
yxxxxxxxH
l$ VWAVH
gfffffffH
fffffff
t$0H;
@A^_^
@SUVWAVAWH
8A_A^_^][
|$ AVH
l$ VWAVH
D$(H;
L$XH3
UVWATAUAVAWH
A_A^A]A\_^]
|$ UH
|$ UAVAWH
A_A^]
VWAUAVAWH
A_A^A]_^
|$ UH
@USVWAVH
A^_^[]
|$ UAVAWH
A_A^]
VWAVH
@A^_^
UWATAVAWH
A_A^A\_]
T$8H+
L$XH3
t$ WH
t$ WH
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
@ Hc@ H
A_A^A]A\_^]
D$PE3
D$PE3
t$ WAVAWH
@A_A^_
|$ UATAUAVAWH
L+|$PI
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UVWATAUAVAWH
VUUUUUUUH
A_A^A]A\_^]
@USVWATAVAWH
A_A^A\_^[]
|$ UATAUAVAWH
E0H9E
T$hH;T$pt
D$pH+
A_A^A]A\]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
t$8H+
yxxxxxxxH
t$8H+
gfffffffH
t$8H+
|$ UATAUAVAWH
L$0E3
A_A^A]A\]
D9u0~f
D$(I;
D$8fff
D$8H+<
UWATAVAWH
A_A^A\_]
UVWATAUAVAWH
A_A^A]A\_^]
@SVWH
@SUVWATAVAWH
A_A^A\_^][
@USVWAVH
E0H9E
T$hH;T$pt
D$pH+
A^_^[]
SUVWH
x 9K(u
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@SVWATAUAVAWH
\$ Mk
>HkL$88H
PA_A^A]A\_^[
\$ UVWATAUAVAWH
@A_A^A]A\_^]
k VWATAVAWH
A_A^A\_^
D$0L;I
UVWATAUAVAWH
pA_A^A]A\_^]
@SUVWAVH
L$@H3
PA^_^][
@SUVWAVAWH
D$8H+
L$@H3
XA_A^_^][
\$ UVWATAUAVAWH
D$0H;
(D$@f
L$(H;L$0
T$pH+
T$pH+
A_A^A]A\_^]
|$ UAVAWH
A_A^]
\$ UVWH
s WATAUAVAWH
D$PH+
r6w4HcC(H
|$`H+
\$0fff
|$`H+
L$pH+
L$xH3
A_A^A]A\_
@SWAUAVAWH
HcK,I
0A_A^A]_[
UVWATAUAVAWH
\$(L;
;C,u|
C(A9E
`L;l$0
A_A^A]A\_^]
L$0H3
L$0H3
UVWAVAWH
A_A^_^]
tbD;H,t_L
WAVAWH
 A_A^_
l$ VWAVH
L$(E3
l$ VWAVH
L$(E3
UVWAVAWH
L$(E3
HcC(H;
pA_A^_^]
@SUWAVH
(D$0f
D$0H;
L$@H3
XA^_][
\$ UVWH
L$ H+
L$8H3
tbD9H(t_L
@SUVWAVH
`A^_^][
|$ AVH
?ai.ou=f
;ai.ou
@SUVWAVH
l$8H;
L$HH3
PA^_^][
\$ UVWAVAWH
|$8H;
L$HH3
PA_A^_^]
L$(H+L$ H
L$8H3
D$0Mc
L$(H+L$ H
L$8H3
|$ UATAUAVAWH
A_A^A]A\]
UVWAVAWH
D$@Mc
D$8H9D$0
\$0H;
L$HH3
PA_A^_^]
L$XL;
@SUVWAVH
\$ I;
L$8H3
@A^_^][
UVWATAUAVAWH
(D$`f
\$8L;
D9`,I
A_A^A]A\_^]
l$ VWATAVAWH
)t$@H
l$0H;
l$0Hc
L$8H3
(t$@I
A_A^A\_^
l$ VWATAVAWH
t$0H;
t$0Hc
L$8H3
A_A^A\_^
|$ AVH
H+K8H;
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@SUVWAVH
T$0H+
L$8H3
@A^_^][
\$ WH
L$@H3
@SUVWATAVAWH
t$0L+t$(I
W +W0
O +O0
H+G8H
W +W0
H+G8H
G +G0
T$8H+
L$@H3
PA_A^A\_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
^(+^0
^(+^0
^(+^0
~(D+~0D
V(+V0
N(+N0
8NPtk
H+F8H
F(D+F0D
~(+~0
V(+V0
N(+N0
8NPtm
H+F8H
F(D+F0D
H+N8H;
F(+F0
^(+^0
^(+^0
HcGXH
V(+V0
N(+N0
H+F8H
V(+V0
H+F8H
^(+^0
A_A^A]A\_^[]
@USVWATAUAVAWH
~(E+~0E
V(A+V0A
N(A+N0A
I+F8H
I+F8H;
V(A+V0A
N(A+N0A
A8NPtk
I+F8H
F(E+F0E
A_A^A]A\_^[]
@SUVWATAVAWH
w(D+w0D
O(+O0
8OPtk
H+G8H
G(D+G0D
W(+W0
O(+O0
8OPtk
H+G8H
G(D+G0D
L$@H3
PA_A^A\_^][
H+C8H
C(D+C0D
(t$ H
O(+O0
8OPtk
H+G8H
G(D+G0D
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
@SUVWATAUAVAWH
(D$ f
XA_A^A]A\_^][
|$ ATAVAWH
H#E0H
 A_A^A\
t$ WATAUAVAWH
)t$`I
UUUUUUU
(D$ f
UUUUUUU
(t$`I
A_A^A]A\_
@SUVWATAUAVAWH
XA_A^A]A\_^][
@SUVWAVH
0A^_^][
|$ AWH
@USVWATAUAVAWH
S H+S
d$XL;
D$hE3
d$XI;
D$pH;
H;\$pL
D$pH;
H;\$p
t$xE3
D$XH;
L$hH;
IcM0H
IcM0H
\$hH;
D$XH;
P0IcM0H
D$XH;
L$hH;
L$hH;
L$hH;
L$XH;
d$XL9`
D$XH;
D$XH;
IcM0H
IcM0H
D$XH;
HcH0H
D$XH;
|$pI;
A_A^A]A\_^[]
@USVWATAUAVAWH
I+VHH
I+V`H
A_A^A]A\_^[]
@USVWATAUAVAWH
Hc@PH
t+H;O
D$8H;H
L$ H;V
D$@H;H
A_A^A]A\_^[]
@SVWH
\$ UVWATAUAVAWH
A_A^A]A\_^]
L$0H;
@USVWATAUAVAWH
IcGhL
l$XLcD$TH
l$XHc
LcD$TL
G8H;G@t
G8H;G@t
Hc\$T
l$XHc
LcD$TL
G8H;G@t
G8H;G@t
HcGPH
A_A^A]A\_^[]
@USVWATAUAVAWH
UUUUUUU
tqfff
IcFhL
IcEPH
d$hM;l$
A_A^A]A\_^[]
UVWATAUAVAWH
HcB H
t$@E3
tAI;V
HcBPH
A_A^A]A\_^]
t$8H+
GXH;GXu
l$ VWAVH
|$ AVH
t$ E3
VWAUAVAWH
A_A^A]_^
|$ UATAUAVAWH
A_A^A]A\]
t$ WATAUAVAWH
A_A^A]A\_
@USVWATAUAVAWH
A_A^A]A\_^[]
VWAVH
L$xH3
t$ WH
@ 9A 
G 9A 
t$ WH
@USVWATAUAVAWH
A_A^A]A\_^[]
VWAVH
UVWAVAWH
A_A^_^]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
VWAVH
|$ UATAUAVAWH
D9`(t
A_A^A]A\]
t$ WATAUAVAWH
T$@E3
l$HL;l$X
A_A^A]A\_
VWAVH
|$ UAVAWH
A_A^]
(D$ H
@USVWATAUAVAWH
A_A^A]A\_^[]
t$ UWAVH
@ 9p 
T$0H;T$8t
T$8H+
L$@H3
\$ WH
|$H9S(u
D$@H;
)t$@H
L$8H3
(t$@H
@SUWATAUAWH
L+CxI
H;k8uuH
A_A]A\_][
H+SxH;
H+kxH
VWAVH
|$ ATAVAWH
A_A^A\
@SUWATAVH
L$8H+
A^A\_][
@SUWATAVH
`A^A\_][
@SVWAVH
)t$pH
D$@L;
t$XM;
T$ M;
(t$pH
A^_^[
@SVWAVH
D$hH;
A^_^[
@SVAVAWH
t$(H+
D$ H;
t$pL+
|$xL+
d$@H;
T$(H;
A_A^^[
\$ UVWATAUH
@A]A\_^]
)l$ D
(l$ L
)l$ D
(l$ L
)l$@D
)t$0D
)|$ I
(t$0L
(|$ I
@SVWH
T$ L;
L$PH3
\$ UVWH
(|$PL
(t$`H
L$@H3
)l$ D
(l$ D
(d$0D
(\$@D
(T$PD
(L$`D
)l$ D
(l$ L
)t$PI
)L$ D
(L$ A
(D$0A
(|$@I
@USVWATAUAVAWH
L;D$pH
CD$pE3
t$0E3
A_A^A]A\_^[]
SUWAUAVH
D$pH;
A^A]_][
UVWATAUAVAWH
D$HE3
L+d$ M
L;d$0
L;D$PuGH
H;D$Xu
A_A^A]A\_^]
UAVAWH
l$(I;
A_A^]
SVWAUAVAWH
L$ H+
HA_A^A]_^[
HA_A^A]_^[
C(H9C@u,H
HA_A^A]_^[
HA_A^A]_^[
HA_A^A]_^[
UVWATAUAVAWH
H+D$HL
D$XL+t$8L
L$hM;
L;t$p
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UWATAUAWH
D$`H;
0A_A]A\_]
UVWATAUAVAW
zHuFA
zEuCA
@wGfff
u`u|H
A_A^A]A\_^]
@SUVWAW
A__^][
@SUVWATAUAVAWH
A0t>H
xA_A^A]A\_^][
UVWATAUAVAWH
)\$pD
)d$`H
D$8Hk
)l$PD
)t$@H
(t$@D
(l$PD
(d$`D
(\$pD
A_A^A]A\_^]
SUVWATAUAVAWH
H+L$ A
D$ L+
8A_A^A]A\_^][
UVWATAUAVAWH
D$hfff
A_A^A]A\_^]
USVWATAVAWH
A_A^A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
\$0H#
@SUWH
SATAUAWH
|$pI;
A_A]A\[
ATAUAWH
|$pI;
 A_A]A\
SATAUAWH
|$pI;
A_A]A\[
@UAUAVAWH
A_A^A]]
ATAUAWH
|$pI;
 A_A]A\
t$ WAVH
t$0A^_
@UAUAVAWH
A_A^A]]
t$ WAVH
t$0A^_
A(tzA
UVWATAUAVAW
},outH
A_A^A]A\_^]
@SUVWATAUAVAWH
D$ M+
|$poH
A_A^A]A\_^][
UVWATAUAVAWH
)t$@I
D$8Ik
k fff
(t$@M
D$8H+
L$(L+
PA_A^A]A\_^]
UVWATAUAVAWH
T$`H;
A_A^A]A\_^]
L$ L;
D$XH;
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
A4XH 
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
A4XH 
A4XH 
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
b},4C
b}.<C
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
ba|H(
ba|H(
ba|H(
ba|H(
QbreH
SbreH
VbbeH
|H(L"
|H(L"
QbreH
SbreH
VbbeH
@bq|H
6bA|H
@bq|I
>bA|I
ba|H(
ba|H(
Qbr}X
Qbr}X
|H(L"
|H(L"
QbreH
|H(L"
|H(L"
QbreH
@bq|H
@bq|I
Qbr}X
Qbr}X
QbreH
SbreH
|H(L"
|H(L"
QbreH
SbreH
@bq|H
@bq|I
Qbr}X
Qbr}X
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
QbreH
|H(L"
|H(L"
QbreH
QbreH
|H(L"
|H(L"
QbreH
@bq|H
@bq|I
Qbr}X
Qbr}X
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
A5XH 
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
A5XH 
A5XH 
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
b}-4C
b}/<C
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
HUSVH
)D$ H
A|U@ 
(D$ H
HUSVH
HUSVWATAUH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
~oL$ I
~o] I
~oL$ I
~o] I
~oL$ I
~o] I
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A]A\_^[]
~oL$ I
~o] I
~oL$ I
~o] I
~oL$ I
~o] I
HUSVWH
HUSVWATAUAVH
br}H{
~HoD$
bReX@3b
]X@#bQ}H
breHQ
~HoT2
breHQ
~HoT2
breHQ
~HoT2
breHQ
breHQ
~HoT2
~HoT2
~HoT2
0bQ~I
bReX@3bQ}H
breHQ
breHQ
breHQ
breHQ
breHQ
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
#bAmX
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
~HoL2
~HoTr
~HoL2
~HoTr
~HoL2
~HoTr
~HoD$
bReX@3b
]X@#bQ}H
bReX@{
#bQ}X
breHQ
breHQ
~HoT2
breHQ
breHQ
~HoT2
breHQ
breHQ
~HoT2
breHQ
breHQ
breHQ
breHQ
~HoT2
~HoT2
~HoT2
0bQ~I
bReX@3bQ}H
bReX@{
3bQ}X
breHQ
breHQ
breHQ
breHQ
breHQ
breHQ
breHQ
breHQ
breHQ
breHQ
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
bReX@{
bBUX@[
'bQ}X
#bAmX
bbeHQ
breHQ
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
bbeHQ
breHQ
bbeHQ
breHQ
~HoL2
~HoTr
~HoL2
~HoTr
~HoL2
~HoTr
~HoD$
bReX@3b
]X@#bQ}H
bReX@{
(bQ}X
#bQ}X
breHQ
breHQ
@bQ~I
0bQ~I
bReX@3bQ}H
bReX@{
3bQ}X
breHQ
breHQ
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
bReX@{
bBUX@[
bBUX@c
<bQ}X
#bAmX
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
$@bA~H
~HoD$
bReX@3b
]X@#bQ}H
bReX@{
6bQ}X
#bQ}X
breHQ
breHQ
~HoT2
breHQ
breHQ
}HX\I
~HoT2
breHQ
breHQ
}HX\I
~HoT2
breHQ
breHQ
}HX\I
breHQ
breHQ
~HoT2
}HX\I
~HoT2
}HX\I
~HoT2
}HX\I
0bQ~I
bReX@3bQ}H
bReX@{
3bQ}X
breHQ
breHQ
breHQ
breHQ
}HX\I
breHQ
breHQ
}HX\I
breHQ
breHQ
}HX\I
breHQ
breHQ
}HX\I
}HX\I
}HX\I
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
bReX@{
bBUX@[
bBUX@c
bBUX@k
QbQ}X
#bAmX
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
bbeHQ
~HoL2
~HoTr
}HX\I
~HoL2
~HoTr
}HX\I
~HoL2
~HoTr
}HX\I
+bA~H
$@ba~H
~HoD$
bReX@3b
]X@#bQ}H
bReX@{
bB]X@C
DbQ}X
#bQ}X
breHQ
breHQ
bbeHQ
;ba=@
;ba~H
0bQ~I
bReX@3bQ}H
bReX@{
"bQ}X
3bQ}X
breHQ
breHQ
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
bReX@{
bBUX@[
bBUX@c
bBUX@k
bB]X@C
bBUX@s
fbQ}X
#bAmX
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
bbeHQ
bbeHQ
bbeHQ
u!bA-@
$@ba~H
+ba~H
~HoD$
bReX@3b
]X@#bQ}H
bReX@{
bB]X@C
bB]X@K
RbQ}X
#bQ}X
breHQ
breHQ
bbeHQ
KbbeHQ
~HoT2
breHQ
breHQ
}HX\I
bbeHQ
}HX\K
bbeHQ
~HoT2
breHQ
breHQ
}HX\I
bbeHQ
}HX\K
bbeHQ
~HoT2
breHQ
breHQ
}HX\I
bbeHQ
}HX\K
bbeHQ
breHQ
breHQ
bbeHQ
KbbeHQ
~HoT2
}HX\I
}HX\K
~HoT2
}HX\I
}HX\K
~HoT2
}HX\I
}HX\K
;ba=@
;ba~H
CbQ~I
0bQ~I
bReX@3bQ}H
bReX@{
)bQ}X
3bQ}X
breHQ
breHQ
breHQ
breHQ
}HX\I
}HX\K
breHQ
breHQ
}HX\I
}HX\K
breHQ
breHQ
}HX\I
}HX\K
breHQ
breHQ
}HX\I
}HX\K
}HX\I
}HX\K
}HX\I
}HX\K
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
bReX@{
bBUX@[
bBUX@c
bBUX@k
bB]X@C
bBUX@s
bB]X@K
bBUX@{
{bQ}X
#bAmX
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
bbeHQ
bbeHQ
bbeHQ
KbbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
bbeHQ
bbeHQ
}HX\K
bbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
bbeHQ
bbeHQ
}HX\K
bbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
bbeHQ
bbeHQ
}HX\K
bbeHQ
bbeHQ
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
bbeHQ
bbeHQ
bbeHQ
KbbeHQ
bbeHQ
~HoL2
~HoTr
}HX\I
}HX\K
~HoL2
~HoTr
}HX\I
}HX\K
~HoL2
~HoTr
}HX\I
}HX\K
u(bA-@
<CbA~H
$@ba~H
+ba~H
(|$ H
0A^A]A\_^[]
HUSVWH
bb}H{
bb}HX'H
w_^[]
bb}HX
HUSVWH
bb}HX'H
w_^[]
bb}HX
HUSVWH
)D$ D
)L$0D
)T$@H
(D$ D
(L$0D
(T$@H
X_^[]
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAVATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A^_^[]
fffffff
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
fffff
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
fffff
fffffff
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAVATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A^_^[]
ffffff
fffffff
A<X@@
fffffff
A<X@@
A<X@@
A<X@@
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
fffff
ffffff
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
fffffff
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAVATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A^_^[]
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
$IbB}H
<Nba|H
$Iba|H
IbR=P
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
fffffff
rbb}H
rbb}H
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
$IbB}H
<Nba|H
$Iba|H
IbR=P
$Nba|H
Iba|H
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
2bb}H
rbb}H
rbb}H
3bb}H
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
IbR=@
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAVATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
rbb}H
3bb}H
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
rbb}H
$IbB}H
<Nba|H
$Iba|H
2bb}H
IbR=P
$Nba|H
Iba|H
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A^_^[]
bQ<HX@
bQ<@_
bQ<HX@
t*ba|H
bQ<@_
bQ<@_
fffff
fffff
t%ba|H
!ba|H
bQ<HX@
bQ4HXL
t1ba|H
!ba|H
bQ<@_
bQ<@_
bQ<HX@
bQ4HXL
tUba|H
!ba|H
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
t8ba|H
!ba|H
ffffff
bQ<HX@
bQ4HXL
bq,HXS
tJba|H
!ba|H
bQ<@_
bQ<@_
bQ<@_
bQ<HX@
bQ4HXL
bq,HXS
!ba|H
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
fffff
tKba|H
!ba|H
bQ<HX@
bQ4HXL
bq,HXS
bq$HX\
tcba|H
!ba|H
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<HX@
bQ4HXL
bq,HXS
bq$HX\
!ba|H
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
HUSVWAVAUATH
A\A]A^_^[]
HUSVWAVAUATH
A\A]A^_^[]
HUSVWAVAUATH
A\A]A^_^[]
HUSVWAVAUATH
wA\A]A^_^[]
HUSVWAVAUATH
wA\A]A^_^[]
HUSVWAVAUATH
wA\A]A^_^[]
HUSVWAVAUATH
wA\A]A^_^[]
fffffff
HUSVWAVAUATH
wA\A]A^_^[]
fffff
HUSVWAVAUATH
*l$hb
wA\A]A^_^[]
@UVAVH
)|$0H
~T$ f
L$(H3
(|$0H
`A^^]
@UWAVAWH
)|$`D
)D$PH
)L$@D
)T$0H
~L$ H
~T$ H
(T$0f
L$(H3
(|$`D
(D$PH
A_A^_]
@UVAVH
)|$0H
~T$ f
L$(H3
(|$0H
`A^^]
@UWAVAWH
)|$`D
)D$PH
)L$@D
)T$0H
~L$ H
~T$ H
(T$0f
L$(H3
(|$`D
(D$PH
A_A^_]
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
b"-@,
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
USVWAVH
A^_^[]
USVWAVAWH
A_A^_^[]
USVWAVH
A^_^[]
USVWAVAWH
A_A^_^[]
)|$0D
)D$ L
bR}H|
)t$@H
(t$@I
(|$0D
(D$ D
)|$0A
)D$ D
bR}H|
)t$@H
(t$@I
(|$0D
(D$ D
)t$`I
x)D$@
x)L$0H
x)T$ Hk
$]Y`H
x(D$@
x(T$ 
x(L$0
ATAUAVH
)t$ M
@A^A]A\
ATAUAVH
|$ ff
0A^A]A\
UVWATAUAVAWH
x)T$`H
zoU H
A_A^A]A\_^]
UVWATAUAVAWH
x)T$`H
zoU H
A_A^A]A\_^]
@USVWATAUAVAW
D8R1u
H;EhuSL
A_A^A]A\_^[]
@SVWAVH
)t$ H
(t$ H
8A^_^[
@SWAWH
(t$@L
L$ H3
PA__[
SUWATAUAVAWH
)T$PE
oD$8f
(T$PH
L$HH3
(D$pH
A_A^A]A\_][
@USVWATAUAVAW
E(H;ExuSL
A_A^A]A\_^[]
@USVWATAUAVAW
$8D8r1u
H;ExuLL
A_A^A]A\_^[]
SUATAVAWH
(t$@H
(|$0D
(D$ H
PA_A^A\][
@WAWH
(t$ L
@USVWATAUAVAW
D8R1u
u9L9RHu3E8U
A_A^A]A\_^[]
@USVWATAUAVAW
A_A^A]A\_^[]
@USVWATAUAVAW
A_A^A]A\_^[]
@USVWATAUAVAW
$8D8r1u
H;ExuLL
A_A^A]A\_^[]
HUSVWATAUH
)|$PD
)D$`D
)L$pD
o|$0J
(|$PD
(D$`D
(L$pD
A]A\_^[]
HUSVWH
)|$PD
)D$`D
)L$pH
(|$PD
(D$`D
(L$pH
HUSVWATAUH
)|$PD
)D$`D
)L$pH
}0t$ 
}0|$0J
(|$PD
(D$`D
(L$pH
A]A\_^[]
HUSVH
WAVAWH
0A_A^_
VWAVH
0A^_^
UVWATAUAVAWH
d$ E3
d$ E3
|$ E3
|$ E3
A_A^A]A\_^]
t$HE3
UVWATAUAVAWH
A_A^A]A\_^]
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
VWATAVAWH
@A_A^A\_^
L$0H3
t$ WH
T$ Ic
UVWAVAWH
A_A^_^]
L$0H3
UVAVH
\$ UVWATAUAVAWH
CL$(3
A_A^A]A\_^]
\$ UVWATAUAVAWH
CL$(3
A_A^A]A\_^]
|$ AVH
t$ UWAVH
UVWAVAWH
A_A^_^]
D$0H;
@SUVWAVH
t"D85
A^_^][
HcD$\
L$xH3
UVWAVAWH
A_A^_^]
\$0H;
t$ WH
UVWATAUAVAWH
th@8=r
@A_A^A]A\_^]
L$ SWH
T$hH+
UVWATAUAVAWH
A_A^A]A\_^]
|$ ATAVAWH
A_A^A\
WATAUAVAWH
t_fD9"tYH
fD9dB
tgD8"tbH
D8$:u
tgD8"tbH
D8$:u
tgD8"tbH
D8$:u
tgD8"tbH
D8$:u
tgD8"tbH
D8$:u
tgD8"tbH
D8$:u
tyfD9"tsH
fD9dB
tnD8"tiH
D8$:u
t\fD9"tV
fD9dj
 A_A^A]A\_
L$ VWAVH
`A^_^
`A^_^
t$ AWH
D$pHcH
D$pHcH
D$pHcH
D$pHcH
|$ AVH
L$0H3
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
\$ UVWATAUAVAWH
|$0I;
@A_A^A]A\_^]
@SVWATAUAVAWH
PA_A^A]A\_^[
SVWATAUAVAWH
L$XI+
H+T$HH
l$xL;|$@t
A_A^A]A\_^[
@SWATAVH
l$(E3
8A^A\_[
L$0I;
t$0ff
l$ VWATAVAWH
T$hE3
|$ H;
A_A^A\_^
A0H9A(u
VWATAVAWH
L$(E3
0A_A^A\_^
F0H9F(t
@USVWAVH
A^_^[]
WAVAWH
 A_A^_
@USVWATAUAVAWH
9zv2H
D8t$0
D8t$0
D$8L+
A_A^A]A\_^[]
UVWATAUAVAWH
T$8E3
}0M+}(I
T$ E3
@A_A^A]A\_^]
l$ VAVAWH
|$HH+
 A_A^^
l$ VWATAVAWH
A_A^A\_^
L$(H3
L$ SH
L$xH3
t$ WH
l$ VWAVH
l$ VWAVH
\$ UVWATAWH
t$`E3
 A_A\_^]
@SVWATAUAVAWH
D$0I;
A_A^A]A\_^[
p WAVAWH
A_A^_
UVWATAUAVAWH
3333333
\$ E3
(D$ f
3333333
pA_A^A]A\_^]
l$ WH
t$8H+
UVWATAUAVAWH
T$(E3
H;D$(
\$0H;
A_A^A]A\_^]
UVWATAUAVAWH
T$PH+T$HH
L$HH+
s~H;^
A_A^A]A\_^]
@SUVWH
L$HH3
X_^][
VWAVH
@SUVWAVH
@A^_^][
\$ UVWATAUAVAWH
PA_A^A]A\_^]
@SUVWATAUAVAWH
L$PH3
hA_A^A]A\_^][
@USVWATAVAWH
A_A^A\_^[]
L$0H3
T$0H;
VWAVH
L9s`v=A
H;s`r
L$(H3
0A^_^
@SUVWAVH
)|$`D
)D$PD
)L$@H
L$0H3
(|$`D
(D$PD
(L$@H
A^_^][
t$ UWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_]
@SUVWAVH
L$0H3
@A^_^][
l$ VH
L$(H3
L$(H3
Q8H;Q@t
t$ WH
APH9AHtl
GPH+H
t$ WH
APH9AH
GPH+H
D$0H;WXt
SUVWAVH
A^_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAWH
A_A\_^[]
@UVWAVAWH
A_A^_^]
\$ UVWATAUAVAWH
L$PH3
`A_A^A]A\_^]
@SUWATAUAVAWH
D3d$(I
D3d$(
L$XH3
`A_A^A]A\_][
UVWATAUAVAWH
T$xE3
APH9AH
|$0E3
t7fff
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
t$ UWATAVAWH
A_A^A\_]
@SUVWATAVAWH
|$hI9>tyH
A_A^A\_^][
@USVWATAUAVAWH
D$@E3
A_A^A]A\_^[]
\$ UVWATAUAVAWH
D$0H;
T$0H;
A_A^A]A\_^]
T$pH;
@USVWATAUAVAWH
D$0Li
@8|$ t
L$$D3
D$XD;
A_A^A]A\_^[]
T$ H;
L$(H3
t$ UWAWH
@VAVH
D$(Liq`@!
L$(H3
UVWATAUAVAWH
L$@E3
t$H;\$8}
A_A^A]A\_^]
t$ WH
UVWAVAWH
0A_A^_^]
t$;y@s
@SUWAVH
(A^_][
(A^_][
|$ AVL
t$@I;
|$(A^
|$ ATAVAWH
|$@E3
|$8A_A^A\
t$ WATAUAVAWH
L$HH3
A_A^A]A\_
@USVWATAUAVAWH
Q`D8Ihu
A_A^A]A\_^[]
\$ UVWAVAWH
L$`E3
L9t$x
A_A^_^]
L$0H3
D$HE3
L$hH3
D$HE3
L$hH3
UVAVAWI
A_A^^]
UATAUAVAWH
t$ E3
|$ E3
t$ E3
t$ E3
t$ E3
D$ E3
A_A^A]A\]
t$ UWAVH
D9X0H
D9X0H
D9X0H
VWAVH
L$XHcB
L$\HcJ
D9X0H
L$8HcB
L$<HcJ
D1X0I
L$pH3
t$ WH
D$-Lc
T$0Hi
T$(H+
t$ WH
L$0H3
@USVWATAUAVAWH
D$pHcH
D$pHcH
D$pHcH
D$pHcH
A_A^A]A\_^[]
gfffffffH
L$0H3
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@SUVWATH
O(+O0
H+G8H
H+G8H
O(+O0
8OPtz
H+G8H
G(D+G0D
0A\_^][
l$ WAVAWH
D+z0A
O +O0
8OPtk
H+G8H
G D+G0D
@8oPtt
H+G8H
G D+G0D
 A_A^_
\$ UVWAVAWH
A_A^_^]
\$ UVWATAUAVAWH
I;U8v
A_A^A]A\_^]
@USVWAVH
A^_^[]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWH
L$8H3
\$ UVWAVAWH
A_A^_^]
@USVWAVH
A^_^[]
@SUVWAVH
s(+s0
@8kPt
L$@H3
PA^_^][
@SUVWAVAWH
s(D+s0D
K(+K0
8KPtk
H+C8H
C(D+C0D
L$@H3
XA_A^_^][
@SUVWATH
s(D+s0D
H+C8H
C(D+C0D
D+s0D
s(D+s0D
@8kPto3
H+C8H
C(D+C0D
@8kPt_3
H+C8H
C(D+C0D
K(+K0
8KPtk
H+C8H
C(D+C0D
@A\_^][
@SVWAVAWH
D$8Ic@
T$0H;T$8t
T$8H+
L$@H3
PA_A^_^[
@SVWAVH
L$8E3
L$@H3
XA^_^[
@USVWATAUAVAWH
g(D+g0D
H+O8H
G(D+G0D
W(+W0
O(+O0
8OPtm
H+G8H
G(D+G0D
xA_A^A]A\_^[]
@SUVWAVAWH
w(D+w0D
W(+W0
O(+O0
8OPtk
H+G8H
G(D+G0D
L$hH3
xA_A^_^][
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
VWATAVAWH
@A_A^A\_^
\$ UVWATAUAVAWH
\$0E3
)D$ L
`A_A^A]A\_^]
@SVWATAUAVAWH
D$0E3
D$0E3
\$ Mk
>HkL$@XH
`A_A^A]A\_^[
t$ WH
SUWAWH
HA__][
t$ WATAUAVAWH
\$ Ii
A_A^A]A\_
L$0H;
@SUVWATAUAVAWH
3333333
(D$ f
hA_A^A]A\_^][
@SUVWATAVAWH
H#U0H
0A_A^A\_^][
H#U0H
(D$ f
H#}0H
\$ UVWATAUAVAWH
d$PE3
(D$ f
`A_A^A]A\_^]
@SUVWAVAWH
8A_A^_^][
L$8H3
L$0H3
L$(H3
{ AVH
{ AVH
{ AVH
{ AVH
)L$@H
@USVWAVH
A^_^[]
\$ UVWAVAWH
A_A^_^]
@USVWATAVAWH
A_A^A\_^[]
@USVWATAVAWH
A_A^A\_^[]
@USVWAVH
A^_^[]
@USVWAVH
T$PE3
A^_^[]
\$ ATAVAWH
t$Hu)I
 A_A^A\
UVWATAUAVAWH
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
\$ UVWATAUAVAWH
A_A^A]A\_^]
[ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
[ UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
L$0H3
VWATAUAVH
D84:u
E84(u
@A^A]A\_^
l$0I+
t$ WH
@USVWATAUAVAWH
G8<4u
A_A^A]A\_^[]
USVWATAUAVAWH
)D$PD
)L$`H
A_A^A]A\_^[]
UVWATAUAVAWH
IcEPH
L;|$X
H;}HtBM
A_A^A]A\_^]
t$ WATAUAVAWH
t$8I;
A_A^A]A\_
@VWAVH
 A^_^
t:fff
 A^_^
 A^_^
@VWAVAWH
hA_A^_^
d$PI+
hA_A^_^
|$ AVH
t$@Ii
L$0M+
UWATAVAWH
A_A^A\_]
L$0H3
UWAVH
\$@H;
H#K0H
@USVWATAUAVAWH
seq(A
l$ E3
t$ E3
t$ E3
A_A^A]A\_^[]
L$PH3
|$ UATAUAVAWH
A_A^A]A\]
|$ AVH
|$ UATAUAVAWH
A_A^A]A\]
T$`H;
T$`H;
T$`H;
T$`H;
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWATAVAWH
A_A^A\_]
T$`H;
T$`H;
T$`H;
T$`H;
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWAVH
|$ UH
USVWH
|$ UH
|$ UH
|$ UH
T$`H;
T$`H;
T$`H;
T$`H;
UWAVH
|$ UH
|$ UH
UWATAVAWH
D$8E3
D$Pff
A_A^A\_]
UWAVH
T$`H;
UWAVH
UWATAVAWH
D$8E3
D$Pff
A_A^A\_]
UWAVH
T$`H;
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
T$`H;
T$`H;
T$`H;
T$`H;
UWAVH
|$ UAVAWH
A_A^]
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
|$ UH
UWAVH
UWAVH
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
T$`H;
T$`H;
UWAVH
T$`H;
T$`H;
T$`H;
T$`H;
UWAVH
UWAVH
|$ UAVAWH
A_A^]
UWAVH
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A^_^[]
@SVWATAUAVAWH
PA_A^A]A\_^[
@SUVAVH
(A^^][
t$ WAVAWH
 A_A^_
t$0ff
t$8H+
UWATAVAWH
A_A^A\_]
|$ UH
E0H9E
T$hH;T$pt
D$pH+
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D9p(u
D9p(u
A_A^A]A\]
UVWATAUAVAWH
C\$pH
t$ E3
CD$Pf
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
t$ WAVAWH
|$xH;
A_A^_
t$ WAVAWH
L$(H;
L$HH3
A_A^_
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
A_A^A\_]
UVWATAUAVAWH
C\$pH
t$ E3
CD$Pf
A_A^A]A\_^]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
)t$`H
T$8H+
L$PH3
(t$`H
t$ WH
L$@H3
T$8H+
L$XH3
T$8H+
L$PH3
@USVWAVH
E0H9E
T$hH;T$pt
D$pH+
A^_^[]
USVWH
T$`H;
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
USVWH
T$`H;
USVWH
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
t$ UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
D9`(t
A_A^A]A\]
|$ UATAUAVAWH
D9`(t
A_A^A]A\]
|$ UATAUAVAWH
D9`(t
A_A^A]A\]
t$ UWATAVAWH
A_A^A\_]
t$ WATAUAVAWH
D9`(t
A_A^A]A\_
|$ UH
t$ UWAVH
@USVWATAVAWH
A_A^A\_^[]
T$pH;
T$`H;
T$pH;
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
|$ UH
|$ UH
T$`H;
T$`H;
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWAVH
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
|$ UH
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
UWAVH
|$ UH
T$`H;
USVWH
USVWH
T$`H;
USVWH
UWAVH
UWATAVAWH
A_A^A\_]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
|$8ff
l$ VWATAVAWH
L$@E3
uTL9~
)D$ H
A_A^A\_^
|$ UH
|$ UH
t$ WH
|$ UH
|$ UH
UWAVH
t$ WH
t$ UWAVH
UVWATAUAVAWH
L$PLc
l$HIc
E(H+E H
t$8H;
D$(H;}
H;t$8
HcT$HI
A_A^A]A\_^]
|$ UATAUAVAWH
L$HE3
}(D9eP~pff
D$0I;
H;\$(
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
\$ UVWATAUAVAWH
t$ E9t$(t
t$ D;
D$(H;
D$(H;
D$(L;
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UH
|$ UH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A^_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
l$ VWAVH
D$(H;
L$XH3
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$8H+
p 9O(t
D$8H+
H;\$Hs
A_A^A]A\]
t$ WATAUAVAWH
A_A^A]A\_
VWATAVAWH
A_A^A\_^
t$ WATAUAVAWH
\$$u"I
;|$$|
A_A^A]A\_
UWATAVAWH
D9x(u
|$ H;]
tGfff
A_A^A\_]
|$ UH
t$ WATAUAVAWH
T$@E3
l$HL;l$X
A_A^A]A\_
UATAUAVAWH
;}'}nHc
A_A^A]A\]
t$ WATAUAVAWH
A_A^A]A\_
|$ UH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
VWATAVAWH
H+T$xH
A_A^A\_^
|$ UATAUAVAWH
D$8H+
p 9O(t
D$8H+
H;\$Hs
A_A^A]A\]
L$PH3
t$ WATAUAVAWH
T$@E3
A_A^A]A\_
l$HL;l$X
|$ UATAUAVAWH
A_A^A]A\]
B tXH
VWAUAVAWH
L$xH+
A_A^A]_^
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$(H;]
D$0I+
|$ fff
A_A^A]A\]
D$0N9$8
D$(J+<8x
t$ WATAUAVAWH
T$`I+
L$hH3
A_A^A]A\_
|$ UATAUAVAWH
A_A^A]A\]
t$$D;u
SUVWAVH
A^_^][
\$ UVWH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
(D$0f
(D$0f
D$0L;
(D$0f
A_A^A]A\]
|$ AVH
t$0fff
|$ UH
UWAVH
UWAVH
|$XH;
T$`H+
UWAVH
|$`H;
T$hH+
|$ UH
UWAVH
|$ UH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
T$pH;
x UATAUAVAWH
uXL9t$h
Ct$pH
|$ E3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
T$`H;
T$`H;
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
T$`H;
T$`H;
T$`H;
|$ UH
UWAVH
|$ UH
T$`H;
USVWH
T$`H;
UWAVH
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
UWAVH
|$ UH
|$ UH
UWAVH
t$ WH
@ 9A 
C 9A 
|$ UH
UVWAVAWH
A_A^_^]
|$ UATAUAVAWH
L$HE3
}(D9eP~pff
D$0I;
H;\$(
A_A^A]A\]
t$ WH
L$PH3
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@SVWATAUAVAWH
UUUUUUU
t$ I;
`A_A^A]A\_^[
|$ UATAUAVAWH
L$xL;
C(9F(
A_A^A]A\]
|$ UATAUAVAWH
L$pL;
C(9F(
A_A^A]A\]
|$ UATAUAVAWH
UUUUUUU
D$xI+
D$@H;t$x
A_A^A]A\]
WAVAWH
0A_A^_
|$ UATAUAVAWH
UUUUUUU
t$@L;
D$HI+
A9F(t>I
H;t$H
D$8I+
A_A^A]A\]
|$ UATAUAVAWH
EhH+E`H
E8H+E0H
UUUUUUU
D$pE3
A_A^A]A\]
t$ WATAUAVAWH
UUUUUUU
A_A^A]A\_
USVWH
T$`H;
|$ UH
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWAVH
USVWH
T$`H;
USVWH
T$`H;
UVWAVAWH
PA_A^_^]
VWAVH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
UWAVH
D$PE3
|$`H;
T$hH+
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@SVWH
@SVWH
@SVWH
@SVWH
t$ WH
UVWATAUAVAWH
Lcy H
A_A^A]A\_^]
|$ UH
|$ UATAUAVAWH
(D$0f
(D$0f
D$0L;
(D$0f
A_A^A]A\]
|$ UAVAWH
A_A^]
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
T$`H;
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWAVH
|$ UH
UWAVH
|$ UAVAWH
A_A^]
T$`H;
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
UWATAVAWH
D$8E3
D$Pff
A_A^A\_]
UWATAVAWH
D$8E3
D$Pff
A_A^A\_]
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
UWAVH
|$ UAVAWH
A_A^]
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$`E3
A_A^A]A\]
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@SUVWAVH
yxxxxxxxI
t$0I;
PA^_^][
|$ UAVAWH
A_A^]
UVWATAUAVAWH
C\$pH
t$ E3
CD$Pf
A_A^A]A\_^]
t$ WH
@ 9A uxH
C 9A 
UVWATAUAVAWH
A_A^A]A\_^]
UWATAVAWH
A_A^A\_]
t$ WH
\$@Hc
T$8H;T$@t
T$@H+
L$HH3
|$ UATAUAVAWH
A_A^A]A\]
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
D$PE3
D$PE3
D$PE3
D$PE3
A_A^A]A\_^]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
|$ UH
UVWATAUAVAWH
|$HE3
t$@H9t$X
H9t$X
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$pE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
|$ UAVAWH
A_A^]
UWAVH
UWAVH
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$pE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$xE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$pE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$pE3
A_A^A\_]
UWATAVAWH
D$pE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWAUAVAWH
A_A^A]_]
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
t$ HcU
A_A^A]A\]
|$ UATAUAVAWH
D9p(u
L$(H+
tGfff
\$ H;U
A_A^A]A\]
L$PH3
VWAVH
t$8I;
t$ I;
T$8H+
L$@H3
PA^_^
|$ UATAUAVAWH
A_A^A]A\]
@USVWAVH
@ HcX 
|$@H;
L$HH+
gfffffffH
A^_^[]
t$ WATAUAVAWH
L$PH3
A_A^A]A\_
t$ WAVAWH
A_A^_
|$ UATAUAVAWH
A_A^A]A\]
VWAVH
t$ WATAUAVAWH
t9E9w
D9p(u
A_A^A]A\_
|$ UATAUAVAWH
D$8H+
p 9O(t
D$8H+
H;t$Hs
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
M'H+M
H;U't
t$ WATAUAVAWH
D$ E3
L$PH3
A_A^A]A\_
|$ UATAUAVAWH
D$@H+
t$ ;u
L$(I+
A_A^A]A\]
L$PH3
UWAVH
D$PE3
|$ UAVAWH
D$`E3
A_A^]
\$ WH
UWAVH
UWAVH
UWAVH
|$ UH
UWAVH
UWATAVAWH
A_A^A\_]
|$ UAVAWH
A_A^]
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
D$pI+
D$xI+
A_A^A]A\]
|$ UATAUAVAWH
UUUUUUU
M`H;Mht
H;U t
D$pH+
D$XI+
D$HH;t$X
A_A^A]A\]
|$ UATAUAVAWH
EhH+E`H
E8H+E0H
UUUUUUU
H;UXt
D$pL;}
A_A^A]A\]
|$ UATAUAVAWH
D$XE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
D$hff
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$XE3
A_A^A]A\]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
A_A^A\_]
|$ UH
U'u<I+
UWATAVAWH
H;U't
A_A^A\_]
t$ WATAUAVAWH
D$0D;
A_A^A]A\_
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
D9`(t
A_A^A]A\]
t$ UWAVH
@83tdH
|$ UH
USVWAVH
A^_^[]
UWAVH
|$XH;
T$`H+
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$XE3
A_A^A\_]
UWAVH
UWATAVAWH
A_A^A\_]
UWAVH
D$`E3
USVWH
|$ UATAUAVAWH
A_A^A]A\]
|$ UAVAWH
A_A^]
UWAVH
UWAVH
D$pE3
|$ UAVAWH
D$`E3
A_A^]
UWAVH
|$ UAVAWH
D$`E3
A_A^]
UWAVH
|$ UH
@SUVWATAVAWH
D$ L;
L$@H3
PA_A^A\_^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
s WAVAWH
@A_A^_
UWATAVAWH
A_A^A\_]
VWAVH
T$XH+
L$`H3
|$ UATAUAVAWH
A_A^A]A\]
|$ UAVAWH
A_A^]
UWATAVAWH
A_A^A\_]
L$8H3
L$8H3
L$8H3
L$8H3
SVWATAUAVAWH
D$0H+
L+d$HI
`A_A^A]A\_^[
`A_A^A]A\_^[
SVWATAUAVAWH
D$0H+
L+d$HI
`A_A^A]A\_^[
`A_A^A]A\_^[
VWAVH
0A^_^
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
UVWAVAWH
D$pH9D$@uf
D$HuC
A_A^_^]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
\$ UVWATAUAVAWH
l$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWAVAWH
HcFXH
HcFpH
A_A^_^]
WATAUAVAWH
IcGPH
IcGhH
IcGPH
IcG8H
IcG L
A_A^A]A\_
@USVWATAVAWH
A_A^A\_^[]
HcFPH
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
l$HE3
A_A^A]A\_^]
\$@H;
t$ AVH
UVWATAUAVAWH
yxxxxxxxI
yxxxxxxxH
@A_A^A]A\_^]
AUAWH
yxxxxxxxM+
yxxxxxxxI
D$XL;
8A_A]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A^_^[]
t$ UWATAVAWH
N H;H 
A_A^A\_]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
l$ VWATAVAWH
A_A^A\_^
@USVWATAUAVAWH
HcGPH
t.H;O
t+H;K
A_A^A]A\_^[]
@USVWATAUAVAWH
UUUUUUU
IcGhL
IcGPH
|$PE3
A_A^A]A\_^[]
@SVWATAUAVAWH
S H+S
S H+S
IcGPH
IcGhH
IcG8H
H;t$PtpH
|$pH;
H;t$XtpH
IcG H
McG N
HcGPH
t$PH;t$p
A_A^A]A\_^[
[ UVWH
D9G(u
D9G(u
\$ UVWATAUAVAWH
T$xE3
C D9x u
H;l$`
HcPhH
Hc@hI
A_A^A]A\_^]
\$ UVWATAUAVAWH
|$HH;
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
D$0H+
D$0H+
)D$@H
|$ AVH
\$ VH
l$0ff
t$ AVH
L$0M+
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
H9w u@
A_A^A]A\_^]
AVAWH
(A_A^
VWAVH
@WATAUAVAWH
@A_A^A]A\_
@SUVWATAVAWH
A_A^A\_^][
VWAVH
 A^_^
@SUVWAVH
L$8H3
@A^_^][
@SVWH
d$HH;
l$@tNH
VWAVH
HcUhH
 A^_^
@USVWATAVAWH
PA_A^A\_^[]
@SVWH
 t'I;
@t*H;
l$@tNH
@SUVWAVH
L$8H3
@A^_^][
l$ VH
\$8t'H
@SUVWAVH
L$8H3
@A^_^][
@SVWH
l$@tNH
t$ E3
t$ H;
\$ UVWAVAWH
L$8H3
@A_A^_^]
@SVWH
l$`H;
l$PtNH
@SUVWAVH
L$HH3
PA^_^][
VWATAVAWH
L$HH3
A_A^A\_^
@USVWATAVAWH
A_A^A\_^[]
WATAUAVAWH
r!fff
 t*H;
 A_A^A]A\_
@SUVWAVH
L$HH3
PA^_^][
WAVAWH
 A_A^_
\$ UVWAVAWH
L$@H3
PA_A^_^]
l$ VH
L$8H3
t$@tXH
@SUVWAVH
L$@H3
PA^_^][
@SUVWAVH
L$8H3
@A^_^][
@SUVWAVH
L$@H3
PA^_^][
\$ UVWAVAWH
L$8H3
@A_A^_^]
@SUVWAVH
L$@H3
PA^_^][
t$ WAVAWH
 A_A^_
\$ UVWAVAWH
L$8H3
@A_A^_^]
t$ WATAUAVAWH
 A_A^A]A\_
t$ WAVAWH
 A_A^_
@USVWATAVAWH
pA_A^A\_^[]
\$ UVWATAUAVAWH
 t1H;
@t1H;
 A_A^A]A\_^]
@SUVWAVH
L$8H3
@A^_^][
t$ WAVAWH
 A_A^_
\$ UVWAVAWH
L$8H3
@A_A^_^]
WATAUAVAWH
 A_A^A]A\_
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
VWAVH
 A^_^
VWAVH
 A^_^
VWAVH
 A^_^
VWAVH
 A^_^
VWAVH
 A^_^
VWAVH
 A^_^
VWAVH
 A^_^
KhH99t
KpH99t
KxH99t
K H99t
K H99t
K H99t
L$0H3
L$0H3
L$0H3
L$(H3
L$(H3
t$ E3
t$ H;
\$ UVWAVAWH
L$@H3
PA_A^_^]
@SVWH
l$@tNH
VWAVH
 A^_^
@SUVWAVH
L$PH3
`A^_^][
WATAUAVAWH
 A_A^A]A\_
\$ UVWAVAWH
L$@H3
PA_A^_^]
@t&H;
 t1H;
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
@SVWH
CX9{Pu
L$(H3
L$0H3
L$0H3
L$0H3
T$ E3
SVWAVH
8A^_^[
WAVAWH
\$8H;
A_A^_
WAVAWH
0A_A^_
x AVH
\D$ fH
T$ H;
\L$ f
L$ A;
HcU0H
SUVWH
SUVWH
SUVWH
(_^][
SUVWH
SUVWH
@UAUH
@UAUH
Unknown exception
bad array new length
string too long
(cannot determine missing fields for lite message)
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\message_lite.cc
Can't 
 message of type "
" because it is missing required fields: 
parse
 exceeded maximum protobuf size of 2GB: 
vector too long
WARNING
ERROR
FATAL
[libprotobuf %s %s:%d] %s
%I64u
00010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
?456789:;<=
 !"#$%&'()*+,-./0123
456789:;<=
 !"#$%&'()*+,-./0123
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_
false
invalid string position
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - SerialArena::kBlockHeaderSize): 
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google/protobuf/parse_context.h
Can't happen
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream_impl_lite.cc
CHECK failed: (count) >= (0): 
CHECK failed: backup_bytes_ == 0 && buffer_.get() != NULL: 
 BackUp() can only be called after Next().
CHECK failed: (count) <= (buffer_used_): 
 Can't back up over more bytes than were returned by the last call to Next().
 Parameter to BackUp() can't be negative.
CHECK failed: (backup_bytes_) == (0): 
CHECK failed: (buffer_used_) == (buffer_size_): 
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream_impl.cc
close() failed: 
CHECK failed: !is_closed_: 
INVALID_ARGUMENT
map/set too long
unordered_map/set too long
invalid hash bucket count
bad allocation
 was false.
Stacktrace:
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/data_types_internal.h
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/tensor.h
CPUExecutionProvider
Tensor sequence must contain only primitive types
elem_type_ != nullptr
onnxruntime::TensorSeq::SetType
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/TensorSeq.h
i < tensors_.size()
onnxruntime::TensorSeq::Get
Trying to get a Tensor, but got: 
IsTensor()
OrtValue::Get
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/ort_value.h
OrtValue::GetMutable
Trying to get a TensorSeq, but got: 
IsTensorSequence()
Trying to get a SparseTensor, but got: 
IsSparseTensor()
ORT_LOAD_CONFIG_FROM_MODEL
Integer overflow
SafeIntExceptionHandler<class onnxruntime::OnnxRuntimeException>::SafeIntOnOverflow
D:\a\_work\1\s\onnxruntime\onnxruntime\core/common/safeint.h
tried creating tensor with negative value in shape
size overflow
, got 
not enough space: expected 
Not able to find appropriate IDataTransfer to copy sparse data
`anonymous-namespace'::GetDataTransfer
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\onnxruntime_c_api.cc
Strings can only reside in CPU memory
`anonymous-namespace'::ValidateFillInputArgs
tried Filling sparse tensor with negative value in values shape
OrtApis::FillSparseTensorCoo
OrtApis::FillSparseTensorCsr
tried Filling sparse tensor with negative value in block sparse indices shape
OrtApis::FillSparseTensorBlockSparse
Can not use strings in pre-allocated memory. Use CreateSparseTensorAsOrtValue() to allocate memory inside and copy
OrtApis::UseCooIndices
OrtApis::UseCsrIndices
OrtApis::UseBlockSparseIndices
the ort_value must contain a constructed tensor
Use GetStringTensor*() API to retrieve strings
RegisterCustomOpsLibrary: Failed to load library
RegisterCustomOps
RegisterCustomOpsLibrary: Entry point RegisterCustomOps not found in library
EnableOrtCustomOps: Custom operators in onnxruntime-extensions are not enabled
onnxruntime_profile_
input name cannot be empty
output name cannot be empty
lengths allocation failed
string buffer allocation failed
Output buffer allocation failed
input array doesn't equal tensor size
element index is out of bounds
OrtValue should contain a Tensor or a Sparse Tensor
Sparse Tensor does not contain sparse data
This API supports Tensors or SparseTensors
shape is invalid
index is out of bounds
offsets buffer is not equal to tensor size
output buffer is too small. Use GetStringTensorDataLength.
buffer size is too small for string element
out of index
internal error
index out of range
Input is not of one of the supported sequence types.
Input is not of type sequence or map.
input array is too short
Input is not of one of the supported map types.
Expecting all elements to be tensors. Got: 
in[idx]->IsTensor()
OrtCreateValueImplSeqHelper
Sequences must have tensors of the same data type. There was at least one tensor in the input that was different.
Each element of the sequence should be either tensor or map.
At least one element in the sequence is of a type different from others.
Unsupported input type
For map type num_values MUST be 2
Either the key tensor or the value tensor has NumDimensions > 1
Key and value tensors have unequal number of elements.
Key type is not supported yet.
Number of values should be at least 1.
opaque(
Specified domain and type names combination does not refer to a registered opaque type
ml_type != nullptr
OrtApis::CreateOpaqueValue
Opaque type is not a non_tensor type!!!
non_tensor_base != nullptr
OrtApis::GetOpaqueValue
this API does not support strings
location dimensions do not match shape size
invalid location range
max_mem
arena_extend_strategy
initial_chunk_size_bytes
max_dead_bytes_per_chunk
initial_growth_chunk_size_bytes
Invalid key found: 
The given version [%u] is not supported, only version 1 to %u is supported in this build.
1.9.1
Tensor type mismatch. 
utils::IsPrimitiveDataType<T>(dtype_)
onnxruntime::Tensor::MutableData
onnxruntime::Tensor::DataAsSpan
Invalid index requested for map type.
Tensor must always contain primitive types. Found: 
value_type != nullptr
OrtCreateValueImplMapHelper
Value type is not supported yet: 
Map is missing type entry for its value
++index < c.size()
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,double,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,double> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,__int64,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,__int64> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,double,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,double> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,__int64> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > > >::check
Sequence is missing type entry for its element
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::vector<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > >,class std::allocator<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > > > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::vector<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > >,class std::allocator<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > > > > >::check
invalid vector subscript
onnxruntime::DataTypeImpl::GetType<T>() == type_
len >= 0 && static_cast<uint64_t>(len) < std::numeric_limits<size_t>::max()
OrtCreateMapMLValue
onnxruntime::Tensor::Data
not implemented
execution_mode is not valid
graph_optimization_level is not valid
 is not implemented
onnxruntime::OpKernel::ComputeAsync
Result buffer is not large enough
' in custom op '
Unsupported version '
onnxruntime::CustomOpKernel::CustomOpKernel
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\custom_ops.cc
custom op registered at runtime
Input
all types
There must be one (and only one) dynamic typed input to the custom op. Its type info at runtime will be used to infer the type info of this dynamic typed output which is required for the success of the model loading step. More than one dynamic typed inputs are currently not supported as differing types at runtime means the output type cannot be inferred without which model loading cannot proceed.
type_id_counter == 1
onnxruntime::CreateCustomRegistry
Output
No requested allocator available
Env is null
OrtMemoryInfo is null
Provided allocator is null
Please register the allocator as OrtDeviceAllocator even if the provided allocator has arena logic built-in. OrtArenaAllocator is reserved for internal arena logic based allocators only.
Provided OrtMemoryInfo is null
TensorSeq: tensor to be added has a different data type.
IsSameDataType(tensor)
onnxruntime::TensorSeq::Add
invalid unordered_map<K, T> key
Tensor type mismatch.
type == dtype_
onnxruntime::Tensor::MutableDataRaw
onnxruntime::Tensor::DataRaw
) != new size (
Tensor size (
shape_.Size() == new_shape.Size()
onnxruntime::Tensor::Reshape
Missing Input: 
onnxruntime::OpKernelContext::Input
Required input at index 
input_ptr
onnxruntime::OpKernelContext::RequiredInput
 is not present.
Required output at index 
output_ptr
onnxruntime::OpKernelContext::RequiredOutput
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/op_kernel_context.h
Please fetch output tensor with specified shape.
p_ml_value
onnxruntime::OpKernelContext::Output
onnxruntime_providers_cuda.dll
onnxruntime_providers_dnnl.dll
onnxruntime_providers_openvino.dll
onnxruntime_providers_tensorrt.dll
Attempt to use DefaultLogger but none has been registered.
onnxruntime::logging::LoggingManager::DefaultLogger
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/common/logging/logging.h
onnxruntime_providers_shared.dll
onnxruntime::ProviderSharedLibrary::Ensure
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\provider_bridge_ort.cc
Provider_SetHost
onnxruntime::ProviderLibrary::Get
GetProvider
SessionOptionsAppendExecutionProvider_Tensorrt: Failed to load shared library
SessionOptionsAppendExecutionProvider_OpenVINO: Failed to load shared library
CUDA execution provider is either not enabled or not available.
OrtSessionOptionsAppendExecutionProvider_Cuda: Failed to load shared library
TensorRT execution provider is not enabled in this build.
? execution provider is not enabled in this build. 
bad cast
 DeviceId:
 MemoryType:
DeviceType:
Device:[
 OrtAllocatorType:
 OrtMemType:
name:
OrtMemoryInfo:[
CUDAExecutionProvider
TensorrtExecutionProvider
DmlExecutionProvider
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/graph/graph.h
 Max:
Validating no unexpected access using an invalid node_index. Got:
node_index < nodes_.size()
onnxruntime::Graph::NodeAtIndexImpl
 has already been registered.
Provider 
onnxruntime::ExecutionProviders::Add
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/execution_providers.h
onnxruntime::FeedsFetchesInfo::FeedsFetchesInfo
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/feeds_fetches_manager.h
Compute_
Create_State_
Release_State_
MemcpyTransformer
[json.exception.
other_error
session.use_env_allocators
session.load_model_format
session.save_model_format
session.set_denormal_as_zero
session.inter_op.allow_spinning
session.intra_op.allow_spinning
session.use_ort_model_bytes_directly
memory.enable_memory_arena_shrinkage
%Y-%m-%d_%H-%M-%S
) node with name '
Could not find an implementation for 
Node placements
onnxruntime::`anonymous-namespace'::VerifyEachNodeIsAssignedToAnEp
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\inference_session.cc
All nodes have been placed on [
 Provider: [
The environment variable contained the value: 
 are '0' and '1'. 
The only supported values for the environment variable 
Reading the provided model for the ORT config
onnxruntime::FinalizeSessionOptions
ModelProto needs to be parsed to check for ORT config within it
is_model_proto_parsed
Flush-to-zero and denormal-as-zero are 
onnxruntime::InferenceSession::ConstructorCommon::<lambda_0e15e5d5aa95f1a51f4a785eaf45e6b8>::operator ()
Could not finalize session options while constructing the inference session. Error Message: 
status.IsOK()
onnxruntime::InferenceSession::ConstructorCommon
graph_transformation_mgr_.SetSteps(session_options_.max_num_graph_transformation_steps).IsOK()
Creating and using per session threadpools since use_per_session_threads_ is true
-intra-op
session-
-inter-op
Failed to create the inter-op thread pool for the parallel executor, setting ExecutionMode to SEQUENTIAL
Using global/env threadpools since use_per_session_threads_ is false
When the session is not configured to use per session threadpools, the env must be created with the the CreateEnvWithGlobalThreadPools API.
session_env.EnvCreatedWithGlobalThreadPools()
CastFloat16Transformer
Given model could not be parsed while creating inference session. Error message: 
onnxruntime::InferenceSession::InferenceSession
Could not parse model successfully while constructing the inference session
result
Error during EndProfiling(): 
onnxruntime::InferenceSession::{dtor}::<lambda_a519b6e9add21bc5a171f3815c354af4>::operator ()
Unknown error during EndProfiling()
onnxruntime::InferenceSession::~InferenceSession
Received nullptr for exec provider
Execution providers must be registered before the session is initialized. 
onnxruntime::InferenceSession::RegisterExecutionProvider
Execution providers must be registered before the session is initialized.
So disabling it for this session since it uses the DML Execution Provider.
Having memory pattern enabled is not supported while using the DML Execution Provider. 
So making the execution mode sequential for this session since it uses the DML Execution Provider.
Parallel execution mode does not support the DML Execution Provider. 
So making the execution mode sequential for this session since it uses the CUDA Execution Provider.
Parallel execution mode does not support the CUDA Execution Provider. 
onnxruntime::InferenceSession::AddCustomOpDomains
Received nullptr for custom registry
onnxruntime::InferenceSession::SaveToOrtFormat
Exception during loading: 
This session already contains a loaded model.
onnxruntime::InferenceSession::Load
Unknown exception in Load()
Encountered unknown exception in Load()
ModelProto corresponding to the model to be loaded has already been parsed. Invoke Load().
Failed to load model because protobuf parsing failed.
model_loading_array
ModelProto corresponding to the model to be loaded has not been parsed yet. This API should be called in conjunction with a ctor that takes a model abstraction.
model_loading_from_saved_proto
onnxruntime::InferenceSession::TransformGraph
onnxruntime::InferenceSession::LoadOrtModel::<lambda_73f4f6c8b9b724afe3a51b52c953b043>::operator ()
onnxruntime::InferenceSession::LoadOrtModel
This session has already been initialized.
ORT model verification failed.
InferenceSession is null. Invalid ORT format model.
Serialized version info is null. Invalid ORT format model.
] is not supported this build 
The ORT format model version [
Missing Model. Invalid ORT format model.
SessionState is null. Invalid ORT format model.
The provided PrePackedWeightsContainer instance to be added to the session is null
The session already has a PrePackedWeightsContainer instance
onnxruntime::`anonymous-namespace'::PartitionOrtFormatModel
onnxruntime::`anonymous-namespace'::AssignNodesToEpsFromHashesImpl
) in kernel registries for 
Failed to find kernel def hash (
onnxruntime::`anonymous-namespace'::AssignNodesToEpsFromHashes
Exception during initialization: 
onnxruntime::InferenceSession::Initialize::<lambda_a2cf5da4633fe38d7764ecb46be458f0>::operator ()
onnxruntime::InferenceSession::Initialize::<lambda_70b0efa2ae1aad498367f6dea88529b8>::operator ()
Initializing session.
onnxruntime::InferenceSession::Initialize
Model was not loaded
Model was not loaded.
Session has already been initialized.
Adding default CPU execution provider.
This session will use the allocator registered with the environment.
loading_ort_format && serialized_session_state != nullptr
Unable to serialize model as it contains compiled nodes. Please disable any execution providers which generate compiled nodes.
NchwcTransformer
Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.
Session successfully initialized.
Encountered unknown exception in Initialize()
session_initialization
 Please fix either the inputs or the model.
 Expected: 
 Got: 
Invalid rank for input: 
 for the following indices
Got invalid dimensions for input: 
 index: 
Unexpected input data type. Actual: (
)) , expected: (
 elements.
elements, but feeds has 
Size mismatch: feed_names has 
Invalid Feed Input Name:
 is not expected to be of type tensor.
Input with name: 
tensor
onnxruntime::InferenceSession::ValidateInputs
 is not expected to be of type sparse tensor.
sparse_tensor
 is not expected to be of type tensor sequence.
Output vector pointer is NULL
At least one output should be requested.
p_fetches->size(): 
Output vector incorrectly sized: output_names.size(): 
Invalid Output Name:
Session was not initialized
onnxruntime::InferenceSession::Run
Session not initialized.
Running with tag: 
Encountered unknown exception in Run()
model_run
onnxruntime::InferenceSession::GetModelMetadata
onnxruntime::InferenceSession::GetModelInputs
onnxruntime::InferenceSession::GetOverridableInitializers
onnxruntime::InferenceSession::GetModelOutputs
onnxruntime::InferenceSession::NewIOBinding
Profiler is disabled.
onnxruntime::InferenceSession::EndProfiling
Could not write a profile because no model was loaded.
Unsupported device specified in the memory arena shrink list: 
Unsupported device id in the memory arena shrink list: 
 combination in the memory arena shrink list: 
Did not find an arena based allocator registered for device-id 
 combination is not an arena based allocator: 
The registered allocator for device-id 
 error message: 
Unable to shrink arena: 
onnxruntime::InferenceSession::ShrinkMemoryArenas
Invalid run log severity level. Not a valid onnxruntime::logging::Severity value: 
run_options.run_log_severity_level >= 0 && run_options.run_log_severity_level <= static_cast<int>(logging::Severity::kFATAL)
onnxruntime::InferenceSession::CreateLoggerForRun
Invalid session log severity level. Not a valid onnxruntime::logging::Severity value: 
session_options_.session_log_severity_level >= 0 && session_options_.session_log_severity_level <= static_cast<int>(logging::Severity::kFATAL)
onnxruntime::InferenceSession::InitLogger
961c151d2e87f2686a955a9be24d316f1362bf21 3.9.1
.json
model_loading_uri
 failed:
Load model from 
onnxruntime::LoadOrtModelBytes
 bytes were able to be read.
 failed. Only 
list too long
localtime_s(&local_tm, &in_time_t) == 0
onnxruntime::`anonymous-namespace'::GetCurrentTimeString
onnxruntime::IOBinding::BindInput
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\IOBinding.cc
p_provider
env_ptr == p_instance_
OrtEnv::Release
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\ort_env.cc
session_options
value
parse error
parse_error
, column 
 at line 
invalid_iterator
type_error
out_of_range
ort_config
Unsupported value for intra_op_num_threads: 
onnxruntime::SetIntraOpNumThreads
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\inference_session_utils.cc
Setting intra_op_num_threads to 
Unsupported value for inter_op_num_threads: 
onnxruntime::SetInterOpNumThreads
Setting inter_op_num_threads to 
Unsupported execution_mode value in ORT config: 
onnxruntime::SetExecutionMode
Sequential mode
Parallel mode
Setting execution_mode to 
Setting graph_optimization_level to ORT_DISABLE_ALL
onnxruntime::SetGraphOptimizationLevel
Setting graph_optimization_level to ORT_ENABLE_BASIC
Setting graph_optimization_level to ORT_ENABLE_EXTENDED
Setting graph_optimization_level to ORT_ENABLE_ALL
Unsupported graph_optimization_level value in ORT config: 
Unsupported value for enable_profiling option: 
onnxruntime::SetEnableProfiling
Setting enable_profiling to 
Json stored in the `ort_config` key cannot be parsed. Error message: 
onnxruntime::inference_session_utils::JsonConfigParser::ParseOrtConfigJsonInModelProto::<lambda_98c68a30f5b1cb5acbbe1d8255ff290f>::operator ()
The Model Proto has already been checked for the ORT config json.
Found session/run/environment configuration in the model file to be used while running the model
onnxruntime::inference_session_utils::JsonConfigParser::ParseOrtConfigJsonInModelProto
ORT config json from the model: 
The Model Proto hasn't been checked for the ORT config json.
Did not find session options in the model file to be used while running the model
onnxruntime::inference_session_utils::JsonConfigParser::ParseSessionOptionsFromModelProto
intra_op_num_threads
intra_op_num_threads option in the model file must be an integer
inter_op_num_threads
inter_op_num_threads option in the model file must be an integer
execution_mode
execution_mode option in the model file must be an integer
graph_optimization_level
graph_optimization_level option in the model file must be an integer
enable_profiling
enable_profiling option in the model file must be an integer
Ignoring unsupported session option in ORT config: 
' not found
key '
cannot use at() with 
cannot use key() for non-object iterators
invalid map<K, T> key
object
array
string
boolean
binary
discarded
number
cannot compare iterators of different containers
cannot get value
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<U+%.4X>
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid literal
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
invalid comment; missing closing '*/'
invalid comment; expecting '/' or '*' after '/'
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
vector<bool> too long
object key
object separator
number overflow parsing '
excessive array size: 
excessive object size: 
iterator does not fit current value
iterator out of range
cannot use erase() with 
type must be number, but is 
com.microsoft
com.microsoft.experimental
com.microsoft.nchwc
com.microsoft.mlfeaturizers
Input type was null
[TypeInferenceError] 
 expected to have tensor or sparse tensor type. Got: 
Input 
 unknown
Element type of input 
Output 
 expected to have sequence type
 expected to have sequence type. Got: 
 expected to have type but instead is null
 Target=
Mismatch between source and target type. Source=
[ShapeInferenceError] 
Unsupported Source/Target type=
unknown
tensor(uint32)
tensor(uint64)
tensor(int32)
tensor(int64)
tensor(float16)
tensor(float)
tensor(double)
tensor(bfloat16)
tensor(uint8)
tensor(uint16)
tensor(int8)
tensor(int16)
seq(tensor(uint8))
seq(tensor(uint16))
seq(tensor(uint32))
seq(tensor(uint64))
seq(tensor(int8))
seq(tensor(int16))
seq(tensor(int32))
seq(tensor(int64))
seq(tensor(float16))
seq(tensor(float))
seq(tensor(double))
tensor(string)
tensor(bool)
tensor(complex64)
tensor(complex128)
seq(tensor(string))
seq(tensor(bool))
seq(tensor(complex64))
seq(tensor(complex128))
Schema error: 
 line 
, but it is already registered from file 
) from file 
 version: 
 (domain: 
Trying to register schema with name 
 known by the checker.
, but its domain is not
in onnx/defs/schema.h).
forgot to update the version range in DomainToVersionRange 
bumped the operator version but 
] (usually, this means you 
in the inclusive range [
, but its version is not 
Only CPU allocators can be shared between multiple sessions for now.
An allocator for this device has already been registered for sharing.
Only CPU devices are supported for now.
Received invalid value for arena extend strategy. Valid values can be either 0, 1 or -1.
No allocator for this device has been registered for sharing.
seq(tensor(bfloat16))
Exception caught: 
intra-op
inter-op
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\environment.cc
MemcpyFromHost
input
output
Constrain to all fixed size tensor and sequence types. If the dtype attribute is not provided this must be a valid output type.
MemcpyToHost
onnxruntime::GraphTransformer::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\graph_transformer.cc
onnxruntime::GraphTransformerManager::ApplyTransformers
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\graph_transformer_mgr.cc
This transformer is already registered 
onnxruntime::GraphTransformer::Recurse
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/optimizer/graph_transformer.h
InsertedCast_
cast node to cast from float16 to float32 on cpu
RemoveDuplicateCastTransformer
onnxruntime::RemoveDuplicateCastTransformer::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\insert_cast_transformer.cc
onnxruntime::InsertCastTransformer::ApplyImpl
dtype
InsertCastTransformer works on the assumption that `dtype` attribute holds an integer.
dtype_attribute->second.has_i()
ACLExecutionProvider
ArmNNExecutionProvider
ROCMExecutionProvider
AttentionFusion
BiasGeluFusion
BiasSoftmaxFusion
CastElimination
CommonSubexpressionElimination
ConvActivationFusion
ConvAddFusion
ConvBNFusion
ConvMulFusion
DivMulFusion
EliminateDropout
Dropout
DynamicQuantizeMatMulFusion
EmbedLayerNormFusion
ExpandElimination
Expand
FastGeluFusion
GeluApproximation
GeluFusion
GemmActivationFusion
GemmTransposeFusion
EliminateIdentity
Identity
LayerNormFusion
SimplifiedLayerNormFusion
MatMulAddFusion
MatMulIntegerToFloatFusion
MatMulScaleFusion
NhwcTransformer
NoopElimination
NotWhereFusion
Where
FuseReluClip
ReshapeFusion
SkipLayerNormFusion
EliminateSlice
Slice
UnsqueezeElimination
Unsqueeze
QDQPropagationTransformer
QDQS8ToU8Transformer
ReluQuantRewrite
session.disable_quant_qdq
optimization.enable_gelu_approximation
MatmulTransposeFusion
BiasDropoutFusion
_RuleBasedTransformer
Level
Unsupported level
onnxruntime::optimizer_utils::GenerateRewriteRules
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\graph_transformer_utils.cc
Unsupported level 
onnxruntime::optimizer_utils::GenerateTransformers
VitisAIExecutionProvider
onnxruntime::Node::ForEachWithIndex
onnxruntime::MemcpyTransformer::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\transformer_memcpy.cc
onnxruntime::TransformerMemcpyImpl::ProcessDefs
' doesn't support memcpy 
Execution type '
Memcpy
Copy from/to host memory
dup_replacements.find(&arg) == dup_replacements.end()
onnxruntime::TransformerMemcpyImpl::ProcessInitializers::<lambda_02dc3923ff80c6ae48f6f7d0552bad14>::operator ()
onnxruntime::TransformerMemcpyImpl::ProcessInitializers
onnxruntime::RuleBasedGraphTransformer::ApplyRulesOnNode
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\rule_based_graph_transformer.cc
onnxruntime::RuleBasedGraphTransformer::ApplyImpl
onnxruntime::Initializer::Initializer
D:\a\_work\1\s\onnxruntime\onnxruntime\core/optimizer/initializer.h
size is different
size_ == size
unsupported data type: 
ReadExternalRawData() failed: 
input_indices.size() == expected_values.size() && input_indices.size() > 0
onnxruntime::AttentionFusionHelper::CheckSliceParameters
D:\a\_work\1\s\onnxruntime\onnxruntime\core/optimizer/attention_fusion_helper.h
Slice does not have enough number of inputs
Slice ends is less than INT_MAX
Expected value:
Slice parameter is not expected. Input index:
Start MatchGemmSubgraph
onnxruntime::AttentionFusionHelper::MatchGemmSubgraph
Reshape
Concat
Squeeze
Shape
Faild to match gemm path
Input of reshape_before_gemm is not the input of subgraph
Output edge count not expected for nodes in gemm path
Gemm does not have 3 inputs
Gemm bias is not constant
Gemm bias shape not expected
CheckSliceParameters return false
concat first input value is not -1
Faild to match concat node for Gather paths
concat_after_gather does not have expected number of inputs or output edges
concat_after_gather input 2 does not have expected value
Gather
Faild to match gemm gather path
Output edge count not expected for nodes in gemm gather path
unsqueeze_after_gather axes value not expected
gather axis value not expected
gather input 1 value is not expected
Pass MatchGemmSubgraph
Start ValidateGemmInitializer
onnxruntime::AttentionFusionHelper::ValidateGemmInitializer
Gemm bias is not constant initializer
Gemm bias shape is not expected
Gemm weight is not constant initializer
Gemm weight shape is not expected
Pass ValidateGemmInitializer
unidir mask is not constant
onnxruntime::AttentionFusionHelper::ValidateUnidirMask
unidir mask shape not expected
This optimizer does not support external data for unidirectional mask right now
Mask is neither unidirectional nor all ones
Expect mask data type is uint8 or float
Start MatchUnidirMaskSubgraph
onnxruntime::AttentionFusionHelper::MatchUnidirMaskSubgraph
Faild to match the path (Div-->Where-->Add) for unidirectional mask
Faild to match path 1 for unidirectional mask
Output edge count not expected for nodes in path 1 of unidirectional mask
Div and Shape1 does not have edge
CheckSliceParameters returns false for last_slice
CheckSliceParameters returns false for mask_slice
ValidateUnidirMask returns false for mask_slice
CheckSliceParameters returns false for slice1
Faild to match path 2 for unidirectional mask
Output edge count not expected for unsqueeze2 of unidirectional mask
Faild to match path 3 for unidirectional mask
Output edge count not expected for unsqueeze3 of unidirectional mask
Faild to match path 4 for unidirectional mask
Div and Shape does not have edge
Output edge count not expected for squeeze_2/slices2/shape2 of unidirectional mask
CheckSliceParameters return false for slice2
Pass MatchUnidirMaskSubgraph
Start MatchInputMaskSubgraph
onnxruntime::AttentionFusionHelper::MatchInputMaskSubgraph
Softmax
Failed to find Softmax node
Output edge count not expected for Softmax
Failed to find path for mask
Output edge count not expected for mask nodes
Softmax attribute axis is expected to be 3
mask_unsqueeze_1 axes not matched. Expect: 1
mask_unsqueeze_2 axes not matched. Expect: 2
mask_sub const input not matched
mask_mul const input not matched
Pass MatchInputMaskSubgraph
Start MatchInputMaskSubgraphDistilBert
Equal
Failed to find mask path
where const not matched.
MatMul
Failed to find shape path
equal const not matched.
Failed to find reshape shape path 1
Failed to find reshape shape path 2
gather indices not matched.
Pass MatchInputMaskSubgraphDistilBert
Start MatchPastSubgraph
onnxruntime::AttentionFusionHelper::MatchPastSubgraph
Transpose
Failed to find path for past_k
Failed to find path for present_k
Failed to find path for present_v and past_v
Failed to match v_concat
past_k_transpose perm attribute not matched
present_k_transpose perm attribute not matched
present_k_unsqueeze axes value not expected
present_v_unsqueeze axes value not expected
past_v_gather indices != 1
past_k_gather indices != 0
past_v_gather and past_k_gather does not have same past input
Output edge count not expected for nodes in past subgraph
Pass MatchPastSubgraph
onnxruntime::AttentionFusionHelper::CheckDistilBertReshapeShape
Start CheckNodesInPathV
onnxruntime::AttentionFusionHelper::CheckNodesInPathV
Output edge count not expected for nodes in path v
Failed in match Transpose attribute perm. Expected: 0, 2, 1, 3
Failed in match v_transpose attribute perm. Expected: 0, 2, 1, 3
hidden_size != num_heads * head_size
v_reshape initializer value is not expected
Pass CheckNodesInPathV
reshape initializer value is not expected
Start CheckNodesInPathQ
onnxruntime::AttentionFusionHelper::CheckNodesInPathQ
q_reshape const not matched
qk_div const not matched.
q_transpose perm attribute not matched
Pass CheckNodesInPathQ
Start CheckNodesInPathK
onnxruntime::AttentionFusionHelper::CheckNodesInPathK
k_transpose perm attribute not matched
k_reshape const not matched
Pass CheckNodesInPathK
Mask_Int32
Cast mask from int64 to int32
MaskCast
Start FuseGptAttention
onnxruntime::AttentionFusionHelper::FuseGptAttention
Faild to find path to qkv_matmul
Split
Faild to find path v to Split
CheckNodesInPathV return false
MatchInputMaskSubgraph returns false
MatchUnidirMaskSubgraph returns NULL
Failed to find path for q
q and v are not from same Split node
CheckNodesInPathQ returns false
Failed to find path for k
k and v are not from same Split node
CheckNodesInPathK returns false
MatchPastSubgraph returns false
Fused Attention subgraphs 
Attention
num_heads
unidirectional
Fused an attention node for GPT.
qkv_weights
qkv_bias
Mask shape is unknown or not 2D, or data type unknown
onnxruntime::ConvertMaskToInt32
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\attention_fusion.cc
Mask data type is not int32 or int64 or float32
onnxruntime::AttentionFusion::ApplyImpl
LayerNormalization
shape of layer norm bias tensor not expected
Total fused Attention node count: 
onnxruntime::FuseSubGraphQKImpl
q root should be layer normalization
q_matmul and q_add shape not matched
k root is not layer norm
k_matmul and k_add shape not matched
Failed to load Q, K and V weights, or data type is not float or float16.
Failed to load Q, K and V bias tensors, or data type is not float or float16.
Failed to convert mask to int32
onnxruntime::FuseSubGraphQK
Fused an attention node.
onnxruntime::FuseSubGraphQKDistilBert
Faild to find path v
onnxruntime::AttentionFusion::FuseSubGraph
Output edge count not expected for Add or MatMul in path v
Failed in match v_matmul and v_add input shape
Failed in match input mask subgraph
ai.onnx
onnxruntime::BiasGeluFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\bias_gelu_fusion.cc
FastGelu
BiasGelu
fused Add and Gelu
 and 
 is not in valid range [-
axis 
axis >= -tensor_rank && axis <= tensor_rank - 1
onnxruntime::HandleNegativeAxis
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/common.h
 into softmax(input + bias)
fused 
BiasSoftmax
softmax_axis
broadcast_axis
onnxruntime::BiasSoftmaxFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\bias_softmax_fusion.cc
onnxruntime::CommonSubexpressionElimination::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\common_subexpression_elimination.cc
representative.output_index != kInvalidOutputIndex
] because it's the graph's output.
 of node 
Not eliminating output 
Could not find OrtValue with name '
ConstantFolding
start
DequantizeLinear
onnxruntime::ConstantFolding::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\constant_folding.cc
 node '
can't constant fold 
Could not find a CPU kernel and hence 
fetches.size() == node->OutputDefs().size()
. Can't constant fold 
Unsupported output type of 
Unexpected data type for Clip input of 
onnxruntime::`anonymous-namespace'::GetClipConstantMinMax::<lambda_7016c3d311ac16b560ac6f1760adedd7>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_activation_fusion.cc
onnxruntime::ConvActivationFusion::ApplyImpl
FusedConv
activation
Sigmoid
LeakyRelu
alpha
HardSigmoid
with activation 
fused Conv 
activation_params
data type is not supported
onnxruntime::Initializer::ToProto
conv_W_tensor_proto
onnxruntime::ConvAddFusion::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_add_fusion.cc
add_B_tensor_proto
conv_B_tensor_proto
ConvAddFusion_B_
ConvAddFusion_Add_B_
epsilon
bn_scale_tensor_proto
onnxruntime::ConvBNFusion::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_bn_fusion.cc
bn_B_tensor_proto
bn_mean_tensor_proto
bn_var_tensor_proto
ConvBnFusion_W_
ConvBnFusion_BN_B_
BatchNormalization
onnxruntime::ConvMulFusion::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_mul_fusion.cc
mul_B_tensor_proto
ConvMulFusion_W_
ConvMulFusion_Mul_B_
onnxruntime::DynamicQuantizeMatMulFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\dynamic_quantize_matmul_fusion.cc
MatMulIntegerToFloat
DynamicQuantizeLinear
DynamicQuantizeMatMul
+_Int32
Cast Input from int64 to int32
_Cast
Input shape is unknown or not 2D, or data type unknown
onnxruntime::CheckInput
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\embed_layer_norm_fusion.cc
Input data type is not int32 or int64
Failed to find path 1 of position shape.
onnxruntime::MatchInputToConcatSubgraph
Output edge count not expected for nodes in path 1 of position shape.
Second input of Gather in path 1 of position shape should be a constant with value 0.
Failed to find path 2 of position shape.
Output edge count not expected for nodes in path 2 of position shape.
Gather node in path 2 is not linked to another subgraph.
Second input of Gather in path 2 of position shape should be a constant with value 1.
The parent of two shape nodes are expected to be input_ids.
two paths share the same shape
NonZero
ConstantOfShape
Range
Output edge count not expected for nodes in path1.
onnxruntime::MatchPositionEmbeddingSubgraphsFromGather
The first input of Range should be a constant with value 0.
The third input of Range should be a constant with value 1.
Second input of Gather should be a constant with value 1. 
Failed to match Shape node. 
The parent of shape nodes are expected to be input_ids.
Optional position subgraph nodes number of outputs unexpected.
Optional position subgraph nodes Where node is expected to be the parent of Reshape.
Failed to match position subgraph.
position_embeddings
mask_index
fused EmbedLayerNorm subgraphs 
EmbedLayerNormalization
Word embedding shape not expected.
onnxruntime::FuseSubGraph
Input is expected to have dim value in all dimensions.
Failed to get initializer tensor.
Position embedding shape not matched.
Position embedding data type shall be float or float16.
Failed to match position embedding subgraph.
Failed to get position embedding weights.
Position embedding shape is not expected.
Input id is not valid. 
Segment id is not valid. 
Input_ids and segment id should have the same shape. 
Gamma should be of shape (hidden_size). 
Beta should be of shape (hidden_size). 
onnxruntime::FuseSubGraphDistilBert
onnxruntime::EmbedLayerNormFusion::ApplyImpl
onnxruntime::FastGeluFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\fast_gelu_fusion.cc
fast_gelu_output
fused GPT2Gelu subgraphs 
GPT2Gelu
'7=*BL?
FreeDimensionOverrideTransformer
Invalid free dimension override.
onnxruntime::FreeDimensionOverrideTransformer::FreeDimensionOverrideTransformer
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\free_dim_override_transformer.cc
Conflicting free dimension overrides.
which does not equal the specified override of 
with a fixed dimension size 
The model has input '
onnxruntime::FreeDimensionOverrideTransformer::ApplyImpl
onnxruntime::GeluApproximation::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\gelu_approximation.cc
Gelu approximation
Total Gelu Approximation (FastGelu) node count: 
onnxruntime::GeluFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\gelu_fusion.cc
fused Gelu subgraphs 
Softplus
Softsign
ScaledTanh
ParametricSoftplus
ThresholdedRelu
onnxruntime::GemmActivationFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\gemm_activation_fusion.cc
fused Gemm 
FusedGemm
activation_
transA
transB
Fused Gemm with Transpose
_transformed
onnxruntime::LayerNormFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\layer_norm_fusion.cc
ReduceMean
fused LayerNorm subgraphs 
onnxruntime::SimplifiedLayerNormFusion::ApplyImpl
Cast_Scale
cast scale of layer norm
SimplifiedLayerNormalization
layer_norm_out
cast output of layer norm
onnxruntime::MatMulAddFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_add_fusion.cc
fused Matmul and Add 
onnxruntime::MatMulIntegerToFloatFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_integer_to_float.cc
MatMulInteger
Unsupported data type: 
Constant initializer NodeArg shape should not be null. NodeArg: 
shape
onnxruntime::`anonymous-namespace'::GetScalarConstantInitializer
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_scale_fusion.cc
div_inputs.size() == 2
onnxruntime::`anonymous-namespace'::GetScaleFromNode
mul_inputs.size() == 2
input_node.InputDefs().size() == 2 && scale_and_index->second < 2
onnxruntime::`anonymous-namespace'::GetInputNodeMerges
output_node.OutputDefs().size() == 1
onnxruntime::`anonymous-namespace'::GetOutputNodeMerges
FusedMatMul
Fused MatMul and Scale
_FusedMatMulAndScale
onnxruntime::MatMulScaleFusion::ApplyImpl
onnxruntime::utils::mltype_dispatcher_internal::UnsupportedTypeDefaultPolicy<class onnxruntime::common::Status>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<struct onnxruntime::BFloat16>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<double>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<float>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<struct onnxruntime::MLFloat16>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<__int64>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<int>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<unsigned __int64>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<unsigned int>::operator ()
reorder
ReorderInput
channels_last
strides
dilations
kernel_shape
auto_pad
NOTSET
VALID
group
_nchwc
reshape
spatial
bn_scale
_bn_nchwc
ReorderOutput
channels
nearest
linear
coordinate_transformation_mode
asymmetric
align_corners
half_pixel
nearest_mode
floor
Upsample
scales
MaxPool
AveragePool
Resize
GlobalMaxPool
GlobalAveragePool
onnxruntime::NchwcTransformer::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\nchwc_transformer.cc
deque<T> too long
_nhwc
QLinearConv
NhwcMaxPool
storage_order
nhwc_permutated_pads
QLinearAdd
QLinearMul
QLinearLeakyRelu
QLinearSigmoid
QLinearGlobalAveragePool
QLinearAveragePool
QLinearConcat
onnxruntime::NhwcTransformer::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\nhwc_transformer.cc
is not supported.
data type 
Unexpected data type for Clip 'min' input of 
onnxruntime::FuseReluClip::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\relu_clip_fusion.cc
_min_zero_constant
FuseReluClip_
onnxruntime::ReshapeFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\reshape_fusion.cc
allowzero
Fused reshape node: 
Total fused reshape node count: 
starts
Cannot replace concat node with initializer:
onnxruntime::ReshapeFusion::Fuse_Subgraph
onnxruntime::SkipLayerNormFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\skip_layer_norm_fusion.cc
fused SkipLayerNorm subgraphs 
SkipLayerNormalization
UnsqueezeElimination_
UnsqueezeElimination cannot remove node 
onnxruntime::UnsqueezeElimination::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\unsqueeze_elimination.cc
QuantizeLinear
up_node should have only one Edge that points to down_node and its output is not graph output
optimizer_utils::CheckOutputEdges(graph, up_node, 1)
onnxruntime::SwapAdjacentNodes
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\qdq_propagation.cc
up_node should be parent of down_node and NodeArg slots of the edge between up_node and down_node should be (0, 0).
edge_it->GetDstArgIndex() == 0 && edge_it->GetSrcArgIndex() == 0 && edge_it->GetNode().Index() == down_node.Index()
SwapAdjacentNodes
onnxruntime::QDQPropagationTransformer::ApplyImpl
onnxruntime::QDQS8ToU8Transformer::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\qdq_s8_to_u8.cc
qdq_s8_to_u8_zp_conversion
qdq_s8_to_u8_quant
QDQSelectorActionTransformer
transpose_node.InputDefs().size() == 1
onnxruntime::GetTransposePerms
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_transpose_fusion.cc
!node_consumers.empty()
onnxruntime::UpdateConsumerCount
cast != nullptr
onnxruntime::ReorderCastAndTranspose
Created a new Cast node to interchange Cast and Transpose nodes
Created a new Transpose node to interchange Cast and Transpose nodes
onnxruntime::MatmulTransposeFusion::ApplyImpl
fused MatMul and Transpose 
MatMul_With_Transpose
onnxruntime::BiasDropoutFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\bias_dropout_fusion.cc
BiasDropout
fused Add and Dropout
External data type must not be UNDEFINED or STRING.
onnxruntime::Initializer::ReadExternalRawData
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\initializer.cc
model_path must not be empty. Ensure that a path is provided when the model is created or loaded.
, external_data.length: 
Computed size: 
TensorProto external data size mismatch. 
RandomUniform
RandomNormal
RandomUniformLike
RandomNormalLike
Multinomial
onnxruntime::OptimizerExecutionFrame::Info::{ctor}::<lambda_45c70c0d7c84bb60ff92f35bb1b93d0f>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\optimizer_execution_frame.cc
Failed to get allocator for optimizer
allocator_ptr_
onnxruntime::OptimizerExecutionFrame::Info::Info
Tried to allocate without valid type information, ort_value index=
static_cast<size_t>(index) < nodes_.size() && ((node = nodes_[index]) != nullptr || !required)
onnxruntime::NodesToOptimize::GetNode
D:\a\_work\1\s\onnxruntime\onnxruntime\core/optimizer/selectors_actions/helpers.h
onnxruntime::MergeIntoTarget::Run
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\selectors_actions\actions.cc
onnxruntime::ReplaceWithNew::Run
Multiple entries for operator is not supported. OpType=
inserted
onnxruntime::SelectorActionTransformer::SelectorActionTransformer
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\selectors_actions\selector_action_transformer.cc
Existing registration with name 
selectors_and_actions_map_.find(name) == selectors_and_actions_map_.cend()
onnxruntime::SelectorsAndActions::RegisterSelectorAndAction
Matched 
onnxruntime::SelectorActionTransformer::MatchAndProcess
TODO: Save the selected nodes into the Graph.
onnxruntime::SelectorActionTransformer::ApplyImpl
b33fd0fa-cd7b-4b10-ae5a-df64cabfe1f8
b33f88f7-c464-43e3-8692-97ac832bb14a
generated at runtime
QLinear
A target node must be set.
target_node != nullptr
onnxruntime::NodesToOptimizeBuilder::Build
Index out of range
onnxruntime::`anonymous-namespace'::MoveInputOutputImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\selectors_actions\helpers.cc
onnxruntime::MoveInputOutput
DnnlExecutionProvider
OpenVINOExecutionProvider
NupharExecutionProvider
NnapiExecutionProvider
RknpuExecutionProvider
MIGraphXExecutionProvider
CoreMLExecutionProvider
onnxruntime::RegisterOnnxOperatorKernels
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\cpu_execution_provider.cc
onnxruntime::ml::RegisterOnnxMLOperatorKernels
onnxruntime::RegisterCPUKernels
onnxruntime::CPUExecutionProvider::GetKernelRegistry
center_point_box
NonMaxSuppression
boxes_tensor
onnxruntime::NonMaxSuppressionBase::PrepareCompute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\object_detection\non_max_suppression.cc
scores_tensor
boxes must be a 3D tensor.
scores must be a 3D tensor.
boxes and scores should have same num_batches.
boxes and scores should have same spatial_dimension.
The most inner dimension in boxes must have 4 data.
iou_threshold must be in range [0, 1].
onnxruntime::NonMaxSuppressionBase::GetThresholdsFromInputs
Missing/Invalid 'axis' attribute value
info.GetAttr<int64_t>("axis", &axis_).IsOK()
onnxruntime::GatherBase::GatherBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\gatherbase.h
onnxruntime::Gather::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\gather.cc
Gather Tind type not supported in this build.
 must be within the inclusive range [
indices element out of data bounds, idx=
Missing/Invalid 'axes' attribute value
info.GetAttrs("axes", axes_).IsOK()
onnxruntime::UnsqueezeBase::UnsqueezeBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/unsqueeze.h
X != nullptr
onnxruntime::UnsqueezeBase::PrepareCompute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\unsqueeze.cc
Axes input is null
axes_tensor != nullptr
An axes tensor must be a scalar or a 1-D tensor.
axes_tensor->Shape().NumDimensions() == 0 || axes_tensor->Shape().NumDimensions() == 1
'axes' has an out of range axis
'axes' has a duplicate axis
nullptr != p.output_tensor
onnxruntime::Unsqueeze::Compute
onnxruntime::contrib::RegisterNchwcKernels
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\cpu_contrib_kernels.cc
onnxruntime::contrib::RegisterQuantizationKernels
onnxruntime::contrib::RegisterCpuContribKernels
called_ == 1
onnxruntime::utils::mltype_dispatcher_internal::CallableDispatchableHelper::CheckCalledOnce
min_ <= max_
onnxruntime::clip_internal::Clip_6Base<float>::Clip_6Base
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/math/clip.h
min should be a scalar.
min->Shape().IsScalar()
onnxruntime::Clip::ComputeImpl<unsigned __int64>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\clip.cc
max should be a scalar.
max->Shape().IsScalar()
onnxruntime::Clip::ComputeImpl<__int64>::operator ()
onnxruntime::Clip::ComputeImpl<unsigned char>::operator ()
onnxruntime::Clip::ComputeImpl<signed char>::operator ()
onnxruntime::Clip::ComputeImpl<double>::operator ()
onnxruntime::Clip::ComputeImpl<float>::operator ()
'is defined.
No attribute with name:'
Attribute name and type don't match for '
input_size < std::numeric_limits<std::ptrdiff_t>::max()
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/element_wise_ranged_transform.h
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::LeakyRelu<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::LeakyRelu<float> >::ElementWiseKernel
gamma
5JCy7
~3a*~3a*~3a*~3a*A
5JCy7JCy7JCy7JCy7
Attempting to broadcast an axis by a dimension other than 1. 
axis == 1 || axis == largest
onnxruntime::BroadcastIterator::Init
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/math/element_wise_ops.h
onnxruntime::BroadcastIterator::Append
 is invalid.
Can broadcast 0 by 0 or 1. 
largest <= 1
onnxruntime::Broadcaster::Broadcaster
InputBroadcaster can only start at span boundary!
offset % span_size_ == 0
onnxruntime::InputBroadcaster::AdvanceBy
) for tensor of length:
Invalid start/ending offset [
start_offset >= 0 && real_end >= 0 && start_offset <= real_end && real_end <= len
onnxruntime::OutputBroadcaster::OutputBroadcaster
) are not at boundary of span with size:
Broadcast Output range [
start_offset % span_size == 0 && real_end % span_size == 0
onnxruntime::TensorAllocator::TensorAllocator
Floor
Reciprocal
Greater
LessOrEqual
GreaterOrEqual
BitShift
Unsupported X type: 
Must have 1 or more inputs
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\element_wise_ops.cc
Asinh
Acosh
Atanh
PRelu
ExpandBroadcastLooper should only have a shape for the second input.
!helper.HaveTwoTensorInputs()
onnxruntime::ExpandBroadcastLooper
Tensor with shape information must be 1 dimensional.
shape_data_tensor.Shape().GetDims().size() == 1
onnxruntime::UntypedExpand
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Floor<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Floor<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned __int64> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned __int64> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned int> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned int> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned short> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned short> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned char> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned char> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<__int64> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<__int64> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<int> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<int> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<short> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<short> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<signed char> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<signed char> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<float> >::ElementWiseKernel
direction
Unsupported Y type: 
Invalid usage. Input 1 is a shape with no data.
onnxruntime::Expand_8<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Compute::<lambda_33d11d7f8ca6944b1c0862f78d216382>::operator ()
BroadcastLooper requires two tensors as input.
helper.HaveTwoTensorInputs()
onnxruntime::BroadcastLooper
onnxruntime::Hardmax<float>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\hardmax.cc
Hardmax inputs N, D and N * D must be < 
Hardmax
LogSoftmax
onnxruntime::Softmax<float>::ComputeImplOpset13
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\softmax.cc
onnxruntime::Softmax<double>::ComputeImplOpset13
SAME_UPPER
SAME_LOWER
Unknown AutoPadType String
onnxruntime::StringToAutoPadType
Dilation not supported for AutoPadType::SAME_UPPER or AutoPadType::SAME_LOWER.
ComputePad: pad type not supported.
onnxruntime::ComputePadAndOutputShape
A Conv/ConvTranspose node has both 'auto_pad' and 'pads' attributes
auto_pad == AutoPadType::NOTSET
onnxruntime::ConvAttributes::ConvAttributes
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/nn/conv_attributes.h
 kernel_shape: 
kernel_shape num_dims is not compatible with W num_dims.
kernel_shape is not compatible with W shape.
X num_dims does not match W num_dims.
 group: 
 kernel channels: 
Input channels C is not equal to kernel channels * group.
Output channels M is not divisible by group.
Not enough elements in strides. Expected: 
Not enough elements in kernel shape. Expected: 
Not enough elements in dilations. Expected: 
Not enough elements in pads. Expected: 
onnxruntime::ConvAttributes::InferOutputShape
Invalid input shape: 
onnxruntime::Conv<float>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\nn\conv.cc
ReduceL1
ReduceL2
ReduceLogSum
ReduceLogSumExp
ReduceMax
ReduceMin
ReduceProd
ReduceSum
ReduceSumSquare
ArgMax
ArgMin
last_loop_red_size > 0
onnxruntime::ResultsNoTransposePrepareForReduce::ValidateNotEmpty
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\reduction\reduction_ops.cc
last_loop_size > 0
projected_index.size() > 0
must be overloaded.
onnxruntime::ValidateMustBeOverloaded
Only works on matrices with two dimensions.
fast_shape.size() == 2
onnxruntime::ValidateFastReduceKR
Output size mismatch.
fast_shape[0] == output.Shape().Size()
onnxruntime::ValidateFastReduceRK
fast_shape[1] == output.Shape().Size()
fast_shape.size() == 3
onnxruntime::ValidateFastReduceKRK
fast_shape[0] * fast_shape[2] == output.Shape().Size()
Reduction on all axes, output size should be 1.
count == 1
onnxruntime::ValidateNoTransposeReduce
onnxruntime::ValidateCommonFastReduce
An axes tensor must be a vector tensor.
axes_tensor->Shape().NumDimensions() == 1
Can't reduce on dim with value of 0 if 'keepdims' is false. Invalid output shape would be produced. input_shape:
keepdims
onnxruntime::ValidateKeepDims
info.GetAttr("keepdims", &keepdims).IsOK()
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/reduction/reduction_ops.h
noop_with_empty_axes
select_last_index
onnxruntime::ReduceKernelBase<1>::ReduceKernelBase
forward
reverse
bidirectional
'. Must be one of 'forward', 'reverse', or 'bidirectional'.
Invalid 'direction' argument of '
onnxruntime::rnn::detail::MakeDirection
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/rnn/rnn_helpers.h
info.GetAttr("direction", &direction).IsOK()
onnxruntime::DeepCpuGruOp::DeepCpuGruOp
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/rnn/deep_cpu_gru.h
linear_before_reset
info.GetAttr("linear_before_reset", &int64_value).IsOK()
hidden_size
info.GetAttr("hidden_size", &int64_value).IsOK() && int64_value > 0
activations
activation_alpha
activation_beta
clip_ > 0.f
sigmoid
activation_func_names.size() == static_cast<size_t>(num_directions_) * 2
layout
Batchwise recurrent operations (layout == 1) are not supported. If you need support create a github issue with justification.
layout_ == 0
GRU operator does not support double yet
Invalid data type for GRU operator of 
onnxruntime::DeepCpuGruOp::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\deep_cpu_gru.cc
onnxruntime::DeepCpuGruOp::ComputeImpl
onnxruntime::Tensor::MutableDataAsSpan
lda >= K && ldb >= K && ldc >= N
onnxruntime::rnn::detail::ComputeGemm
A + (M * lda - (lda - K)) <= A_end
B + (N * ldb - (ldb - K)) <= B_end
C + (M * ldc - (ldc - N)) <= C_end
cur + size <= end
onnxruntime::rnn::detail::SafeRawConstPointer
offset + size <= size_t(span.size())
onnxruntime::rnn::detail::SafeRawPointer
onnxruntime::LSTMBase::LSTMBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\lstm_base.h
input_forget
activation_func_names.size() == static_cast<size_t>(num_directions_) * 3
onnxruntime::DeepCpuLstmOp::PrePack
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\deep_cpu_lstm.cc
LSTM operator does not support double yet
Invalid data type for LSTM operator of 
onnxruntime::DeepCpuLstmOp::Compute
invalid stoll argument
stoll argument out of range
invalid stoull argument
stoull argument out of range
invalid stod argument
stod argument out of range
onnxruntime::`anonymous-namespace'::GetIntermediateMLFloat16ToFloatTensor
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\cast_op.cc
Attribute to is not set.
onnxruntime::`anonymous-namespace'::Cast::Cast
snprintf() failed with return value: 
snprintf_result > 0
onnxruntime::`anonymous-namespace'::CastToString
Failed to write value with snprintf().
snprintf_result > 0 && gsl::narrow_cast<size_t>(snprintf_result) == buffer_span.size() - 1
CMust have valid 'axis' attribute
onnxruntime::ConcatBase::ConcatBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\concatbase.h
new_axis
onnxruntime::ConcatBase::PrepareForCompute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\concat.cc
input count mismatch
input != nullptr
Cannot concatenate scalars
 got: 
Ranks of input data are different, cannot concatenate them. expected rank: 
input_rank == reference_rank
 has mismatched dimensions of 
Non concat axis dimensions must match: Axis 
Data type mismatch
onnxruntime::ConcatBase::ComputeImpl
src and dst types must match
dst.DataType() == src.DataType()
onnxruntime::DispatchStridedCopy
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/copy.h
Unsupported input data type of 
last >= first
onnxruntime::StridedCopy::<lambda_7cf9f7011f71cbc7a7f9f1e7bd9d9e44>::operator ()
counter.current_offset == last
onnxruntime::StridedCopy::<lambda_432c0fbab4ccd64eefecf0c6cfc89332>::operator ()
src and dst must have same shape and not be rank 0.
dst_strides.size() == src_strides.size() && src_strides.size() == copy_shape.size() && !copy_shape.empty()
onnxruntime::StridedCopy
onnxruntime::StridedCopy::<lambda_e5db1942e7340c738b6ebdc5da682efe>::operator ()
onnxruntime::StridedCopy::<lambda_ddd8493ebb39a49cc2643ed4269af499>::operator ()
onnxruntime::StridedCopy::<lambda_4ce86fe204f71dba32306ac9854bc206>::operator ()
onnxruntime::StridedCopy::<lambda_c60aa8fc78ffaf341f1d54c884d3f799>::operator ()
onnxruntime::StridedCopy::<lambda_02871f30a7ce451399da82fe783f932a>::operator ()
onnxruntime::StridedCopy::<lambda_f16edf5cdd807d431b24c8b686f2ae9b>::operator ()
onnxruntime::StridedCopy::<lambda_f66e8601ea32ff7b33b7feafbaeaff41>::operator ()
onnxruntime::StridedCopy::<lambda_5a5fc68c4068eb1de24eefff3968df88>::operator ()
onnxruntime::IdentityOp<0>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/identity_op.h
Unable to get an allocator
onnxruntime::IdentityOp<1>::Compute
A dimension cannot be less than -1, got 
requested_shape[i] >= -1
onnxruntime::ReshapeHelper::ReshapeHelper
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\reshape_helper.h
, requested shape:
The input tensor cannot be reshaped to the requested shape. Input shape:
!allow_zero
At most one dimension can be -1.
unknown_dim == -1
The dimension with value zero exceeds the dimension size of the input tensor.
i < input_shape.NumDimensions()
size != 0 && (input_shape.Size() % size) == 0
gsl::narrow_cast<int64_t>(input_shape.Size()) == size
A shape tensor must be a vector tensor.
shapeTensor->Shape().NumDimensions() == 1
onnxruntime::Reshape::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/reshape.h
Missing or invalid starts and ends attribute
has_starts && has_ends && attr_starts_.size() == attr_ends_.size()
onnxruntime::SliceBase::SliceBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/slice.h
Invalid axes attribute, axes attribute (if present) should have the same size as starts/ends attributes
!has_axes || attr_axes_.size() == attr_starts_.size()
'axes' has an axis outside of the tensor dimension count
'axes' has duplicates
'step' value cannot be 0
dims.size() == extents.size() && dims.size() >= steps.size()
onnxruntime::SliceSkips::SliceSkips
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/utils.h
dims.size() == starts.size() && dims.size() == extents_.size() && dims.size() >= steps.size()
onnxruntime::SliceIteratorBase::Init
Unexpected element size of 
onnxruntime::SliceIteratorBase::CopyInnermostAxisNonSolitaryInnerStep
onnxruntime::SliceBase::PrepareForCompute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\slice.cc
Starts must be a 1-D array
onnxruntime::SliceBase::FillVectorsFromInput
Ends must be a 1-D array
Starts and ends shape mismatch
Starts and axes shape mismatch
Starts and steps shape mismatch
Data type for starts and ends inputs' is not supported in this build. Got 
Cannot slice scalars
onnxruntime::SliceBase::Compute
output == output_end
onnxruntime::SliceImpl::<lambda_dcc61af08304d97c0692cb03374079ac>::operator ()
onnxruntime::SliceImpl::<lambda_5b2e4509ab27aba0d100f6e12dff1cde>::operator ()
onnxruntime::SliceImpl::<lambda_64ea152fa15c037e8707a9d30091f106>::operator ()
onnxruntime::SliceImpl::<lambda_790b5ec1a3c149bb3df697a2930cce40>::operator ()
onnxruntime::SliceImpl::<lambda_04baced002afea44beba91f98ea8b007>::operator ()
split
Invalid value in 'split' attribute. All values must be > 0
std::all_of(split_sizes_.cbegin(), split_sizes_.cend(), [](int64_t value) { return value >= 0; })
onnxruntime::SplitBase::SplitBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/split.h
 NumOutputs=
 Axis=
Input cannot be split evenly on selected axis. Input shape=
 Sum of sizes in 'split' (must equal size of selected axis) was 
 Num entries in 'split' (must equal number of outputs) was 
 Input shape=
Cannot split using values in 'split' attribute. Axis=
Split operator does not support 
onnxruntime::Split::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\split.cc
An split tensor must be a vector tensor.
split_tensor->Shape().NumDimensions() == 1
onnxruntime::Split::ComputeImpl
. shape=
 must be 1 instead of 
Dimension of input 
input_shape[i] == 1
onnxruntime::SqueezeBase::ComputeOutputShape
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/squeeze.h
onnxruntime::Squeeze::Compute
Input count of Tile OP mismatch, the first one is empty
Input count of Tile OP mismatch, the second one is empty
the tensor to be tiled using Tile OP must be atleast 1 dimensional
'repeat' input tensor must be 1 dimensional
'repeat' input tensor must have the same length as the 'input' tensor
Tile doesn't support string type yet
!input_tensor.IsDataType<std::string>()
onnxruntime::Tile::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\tile.cc
Tile doesn't have an implementation yet for the type: 
v >= 0 && static_cast<uint64_t>(v) <= std::numeric_limits<size_t>::max()
onnxruntime::TransposeBase::TransposeBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/transpose.h
 is outside range.
Attribute perm of Transpose has an invalid value. Value 
 is repeated.
 does not align with rank of input data: 
perm: 
Method IncrementIndexAndComputeOffset assumes this value is strictly positive.
naxes > 0
onnxruntime::IncrementIndexAndComputeOffsetSetup
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\transpose.cc
(local_source >= source) && (local_source < source + num_blocks * blocksize)
onnxruntime::DoTransposeImpl
Transpose not implemented for empty tensors.
num_axes > 0
(local_source >= source) && (local_source < source + num_blocks * num_elts_in_block)
Transpose of element size not supported in this build. Size=
onnxruntime::DoTransposeEltWise
(local_source >= source) && (local_source < source + num_blocks)
Mismatched data types between input and output Tensors. 
input_tensor_ptr != nullptr
onnxruntime::Transpose::Compute
(local_source >= source) && (local_source < source + sizeof(T) * num_blocks)
onnxruntime::TypedDoTransposeEltWise
invalid expand shape
onnxruntime::`anonymous-namespace'::ConstantOfShape::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\generator\constant_of_shape.cc
Unsupported output datatype with size: 
Must have a valid input shape.
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::PrepareCompute
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/generator/constant_of_shape_base.h
Must have a single dimension
t_proto_p->dims_size() == 1
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::ConstantOfShapeBase
Must have a single dimension of 1
t_proto_p->dims()[0] == 1
Unsupported value attribute datatype with size: 
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::SetValue
utils::HasDataType(t_proto)
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::SetValueFromTensorProto
ONNX_NAMESPACE::TensorProto::DataType_IsValid(t_proto.data_type())
Tensor proto with external data for value attribute is not supported.
!utils::HasExternalData(t_proto)
Unsupported value attribute datatype: 
Attempt to retrieve final output before it was set.
final_output_mlvalue_
onnxruntime::scan::detail::OutputIterator::GetOutput
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/controlflow/scan_utils.h
info.GetAttr<ONNX_NAMESPACE::GraphProto>("body", &proto).IsOK()
onnxruntime::Scan<9>::Init
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\controlflow\scan_9.cc
num_scan_inputs
info.GetAttr<int64_t>("num_scan_inputs", &num_scan_inputs_).IsOK()
scan_input_directions
scan_output_directions
scan_input_axes
 but expected 
Number of entries in 'scan_input_axes' was 
gsl::narrow_cast<int64_t>(input_axes_.size()) == num_scan_inputs_
scan_output_axes
Number of entries in 'scan_output_axes' was 
gsl::narrow_cast<int64_t>(output_axes_.size()) == num_scan_outputs
SetupSubgraphExecutionInfo should only be called once for each subgraph.
info_ == nullptr
onnxruntime::Scan<9>::SetupSubgraphExecutionInfo
CreateFeedsFetchesManager must be called prior to execution of graph.
feeds_fetches_manager_ && info_
onnxruntime::Scan<9>::Compute
Subgraph SessionState was not found for 'body' attribute.
session_state
onnxruntime::ScanImpl::Initialize
 dimensions or more but input had shape of 
 Expected 
Invalid scan input:
 has length of 
' dimension 
 but input '
Scan inputs have inconsistent sequence lengths. Previous value was 
. Input tensor rank was 
Invalid value in scan_input_axes for input 
onnxruntime::ScanImpl::ValidateInput
onnxruntime::ScanImpl::SetupInputs
 outputs but Scan expects 
Subgraph in 'body' produces 
onnxruntime::ScanImpl::AllocateOutputTensors
onnxruntime::ScanImpl::CreateLoopStateVariables
Output OrtValue has not been created for loop state variable output 
output_mlvalue
onnxruntime::ScanImpl::Execute
. Output tensor rank was 
Invalid value in scan_output_axes for output 
Outputs from Scan are not optional and should never be null.
onnxruntime::ScanImpl::TransposeOutput
info.GetAttr<int64_t>("transA", &temp).IsOK()
onnxruntime::GemmBase::GemmBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\gemm_base.h
info.GetAttr<int64_t>("transB", &temp).IsOK()
info.GetAttr<float>("alpha", &alpha_).IsOK()
left.NumDimensions() == 2 || left.NumDimensions() == 1
onnxruntime::GemmHelper::GemmHelper
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\gemm_helper.h
right.NumDimensions() == 2
GEMM: Dimension mismatch, W: 
Gemm: Invalid bias shape for broadcast
M_ >= 0 && K_ > 0 && N_ >= 0
c_shape is required if c_data is provided
c_shape != nullptr
onnxruntime::GemmBroadcastBias
left_num_dims and right_num_dims must be >= 1
onnxruntime::MatMulComputeHelper::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/math/matmul_helper.h
MatMul dimension mismatch
left operand cannot broadcast on dim 
right operand cannot broadcast on dim 
num_dims_with_pad != num_output_dims
M_ == 1 && N_ == 1 was false
num_dims_with_pad - 1 != num_output_dims
num_dims_with_pad - 2 != num_output_dims
onnxruntime::MatMul<float>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\matmul.cc
onnxruntime::MatMul<double>::Compute
onnxruntime::MatMul<int>::Compute
onnxruntime::MatMul<__int64>::Compute
x_zero_point must be null or a scalar or 1D tensor or size 1.
zero_point_ptr == nullptr || IsScalarOr1ElementVector(zero_point_ptr)
onnxruntime::PrepareForQDQ
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\quantize_linear.cc
scale must be 1D tensor with size 
scale.Shape().NumDimensions() == 1 && scale.Shape()[0] == broadcast_dim
x_zero_point must be null or 1D tensor with size 
zero_point_ptr == nullptr || (zero_point_ptr->Shape().NumDimensions() == 1 && zero_point_ptr->Shape()[0] == broadcast_dim)
DequantizeLinear with type int32 should have no zero point or all zero points should be 0
zero_point == nullptr || std::all_of(zero_point, zero_point + x_zero_point->Shape().Size(), [](int32_t zp) { return zp == 0; })
onnxruntime::DequantizeLinear<int>::Compute
`@Per-column quantization parameter of batched matrix should have same dimension as the matrix,and its size by K should be equal to the matrix's size.
onnxruntime::MatMulComputeHelper::Compute::<lambda_4f90b78f762d39bdc6a7a51bc529ba99>::operator ()
MatmulInteger : input1 zero point must be a scalar or 1D tensor of size 1
IsScalarOr1ElementVector(a_zero_point)
onnxruntime::MatMulInteger::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\matmul_integer.cc
MatmulInteger : B zero point is not valid
IsBQuantParamSupported(b_zero_point->Shape(), b ? b->Shape() : b_shape_)
ConvInteger
Must be a scalar or 1D tensor or size 1.
IsScalarOr1ElementVector(X_Zero_Point)
onnxruntime::ConvInteger::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\nn\conv_integer.cc
Non per-tensor quantization is not supported now.
IsScalarOr1ElementVector(W_Zero_Point)
Axis tensor must be provided to the CumSum op
Axis tensor should be 0D or 1D
Axis tensor should be of type `int32_t` or `int64_t`
CumSum
exclusive
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\cumsum.cc
Cannot apply CumSum operator on a scalar
onnxruntime::CumSum<float>::Compute
onnxruntime::CumSum<double>::Compute
onnxruntime::CumSum<int>::Compute
onnxruntime::CumSum<__int64>::Compute
starts.size()=
dims.size()=
dims.size() == starts.size()
onnxruntime::WritableSliceIterator<__int64>::Init
extents.size()=
dims.size() == extents_.size()
steps.size()=
dims.size() == steps.size()
onnxruntime::WritableSliceIterator<int>::Init
onnxruntime::WritableSliceIterator<double>::Init
onnxruntime::WritableSliceIterator<float>::Init
Round
x_ptr != nullptr
onnxruntime::DynamicQuantizeLinear<unsigned char>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\dynamicquantizelinear.cc
start in Range operator should be scalar like tensor, yet got shape:
limit in Range operator should be scalar like tensor, yet got shape:
delta in Range operator should be scalar like tensor, yet got shape:
delta in Range operator can not be zero!
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\top_k.cc
op_kernel_info.GetAttr<int64_t>("axis", &axis_temp).IsOK()
onnxruntime::TopkOpset11ConstructorCommon
largest
op_kernel_info.GetAttr<int64_t>("largest", &largest_temp).IsOK()
sorted
op_kernel_info.GetAttr<int64_t>("sorted", &sorted_temp).IsOK()
input count mismatch, expected 2 inputs - the tensor to be processed and a tensor containing k value
k tensor should be a 1D tensor of size 1
value of k must not be negative
] should not be greater than specified axis dim value [
k argument [
output count mismatch, expected 2 outputs to be present for TopK operator
333333
?GlobalLpPool
ceil_mode
count_include_pad
info.GetAttr<int64_t>("channels_last", &channels_last_).IsOK()
onnxruntime::contrib::ReorderInput::ReorderInput
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\nchwc_ops.h
info.GetAttr<int64_t>("channels", &channels_).IsOK()
onnxruntime::contrib::ReorderOutput::ReorderOutput
invalid channel count
channels_ > 0
GetFusedActivationAttr(info, activation_).IsOK()
onnxruntime::contrib::NchwcConv::NchwcConv
X_rank == 4
onnxruntime::contrib::ReorderInput::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\nchwc_ops.cc
(channels % 4) == 0
onnxruntime::contrib::ReorderOutput::Compute
channels_ <= X_shape[1]
onnxruntime::contrib::NchwcConv::Compute
X_shape.NumDimensions() == 4
(static_cast<size_t>(X_shape[1]) < nchwc_block_size) || ((X_shape[1] % nchwc_block_size) == 0)
Unsupported convolution size.
output and sum shape must match
onnxruntime::contrib::MatMulIntegerToFloatBase::ComputeCommon
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\quantization\dynamic_quantize_matmul.cc
MatmulInteger : b zero point is not valid
IsBQuantParamSupported(b_zp_tensor->Shape(), b_tensor ? b_tensor->Shape() : b_shape_)
onnxruntime::contrib::DynamicQuantizeMatMul::Compute
MatMulIntegerToFloat : input a zero point must be a scalar or 1D tensor of size 1. Per-Channel is not supported yet.
IsScalarOr1ElementVector(a_zero_point_tensor)
onnxruntime::contrib::MatMulIntegerToFloat::Compute
onnxruntime::contrib::DynamicQuantizeLSTM::PrePack
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\quantization\dynamic_quantize_lstm.cc
} for per-channel quantization. Actual:
} for per-tensor/layer quantization or shape {
 must have shape {
W_zero_point
R_zero_point
W_scale
R_scale
Weight zero point must be zero
DynamicQuantizeLSTM : 
Weight point must be constant
Recurrent
DynamicQuantizeLSTM
onnxruntime::contrib::FusedConvFloat::FusedConvFloat
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\fused_conv.cc
TransposeMatMul
op_kernel_info.GetAttr("axis", &axis_).IsOK()
onnxruntime::contrib::LayerNorm<float,0>::LayerNorm
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\layer_norm.cc
op_kernel_info.GetAttr<float>("epsilon", &epsilon_).IsOK()
onnxruntime::contrib::LayerNorm<float,0>::Compute
onnxruntime::contrib::LayerNorm<float,1>::LayerNorm
onnxruntime::contrib::LayerNorm<float,1>::Compute
onnxruntime::contrib::LayerNorm<double,0>::LayerNorm
onnxruntime::contrib::LayerNorm<double,0>::Compute
onnxruntime::contrib::LayerNorm<double,1>::LayerNorm
onnxruntime::contrib::LayerNorm<double,1>::Compute
SoftmaxCPU inputs N, D and N * D must be < 
affine
leakyrelu
thresholdedrelu
scaledtanh
hardsigmoid
softsign
softplus
Input X must have 3 dimensions only. Actual:
}. Actual:
Input W must have shape {
Input R must have shape {
Input B must have shape {
Input sequence_lens must have shape {
Invalid value/s in sequence_lens. All values must be > 0 and < seq_length. seq_length=
Input initial_h must have shape {
Expecting activation to be one of Affine, Relu, LeakyRelu, ThresholdedRelu, Tanh, ScaledTanh, Sigmoid, HardSigmoid, Elu, Softsign, Softplus. Got 
onnxruntime::rnn::detail::NormalizeActivationArgumentAndGetAlphaBetaCount
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\rnn_helpers.cc
A + (M * K) <= A_end
weights.quant_para_
Quantized GEMM only support alpha equal to 1.0f and beta equal to 0.0f or 1.0f
alpha == 1.0f && (beta == 0.0f || beta == 1.0f)
Invalid activation function of 
onnxruntime::rnn::detail::deepcpu::ActivationFuncByName
Invalid LSTM merge activation function of 
onnxruntime::rnn::detail::deepcpu::LstmMergeGatesFuncByName
Invalid GRU reset gate activation function: 
onnxruntime::rnn::detail::deepcpu::GruResetGateFuncByName
Invalid GRU hidden gate activation function: 
onnxruntime::rnn::detail::deepcpu::GruOutputGateFuncByName
.Input initial_c must have shape {
Input P must have shape {
onnxruntime::LSTMBase::ComputeImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\lstm_base.cc
 inputs but Scan was only given 
The subgraph in 'body' requires 
num_variadic_inputs == num_subgraph_inputs
onnxruntime::scan::detail::Info::Info
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\controlflow\scan_utils.cc
' was 
Number of entries in '
directions.size() == num_entries
onnxruntime::scan::detail::ReadDirections
'. 0 == forward. 1 == reverse.
Invalid values in '
valid
 did not.
Subgraph must have the shape set for all outputs but 
onnxruntime::scan::detail::CreateFeedsFetchesManager
onnxruntime::scan::detail::IterateSequence::<lambda_7d40fd05acaf32e2efee452cda59a5a2>::operator ()
onnxruntime::scan::detail::IterateSequence
Misuse of LoopStateVariable. Attempt to move beyond end of sequence
iteration_num_ < sequence_len_
onnxruntime::scan::detail::LoopStateVariable::Next
 is not compatible with 
Mismatch between expected shape and shape from first output
onnxruntime::scan::detail::OutputIterator::Initialize
Failed to create output tensor for output #
onnxruntime::scan::detail::OutputIterator::AllocateFinalBuffer
If shape was concrete we shouldn't be using a custom allocator
!is_concrete_shape_
onnxruntime::scan::detail::OutputIterator::AllocateFinalOutput
cur_iteration_ < num_iterations_
onnxruntime::scan::detail::OutputIterator::operator *
Expected AllocateFinalOutput to have been called to before we read the OrtValue from the iterator.
is_concrete_shape_
Expected AllocateFinalOutput to have been called to before we increment the iterator
onnxruntime::scan::detail::OutputIterator::operator ++
position_ >= 0 && position_ < sequence_length_
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Iterator::operator *
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/ort_value_tensor_slicer.h
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Iterator::operator *
unimplemented activation: 
activation_params count mismatch
Received null OrtThreadingOptions
Received invalid value for allow_spinning. Valid values are 0 or 1
dims[d_i] < d_max
onnxruntime::math::NextPosition
D:\a\_work\1\s\onnxruntime\onnxruntime\core\util\math_cpu.cc
Gemv found an unexpected CBLAS_TRANSPOSE input of
onnxruntime::math::Gemv
CudaPinned
onnxruntime::IAllocator::CalcMemSizeForArrayWithAlignment::<lambda_200b8346f1e5a884ccf74761b31486f4>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\allocator.cc
Specified device is not supported.
OrtValue is TensorSequence type but has no element Tensor DataType.
Tensor types should have been handled already
 is not supported
Not implemented
the ort_value must contain a constructed tensor or sparse tensor
Argument is not a tensor
OrtApis::GetTensorTypeAndShape
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor_type_and_shape.cc
Unsupported indices_format passed
`anonymous-namespace'::GetIndicesTensor
type_proto is not of type map!
type_proto is not of type sequence!
 dimensions.
 for SizeFromDimension. Tensor has 
Invalid dimension of 
dimension <= num_dims
onnxruntime::TensorShape::SizeToDimension
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor_shape.cc
onnxruntime::TensorShape::SizeFromDimension
Invalid tensor shape slice argument.
dimstart <= dimend && dimend <= size()
onnxruntime::TensorShape::Slice
onnxruntime::TensorTypeBase::GetElementType
onnxruntime::SparseTensorTypeBase::GetElementType
onnxruntime::SequenceTensorTypeBase::GetElementType
onnxruntime::data_types_internal::IsCompatible
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\data_types.cc
Only ONNX MLDataType can be registered
proto != nullptr
onnxruntime::data_types_internal::DataTypeRegistry::RegisterDataType
We do not expect duplicate registration of types for: 
p.second
thisProto->value_case() == TypeProto::ValueCase::kTensorType
onnxruntime::TensorTypeBase::IsCompatible
utils::HasElemType(thisProto->tensor_type())
thisProto->value_case() == TypeProto::ValueCase::kSparseTensorType
onnxruntime::SparseTensorTypeBase::IsCompatible
utils::HasElemType(thisProto->sparse_tensor_type())
thisProto->value_case() == TypeProto::ValueCase::kSequenceType
onnxruntime::SequenceTensorTypeBase::IsCompatible
utils::HasElemType(thisProto->sequence_type())
thisProto->value_case() == TypeProto::ValueCase::kMapType
onnxruntime::NonTensorTypeBase::IsMapCompatible
utils::HasKeyType(thisProto->map_type())
onnxruntime::NonTensorTypeBase::IsSequenceCompatible
onnxruntime::NonTensorTypeBase::FromDataContainer
onnxruntime::NonTensorTypeBase::ToDataContainer
(null)
float
double
uint8
int16
uint16
int32
uint32
int64
uint64
float16
bfloat16
tensor type 
sparse tensor type 
 is not currently registered or supported
MLDataType for: 
Invalid DataTypeImpl TypeProto definition
onnxruntime::utils::ContainerChecker::ContainerChecker
 expected to be a registered ONNX type
value_proto != nullptr
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Set
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/data_types.h
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64>::Set
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float>::Set
onnxruntime::data_types_internal::SetMapTypes<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,double>::Set
onnxruntime::data_types_internal::SetMapTypes<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Set
onnxruntime::data_types_internal::SetMapTypes<__int64,__int64>::Set
onnxruntime::data_types_internal::SetMapTypes<__int64,float>::Set
onnxruntime::data_types_internal::SetMapTypes<__int64,double>::Set
elem_proto != nullptr
onnxruntime::data_types_internal::SetSequenceType<float>::Set
onnxruntime::data_types_internal::SetSequenceType<double>::Set
onnxruntime::data_types_internal::SetSequenceType<signed char>::Set
onnxruntime::data_types_internal::SetSequenceType<unsigned char>::Set
onnxruntime::data_types_internal::SetSequenceType<short>::Set
onnxruntime::data_types_internal::SetSequenceType<unsigned short>::Set
onnxruntime::data_types_internal::SetSequenceType<int>::Set
onnxruntime::data_types_internal::SetSequenceType<unsigned int>::Set
onnxruntime::data_types_internal::SetSequenceType<__int64>::Set
onnxruntime::data_types_internal::SetSequenceType<unsigned __int64>::Set
onnxruntime::data_types_internal::SetSequenceType<bool>::Set
onnxruntime::data_types_internal::SetSequenceType<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Set
onnxruntime::data_types_internal::SetSequenceType<struct onnxruntime::MLFloat16>::Set
onnxruntime::data_types_internal::SetSequenceType<struct onnxruntime::BFloat16>::Set
onnxruntime::data_types_internal::SetSequenceType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > > >::Set
onnxruntime::data_types_internal::SetSequenceType<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > > >::Set
p_type != nullptr
onnxruntime::Tensor::Tensor
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor.cc
shape.Size() must >=0
tensor failed memory size calculation
tensor size overflow
onnxruntime::Tensor::SizeInBytes
onnxruntime::Tensor::Init
Tensor is expected to contain one of the primitive data types. Got: 
dtype_ != nullptr
onnxruntime::IDataTransfer::CopyTensors
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\data_transfer.cc
onnxruntime::IDataTransfer::CopySparseTensors
src.SizeInBytes() == dst.SizeInBytes()
onnxruntime::CPUDataTransfer::CopyTensor
Divide by zero
SafeIntExceptionHandler<class onnxruntime::OnnxRuntimeException>::SafeIntOnDivZero
 dst_size: 
Must have the same size. Got src_size: 
onnxruntime::`anonymous-namespace'::CopyData
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\sparse_tensor.cc
the ort_value must contain a constructed sparse tensor
onnxruntime::SparseTensor::GetSparseTensorFromOrtValue
this tensor already has populated sparse_indices
 must be less than total buffer size: 
Values size 
onnxruntime::SparseTensor::AllocateBuffer
SparseTensor Allocation failed for size: 
Must contain Coo format. Got: 
Format() == SparseFormat::kCoo
onnxruntime::SparseTensor::AsCoo
Expecting to contain one index, got: 
format_data_.size() == 1U
 must be equal to or twice the values size: 
Index size: 
values_count == index_size
onnxruntime::SparseTensor::GetCooIndexDims
Sparse format must not be set. Already contains format: 
onnxruntime::SparseTensor::UseCooIndices
Not expecting an allocator set
Use MakeCooStrings
onnxruntime::SparseTensor::MakeCooData
Expecting data type to be set as string
onnxruntime::SparseTensor::MakeCooStrings
Format() == SparseFormat::kUndefined
This method should follow a call to constructor that supplies the allocator
allocator_ != nullptr
Must contain Csr format. Contains: 
Format() == SparseFormat::kCsrc
onnxruntime::SparseTensor::AsCsr
Expecting two indices. Got: 
format_data_.size() == 2U
dense shape must 2-D. Got: 
onnxruntime::SparseTensor::ValidateCsrIndices
Inner and Outer indices must either be both zero or non-zero
 the same as values size: 
Expecting inner index size: 
 rows: 
Outer index count must be rows + 1 or zero. Got: 
This method does not expect allocator to be set
onnxruntime::SparseTensor::UseCsrIndices
Use MakeCsrStrings
onnxruntime::SparseTensor::MakeCsrData
onnxruntime::SparseTensor::MakeCsrStrings
Must contain BlockSparse format. Got: 
Format() == SparseFormat::kBlockSparse
onnxruntime::SparseTensor::AsBlockSparse
Expecting one index. Got: 
Expecting to have at lest 3-D shape. Got:
onnxruntime::SparseTensor::ValidateBlockSparseShapes
Expecting indices to have 2-D shape . Got: 
Indices shape must have dim[0] == 2
 to be equal to values blocks: 
Expecting index blocks: 
Expecting fully sparse tensors to have value shape {0}
Expecting fully sparse tensors to have indices shape {0}
onnxruntime::SparseTensor::UseBlockSparseIndices
Use MakeBlockSparseStrings
onnxruntime::SparseTensor::MakeBlockSparseData
onnxruntime::SparseTensor::MakeBlockSparseStrings
 to device type: 
Unable to find a data transfer for copying from device type: 
onnxruntime::SparseTensor::Copy
This instance should not be empty
Destination should be empty
Destination must have a CPU allocator set
X-device copy of strings not supported
Src and Dst must be of the same type
Must have the same shape
Config key is empty or longer than maximum length 128
Config value is longer than maximum length 1024
]. It will be overwritten
] already exists with value [
Config with key [
onnxruntime::ConfigOptions::AddConfigEntry
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\config_options.cc
Received nullptr for name.
Received nullptr for OrtValue.
Received OrtValue is not a tensor. Only tensors are supported.
Buffer containing the initializer must be owned by the user.
An OrtValue for this name has already been added.
InternalTestingExecutionProvider
invalid allocator.
Unsupported OrtValue type.
Failed to find allocator for device 
allocator != nullptr
onnxruntime::utils::BatchOrCopyMLValue
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\utils.cc
Unsupported OrtValue type to copy between device.
onnxruntime::utils::FindMemoryInfoForValue
exec_plan_ptr
onnxruntime::utils::CalculateStaticCopyInfoForFeed
onnxruntime::utils::CalculateStaticCopyInfoForFeeds
onnxruntime::utils::InitializeFeedFetchCopyInfo
feed_locations.size() == copy_info.size()
onnxruntime::utils::FinalizeCopyInfoForFeeds
fetch_alloc_info.size() == copy_info.size()
onnxruntime::utils::FinalizeCopyInfoForFetches
copy_info.size() == num_feeds
onnxruntime::utils::CopyInputsAcrossDevices
onnxruntime::utils::CopyOneInputAcrossDevices
onnxruntime::utils::CopyOutputsAcrossDevices
Only one thread was configured for parallel execution. Hence will use sequential execution.
onnxruntime::utils::ExecuteGraphImpl
onnxruntime::utils::ExecuteGraph
input_offset >= 0 && output_offset >= 0
onnxruntime::KernelDefBuilder::VariadicAlias
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\kernel_def_builder.cc
node_offsets_index < node_offsets_size_
onnxruntime::NodeIndexInfo::GetNodeOffset
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/node_index_info.h
Execution frame was null
frame != nullptr
onnxruntime::OpKernelContext::OpKernelContext
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\op_kernel.cc
OpKernel was null
kernel != nullptr
onnxruntime::OpKernelContext::OutputMLValue
TempSpace allocator not found
onnxruntime::OpKernelContext::GetOrCreateOutputMLValue
Attibute name and type don't match
No attribute with this name is defined.
Received invalid value of arena_extend_strategy 
onnxruntime::CreateAllocator
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\allocatormgr.cc
duplicated allocator
onnxruntime::AllocatorManager::InsertAllocator
data_transfer registered is nullptr.
Tensor size mismatch
There's no data transfer registered for copying tensors from 
onnxruntime::DataTransferManager::CopyTensors
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\data_transfer_manager.cc
onnxruntime::DataTransferManager::CopySparseTensors
onnxruntime::IExecutionProvider::InsertAllocator
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\execution_provider.cc
duplicated allocator: 
onnxruntime::IExecutionProvider::TryInsertAllocator
IExecutionProvider::Compile with fused Node is not implemented by 
IExecutionProvider::Compile with fused Node and dll path is not implemented by 
IExecutionProvider::Compile with FusedNodeAndGraph is not implemented by 
IExecutionProvider constructor must be called with true for use_metadef_id_creator
metadef_id_generator_
onnxruntime::IExecutionProvider::GenerateMetaDefId
cannot find allocator
onnxruntime::OpKernelInfo::GetMemoryInfo
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\op_kernel_info.cc
 kernel_end_version: 
 kernel start version: 
 node_version: 
 Version mismatch.
 and type (
Op with name (
 This op has been implemented only for the following types (
 However the types are incompatible.
 (node_version: 
 in the supported version range
Found kernel for Op with name (
 but the node in the model has the following type (
onnxruntime::KernelRegistry::TryCreateKernel
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\kernel_registry.cc
 Encountered following errors: (
 kernel is not supported in 
Kernel not found
kernel def can't be NULL
: Conflicting with a registered kernel with op versions.
Failed to add kernel for 
: Conflict with existing kernel def hash.
onnxruntime::KernelRegistry::Register
len <= op_schema.inputs().size()
onnxruntime::`anonymous-namespace'::TraverseFormalParametersWithTypeProto
Candidate for fallback CPU execution: 
onnxruntime::GetCpuPreferredNodes::<lambda_c9c94e4a7d5ae844e1f9d0f784dced0b>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\fallback_cpu_capability.cc
kernel_info != nullptr
onnxruntime::GetCpuPreferredNodes
 capable of executing this node
 because the CPU execution path is deemed faster than overhead involved with execution on other EPs 
ORT optimization- Force fallback to CPU execution for node: 
Currently do not support dims higher than 2 dimensions: 
Unable to convert strings tensor to a sparse tensor that not on CPU
onnxruntime::sparse_utils::DenseTensorToSparseCsr
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\sparse_utils.cc
Unsupported element size: 
Support 2-D matrices only
Input must be of CSR format
Unable to convert strings tensor to a sparse tensor that is not on CPU
Expecting inner indices to be same as nnz. Got: 
inner_num == src.Values().Shape().Size()
onnxruntime::sparse_utils::SparseCsrToDenseTensor
Outer indices must be M + 1. Got: 
outer_num == (rows + 1)
Input must be of COO format
Expecting indices to be equal the number of values or be twice as many
onnxruntime::sparse_utils::SparseCooToDenseTensor
 > dense_size: 
Invalid index: 
onnxruntime::sparse_utils::DenseTensorToSparseCoo
 type: 
UnpackTensor: the pre-allocated size does not match the raw data size, expected 
Tensor does not have external data to read from.
`anonymous-namespace'::GetExternalDataInfo
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensorprotoutils.cc
External data type cannot be UNDEFINED or STRING.
TensorProto external data size mismatch. Computed size: 
`anonymous-namespace'::ReadExternalDataForTensor
nullptr == p_data
onnxruntime::utils::UnpackTensorWithExternalDataImpl
) in proto
) does not match the data size(
corrupted protobuf data: tensor shape size(
UnpackTensor: the pre-allocate size does not match the size in proto
data overflow
onnxruntime::utils::GetFileContent
TensorProtoToTensor() tensor shape mismatch!
 can not be writen into Tensor type 
TensorProto type 
onnxruntime::utils::TensorProtoToTensor
string tensor can not have raw data
tensor can't contain negative dims
Initialized tensor with unexpected type: 
TensorProtoToMLValue() must take a pre-allocated MemBuffer!
string tensor can not use pre-allocated buffer
, Got 
The preallocated buffer is too small. Requires 
onnxruntime::utils::ConstantNodeProtoToTensorProto
 in 'Constant' node '
Unsupported attribute value type of 
Sparse Indices raw data size does not match expected.
onnxruntime::utils::CopySparseData
Sparse indices int64 data size does not match expected
Sparse indices int32 data size does not match expected
Invalid SparseTensor indices. INT16 indices must be in the raw data of indices tensor
Invalid SparseTensor indices. INT8 indices must be in the raw data of indices tensor
Invalid SparseTensor indices. Should one of the following types: int8, int16, int32 or int64
indices_shape[1] > 0 && static_cast<size_t>(indices_shape[1]) == dims.size()
cur_index == &*indices_data.cend()
Invalid SparseTensor indices. Should be rank 0 or 1. Got:
onnxruntime::utils::SparseTensorProtoToDenseTensorProto
 is not supported.
Element_size of: 
Unsupported sparse tensor data type of 
Must have a valid data type
HasDataType(dense_proto)
onnxruntime::utils::DenseTensorToSparseTensorProto
 data_type: 
onnxruntime::utils::UnpackInitializerData
Unsupported type: 
Invalid TensorProto
 in KernelRegistryManager
found duplicated provider 
 (node 
The node is not placed on any Execution Provider. 
Failed to find kernel for 
onnxruntime::FeedsFetchesInfo::MapNamesToMLValueIdxs
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\feeds_fetches_manager.cc
Error mapping feeds: 
Error mapping output names: 
input_copy_needed != DeviceCopyCheck::Unknown && output_copy_needed != DeviceCopyCheck::Unknown
onnxruntime::FeedsFetchesManager::SetDeviceCopyChecks
Caught exception while destructing CustomOpsLoader with message: 
onnxruntime::ExLibLoader::{dtor}::<lambda_3229e3f829fe3a5ff7c7841155b8b8df>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\ex_lib_loader.cc
Unloading DSO 
onnxruntime::ExLibLoader::~ExLibLoader
Failed to unload DSO: 
Caught exception while loading custom ops with message: 
 has already been loaded.
A dso with name 
onnxruntime::ExLibLoader::LoadExternalLib
Could not find OrtValue with idx '
session.disable_prepacking
. Ignoring allocator from 
Allocator already registered for 
onnxruntime::SessionState::SetupAllocators
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\session_state.cc
SaveMLValueNameIndexMapping
onnxruntime::SessionState::CreateGraphInfo
Done saving OrtValue mappings.
onnxruntime::SessionState::PopulateKernelCreateInfo
entry != kernel_create_info_map_.cend()
onnxruntime::SessionState::GetNodeKernelCreateInfo
. Do you have duplicated calls to SessionState::AddInitializedTensor function?
duplicated ort_value index:
onnxruntime::KernelUseSharedPrePackedBuffers
 doesn't have an implementation that can consume provided pre-packed weights
The kernel corresponding to the node 
allocator_for_caching.get() != nullptr
onnxruntime::SessionState::PrepackConstantInitializedTensors::<lambda_4b2c19fdf6db3770ba085ad29d6de2dd>::operator ()
 doesn't have an implementation that can cache computed pre-packed weights
weights_to_be_filled_in.buffers_.size() > 0
The op type of a node cannot be empty
!op_type.empty()
 which is of op type: 
 used in the node: 
Using cached version of pre-packed weight for constant initializer: 
Unable to write the provided PrePackedWeights instance into the container
) and node 
 is used by node 
Using an input in multiple nodes on different devices is not supported currently. Input:
Failed to find input name in the mapping: 
Only one node should produce an output. Existing entry for 
output_names_to_nodeinfo.empty()
onnxruntime::SessionState::AddOutputNameToNodeInfoMapping
 for attribute 
Entry exists in node 
existing_entries.find(attribute_name) == existing_entries.cend()
onnxruntime::SessionState::AddSubgraphSessionState
SetGraphAndCreateKernels must be called prior to GetExecutionInfo.
node_index_info_
onnxruntime::SessionState::GetNodeIndexInfo
onnxruntime::SessionState::UpdateToBeExecutedNodes
onnxruntime::GetSubGraphSessionStatesOrtFormat
onnxruntime::SessionState::SaveToOrtFormat
Main Graph instance should have populated all subgraphs when being resolved.
subgraph
onnxruntime::SessionState::CreateSubgraphSessionState
onnxruntime::SessionState::LoadFromOrtFormat::<lambda_0307bc470a7afef23306865e4ec45d55>::operator ()
onnxruntime::SessionState::LoadFromOrtFormat
. Invalid ORT format model.
Can't find node with index 
Unable to find compiled kernel hash for node '
onnxruntime::SessionState::FinalizeSessionState
onnxruntime::OuterScopeNodeArgLocationAccumulator::<lambda_50c8fe897e68e43b1818d88f70a689d9>::operator ()
onnxruntime::OuterScopeNodeArgLocationAccumulator::<lambda_a641b8f1e5dd6615c70f20c32f700fce>::operator ()
onnxruntime::OuterScopeNodeArgLocationAccumulator
subgraphs_kernel_create_info_maps.find(local_subgraph_kernel_create_info_map_key) == subgraphs_kernel_create_info_maps.end()
onnxruntime::AccumulateAllNestedSubgraphsInfo
onnxruntime::SessionState::FinalizeSessionStateImpl
 Attribute:
 Index:
' OpType:
Missing session state for subgraph. Node:'
entry != node_to_subgraph_ss.second.cend()
p_op_kernel
MaxAllocSize:             
NumArenaShrinkages:       
NumArenaExtensions:       
NumReserves:              
NumAllocs:                
MaxInUse:                 
TotalAllocated:           
InUse:                    
Limit:                    
 | in_use: 
 | Requested Size: 
  Size: 
, prev: 
, next: 
0 == memory_size % kMinAllocationSize
onnxruntime::BFCArena::AllocationRegion::AllocationRegion
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/bfc_arena.h
p_int >= base_int
onnxruntime::BFCArena::AllocationRegion::IndexFor
p_int < base_int + memory_size_
Could not find Region for: 
entry != regions_.end()
onnxruntime::BFCArena::RegionManager::RemoveAllocationRegion
Could not find Region for 
onnxruntime::BFCArena::RegionManager::RegionFor
 arena_extend_strategy: 
 memory limit: 
 initial_growth_chunk_size_bytes: 
 max_dead_bytes_per_chunk: 
 with following configs: initial_chunk_size_bytes: 
Creating BFCArena for 
onnxruntime::BFCArena::BFCArena
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\bfc_arena.cc
 bins of max chunk size 
Creating 
BinForSize(bin_size) == BinFromIndex(b)
BinForSize(bin_size + 255) == BinFromIndex(b)
BinForSize(bin_size * 2 - 1) == BinFromIndex(b)
BinForSize(bin_size * 2) != BinFromIndex(b)
h < chunks_.size()
onnxruntime::BFCArena::ChunkFromHandle
cudaMalloc
hipMalloc
Incorrect arena extend strategy.
onnxruntime::BFCArena::Extend::<lambda_6bf74fe8c2f6f409bb5a2a70c054cf56>::operator ()
 is smaller than requested bytes of 
Available memory of 
Failed to allocate memory for requested buffer of size 
 bytes.
Extended allocation by 
onnxruntime::BFCArena::Extend
Total allocated bytes: 
Allocated memory at 
 size: 
Reserving memory in BFCArena for 
onnxruntime::BFCArena::Reserve
reserved_chunks_.find(ptr) == reserved_chunks_.end()
h != kInvalidChunkHandle
tried to allocate 0 bytes
onnxruntime::BFCArena::AllocateRawInternal
 (actual) rounded_bytes:
 (requested) num_bytes: 
. bin_num:
Extending BFCArena for 
Failed to find a free memory block despite calling Extend. rounded_bytes=
.  Current allocation summary follows.
BFC Arena ran out of memory trying to allocate 
!chunk->in_use()
onnxruntime::BFCArena::FindChunkPtr
!c->in_use() && (c->bin_num == kInvalidBinNum)
onnxruntime::BFCArena::SplitChunk
 The total allocated bytes is now 
 bytes. 
 BFC Arena shrunk by 
onnxruntime::BFCArena::Shrink
onnxruntime::BFCArena::DeallocateRawInternal
!c1->in_use() && !c2->in_use()
onnxruntime::BFCArena::Merge
c2->prev == h1
onnxruntime::BFCArena::InsertFreeChunkIntoBin
!c->in_use() && (c->bin_num != kInvalidBinNum)
onnxruntime::BFCArena::RemoveFreeChunkIterFromBin
onnxruntime::BFCArena::RemoveFreeChunkFromBin
Could not find chunk in bin
BinFromIndex(c->bin_num)->free_chunks.erase(h) > 0
c->in_use() && (c->bin_num == kInvalidBinNum)
onnxruntime::BFCArena::FreeAndMaybeCoalesce
bin->free_chunks.count(h) == 1
onnxruntime::BFCArena::get_bin_debug_info
c->bin_num == bin_num
Allocator:
onnxruntime::BFCArena::DumpMemoryLog
Bin size: Chunks in_use/total (if not zero). Allocated bytes in_use/total. Requested bytes.
b->free_chunks.size() == bin_info.total_chunks_in_bin - bin_info.total_chunks_in_use
Requested 
. Bytes 
: Chunks 
Diff between in-use and requested bytes is 
, Chunk State: 
 bytes has max bytes of 
Bin for 
Overall chunks summary:
 of size 
  Chunk
  Free 
Summary of in-use chunks by size: 
. Total 
 chunks of size 
Sum Total of in-use chunks: 
Stats: 
onnxruntime::FunctionKernel::FunctionKernel
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/func_kernel.h
compute_info_->create_state_func(&context, &func_state_) == 0
1 == capability.nodes.size()
onnxruntime::PlaceNode
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\graph_partitioner.cc
onnxruntime::PartitionOnnxFormatModelImpl
Must use Function based fusion when exporting compiled nodes to dll.
fusion_style == IExecutionProvider::FusionStyle::Function
 did not return correct number of compiled functions
onnxruntime::InlineNodes
onnxruntime::GraphPartitioner::PartitionOnnxFormatModel
onnxruntime::PartitionOrtFormatModelImpl
 has Compile error: 
single_node_compute_func should have 1 elements
. Execution Provider must generate unique names across the entire model.
Existing entry in compiled kernel hashes for 
onnxruntime::GraphPartitioner::PartitionOrtFormatModel
No provider specified.
onnxruntime::GraphPartitioner::Partition
Compiled kernel hashes must be provided
compiled_kernel_hashes != nullptr
nullptr != type_proto
onnxruntime::utils::GetMLDataType
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\mldata_type_utils.cc
SessionState for subgraphs is null. Invalid ORT format model.
Kernel create info is null. Invalid ORT format model.
Kernel create info node indices are null. Invalid ORT format model.
Kernel create info hashes are null. Invalid ORT format model.
Size mismatch for kernel create info node indexes and hashes. Invalid ORT format model.
 is missing. Invalid ORT format model.
Subgraph SessionState entry for 
 is null. Invalid ORT format model.
Subgraph SessionState for 
offset >= 0 && static_cast<size_t>(offset) < node_values_size_
onnxruntime::NodeIndexInfo::GetMLValueIndex
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < all_values_size_
onnxruntime::IExecutionFrame::GetMLValue
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/execution_frame.h
node_index_info and ort_value_idx_map are out of sync and cannot be used
node_index_info_.GetMaxMLValueIdx() == ort_value_idx_map.MaxIdx()
onnxruntime::IExecutionFrame::IExecutionFrame
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\execution_frame.cc
 Requested shape:
OrtValue shape verification failed. Current shape:
shape && tensor.Shape() == *shape
onnxruntime::IExecutionFrame::GetOrCreateNodeOutputMLValue
shape && sp_tensor.DenseShape() == *shape
invalid index 
feeds.size() == feed_mlvalue_idxs.size()
onnxruntime::IExecutionFrame::Init
fetches.empty() || fetches.size() == fetch_mlvalue_idxs_.size()
 entries which doesn't match the number of fetches the frame was initialized with of 
Fetches vector passed to GetOutputs contains 
 failed. Error:
Allocation of memory pattern buffer for 
onnxruntime::ExecutionFrame::{ctor}::<lambda_0a31ecaa8a2a18f121ec57815ab07520>::operator ()
buffers_.find(location) == buffers_.end()
onnxruntime::ExecutionFrame::ExecutionFrame
 returned nullptr
Trying to allocate memory for unused optional inputs/outputs
Tensor shape cannot contain any negative value
ort_value.Fence() == nullptr
onnxruntime::ExecutionFrame::AllocateMLValueTensorSelfOwnBufferHelper
, fall back to default allocation behavior
 but the actually size is: 
, block in memory pattern size is: 
For ort_value with index: 
. Validate usage of dim_value (values should be > 0) and dim_param (all values with the same string should equate to the same size) in shapes in the model.
Shape mismatch attempting to re-use buffer. 
onnxruntime::ExecutionFrame::AllocateMLValueTensorPreAllocateBuffer
mlvalue.Fence() == nullptr
onnxruntime::AllocateSparseTensor
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < alloc_plan.size()
onnxruntime::ExecutionFrame::AllocateAsPerAllocationPlan
We don't expect custom allocators for non-tensor types, so a shape is mandatory here.
Allocation of tensor types requires a shape.
Invalid allocation kind: 
 for output 
 does not match actual shape of 
Expected shape from model of 
onnxruntime::ExecutionFrame::VerifyOutputSizes
onnxruntime::ExecutionFrame::ReleaseMLValueImpl
ort_value_idx >= 0 && static_cast<size_t>(ort_value_idx) < alloc_plan.size()
onnxruntime::ExecutionFrame::GetAllocationPlan
 failed: 
 size=
TraceAllocation for ort_value_idx=
onnxruntime::ExecutionFrame::TraceAllocate
onnxruntime::ExecutionFrame::TraceFree
TraceFree for ort_value_idx=
Memory pattern planner is not enabled on this execution framework.
model format error! Need a key for the external data info
model format error! Need a value for the external data info
location
offset
 failed
parsing 
length
checksum
model format error!
model format error! Missing 'location'
onnxruntime::NodeIndexInfo::Init::<lambda_1123ca3288c22333dcfbc6780e56f3b6>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\node_index_info.cc
onnxruntime::NodeIndexInfo::Init::<lambda_4404716c35945f1da6a07154c932397d>::operator ()
Can't slice a non-tensor OrtValue. Type was 
ort_value.IsTensor()
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Create
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\ort_value_tensor_slicer.cc
OrtValue has not been allocated so can't be sliced.
ort_value.IsAllocated()
. Shape:
Insufficient dimensions to slice on 
gsl::narrow_cast<int64_t>(tensor_shape.NumDimensions()) >= slice_dimension
. Dimension 0 is 
Invalid dim0_offset of 
dim0_offset < dim0_size
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Iterator::Iterator
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Create
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Iterator::Iterator
 does not.
All implicit inputs should have OrtValue instances by now. 
entry != nullptr
onnxruntime::OpKernelContextInternal::OpKernelContextInternal
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/op_kernel_context_internal.h
Multiple errors were found.
onnxruntime::ParallelExecutor::Execute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\parallel_executor.cc
ParallelExecutor::Execute
Begin execution
onnxruntime::ParallelExecutor::RunNodeAsync
Exiting due to terminate flag being set to true.
Got nullptr from GetKernel for node: 
op_name
_fence_before
' Status Message: 
 node. Name:'
Non-zero status code returned while running 
provider
thread_scheduling_stats
_kernel_time
_fence_after
Unknown exception was caught by catch-all handler.
Exception running nodes starting at 
onnxruntime::SequentialExecutor::Execute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\sequential_executor.cc
graph_index
exec_plan_index
activation_size
parameter_size
output_size
SequentialExecutor::Execute
onnxruntime::ReleaseNodeMLValues
 already exist.
func info for node: 
Can't use func with null ptr
 not found.
onnxruntime::FuncManager::GetFuncs
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\fuse_nodes_funcs.cc
source and destination buffer size mismatch
onnxruntime::utils::detail::CopyLittleEndian
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\endian_utils.cc
Previous entry was not terminated.
starts_.size() == ends_.size()
onnxruntime::AllocPlanPerValue::ProgramCounter::AddStart
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/sequential_execution_plan.h
Invalid 'start'. Value is smaller than previous 'end'.
starts_.empty() || start > ends_.back()
No matching 'start' entry.
starts_.size() == ends_.size() + 1
onnxruntime::AllocPlanPerValue::ProgramCounter::AddEnd
Invalid 'end'. Value is larger than 'start'.
end >= starts_.back()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\allocation_planner.cc
SessionState should have saved the KernelCreateInfo prior to this running. NodeIndex:
entry != kernel_create_info_map.cend()
onnxruntime::GetKernelCreateInfo
onnxruntime::PlannerImpl::Index
n >= 0 && static_cast<size_t>(n) < ort_value_info_.size()
onnxruntime::PlannerImpl::UseCount
onnxruntime::PlannerImpl::Buffer
n >= 0 && static_cast<size_t>(n) < plan_.allocation_plan.size()
onnxruntime::PlannerImpl::AllocPlan
id >= 0 && static_cast<size_t>(id) < ort_value_info_.size()
onnxruntime::PlannerImpl::ProcessDef
reused != reused_for
onnxruntime::PlannerImpl::Reuse
nullptr != tensor_type_base
onnxruntime::PlannerImpl::GetElementSize
There is no location for this node arg in the outer scope location map
found_in_outer_scope_location_map
onnxruntime::PlannerImpl::ComputeUseCounts::<lambda_47e575137926bdb4c6da3cd254bbf347>::operator ()
Can not find the node 
Should not have entry in kernel create info with nullptr for kernel_def
p_kernel_def
onnxruntime::PlannerImpl::ComputeUseCounts
Can not find the execution provider 
allocator
onnxruntime::PlannerImpl::GetLocationForNodeInput
specific_subgraph_kernel_create_info_map != subgraphs_kernel_create_info_maps_.end()
onnxruntime::PlannerImpl::GeneratePlanForWeightsHelper
onnxruntime::PlannerImpl::ComputeReusePlan
Only tensors are supported for external outputs for now.
!IsNonTensor(*node_output)
Invalid program_counter entries at index 
entry.program_counter.HasValidEntries()
onnxruntime::PlannerImpl::VerifyMemoryTimeSchedule
AllocPlan(ml_value_idx).program_counter.Ends().back() == program_counter
onnxruntime::PlannerImpl::GenerateDeallocationPlan
onnxruntime::PlannerImpl::CreatePlan
buffers_.size() == buffer_sizes_.size()
onnxruntime::PrePackedWeights::GetHash
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\prepacked_weights.cc
Unsupported device allocator in the context of pre-packed weights caching: 
onnxruntime::PrepackedWeightsContainer::GetOrCreateAllocator
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\prepacked_weights_container.cc
Failed to get allocator for location: 
duplicated location
onnxruntime::TensorAllocatorWithMemPattern::FinalizePlan
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor_allocator_with_mem_pattern.h
Internal error.
 is not found
Mem pattern for initializer 
' is not found
Weight buffer for initializer '
' failed
Get preallocated buffer for initializer '
onnxruntime::TensorAllocatorWithMemPattern::Trace
session.use_device_allocator_for_initializers
Failed memory size calculation
DeserializeTensorProto() takes either pre-allocated buffer or an allocator!
Internal error. The preallocated buffer is too small. Requires 
onnxruntime::session_state_utils::DeserializeTensorProto
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\session_state_utils.cc
string tensor is not supported for copying between allocators
Failed to copy tensor to 
 ) is different from what is supplied (
) because the ORT planned memory location device 
Cannot use user supplied initializer with name: (
onnxruntime::session_state_utils::SaveInitializedTensors::<lambda_6c4003787d982facc3e4a14cc0a1fb45>::operator ()
Saving initialized tensors.
onnxruntime::session_state_utils::SaveInitializedTensors
OrtValue indexes should have been populated.
ort_value_name_idx_map.MaxIdx() > -1
entry != initialized_tensors_to_allocate.end() && entry->second->data_type() != ONNX_NAMESPACE::TensorProto_DataType_STRING
 bytes for 
[Memory] SessionStateInitializer statically allocates 
Using user supplied initializer with name (
 failed.
Deserialize tensor 
Done saving initialized tensors
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping::<lambda_f663e1cb5f92583d40a80c3711b532b4>::operator ()
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping::<lambda_2314020bbb2bcb9dacfa0af3f7ebfa1d>::operator ()
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping
 is not used by any node.
 input with name 
Subgraph
Graph
!using_counters_
onnxruntime::MemPatternPlanner::TraceAllocation
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/mem_pattern_planner.h
current <= buffer_size_
ALLOW_RELEASED_ONNX_OPSET_ONLY
ai.onnx.ml
ai.onnx.training
ai.onnx.preview.training
 Dimension=
Can't merge shape info. Both source and target dimension have values but they differ. Source=
Mismatch between number of source and target dimensions. Source=
TypeProto must have shape for this to run
onnxruntime::utils::GetShape
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/tensorprotoutils.h
Constant
 are '0' and '1'. The environment variable contained the value: 
onnxruntime::model_load_utils::IsAllowReleasedONNXOpsetsOnlySet
D:\a\_work\1\s\onnxruntime\onnxruntime\core/graph/model_load_utils.h
Output:
Source and target must both be either tensors or sparse tensors
. Falling back to lenient merge.
 target:
' source:
Error merging shape info for output. '
onnxruntime::MergeShapeInfo
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph.cc
 Input=
Type mismatch. Current=
Tensor element type mismatch. 
onnxruntime::NodeArg::UpdateTypeAndShape
SparseTensor element type mismatch. 
] op_type [
Node [
Serialization of fused function body is not currently supported, 
does not have the graph for key 
onnxruntime::Node::SaveToOrtFormat
fbs_node_arg_names cannot be null
onnxruntime::Node::LoadFromOrtFormat::<lambda_5cefde7572b858b861a84f36027071f7>::operator ()
node_arg_name cannot be null
], could not find NodeArg 
LoadNodeArgsFromOrtFormat: Node [
onnxruntime::Node::LoadFromOrtFormat
fbs_attr cannot be null
Serialization error. Graph attribute was serialized without Graph instance
Node::LoadFromOrtFormat, input_arg_counts is missing
Node::LoadEdgesFromOrtFormat, edge is missing for 
onnxruntime::Node::LoadEdgesFromOrtFormat::<lambda_e796a17fc8d69be0685e7c1cd3180fe4>::operator ()
 is not the same as this node's index:
input index: 
onnxruntime::Node::LoadEdgesFromOrtFormat
input edges
output edges
This is an invalid model. The sum of input arg count is not equal to size of input defs in node (
graph_proto cannot be null
graph_proto != nullptr
onnxruntime::Graph::Graph
' Model is invalid.
Duplicate constant node sparse initializer name: '
Sparse initializer must have a name. This model is invalid
utils::HasName(sparse_tensor)
Duplicate sparse_tensor_initializer: '
. Please, fix your model.
' the model will use the latest encountered initializer
Duplicate initializer (dense, sparse or ConstantNode): '
This is an invalid model. Tensor does not have type information.
or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.
by either re-generating the model with latest exporter/converter 
Move it out of graph inputs if there is no need to override it, 
This may prevent some of the graph optimizations, like const folding. 
 appears in graph inputs and will not be treated as constant value/weight. 
Initializer 
Graph state to be loaded into must be empty.
graph_inputs_excluding_initializers_.empty() && graph_inputs_including_initializers_.empty() && value_info_.empty() && graph_outputs_.empty()
onnxruntime::Graph::InitializeStateFromModelFileGraphProto
Graph ctor should have created NodeArg for initializer. Missing:
node_arg
) does not exist in the graph.
This is an invalid model. Graph output (
This is an invalid model. Error: two nodes with same node name (
This is an invalid model. Error: Duplicate definition of name (
onnxruntime::Graph::SetOuterScopeNodeArgs
Invalid node indexes specified when adding edge.
onnxruntime::Graph::AddEdge
Invalid source node arg slot specified when adding edge.
Invalid destination node arg slot specified when adding edge.
Argument type mismatch when adding edge.
Invalid node indexes specified when removing edge.
onnxruntime::Graph::RemoveEdge
Invalid source node arg slot specified when removing edge.
Invalid destination node arg slot specified when removing edge.
Argument mismatch when removing edge.
onnxruntime::Graph::BuildConnections
 Graph may not conform to the ONNX spec and contain initializers that are not graph inputs.
This is an invalid model. At top level graph without matching NodeArg that subgraph consumes. Name=
This is an invalid model. Failed to find NodeArg in all parent graphs. Name=
' is not a graph input, initializer, or output of a previous node.
Invalid model. Node input '
Some nodes are not included in the topological sort, graph have a cycle.
onnxruntime::Graph::KahnsTopologicalSort
This is an invalid model. Error: the graph is not acyclic.
Graph attribute inferencing failed: 
 in node 
No Graph instance was found for attribute 
 inputs. Either provide all subgraph inputs, or just the required inputs.
 inputs and requires 
 inputs but subgraph has 
Size mismatch validating subgraph inputs. Got 
Node:
Subgraph input missing type.
onnxruntime::Graph::InferAndVerifySubgraphTypes
UpdateTypeShapeInference is not intended to be used with control flow nodes containing subgraphs
node.GetAttributeNameToMutableSubgraphMap().empty()
onnxruntime::Graph::UpdateShapeInference
) Op (
Node (
) does not have type information set by parent node.
) input arg (
This is an invalid model. Node (
) is invalid.
) in node (
) of operator (
' of input parameter (
This is an invalid model. Type Error: Type '
 in node (
) bound to different types (
) of Optype (
Type Error: Type parameter (
onnxruntime::Graph::InferAndVerifyTypeMatch
) type inference failed
) output arg (
) does not match expected type (
) of node (
) of output arg (
Type Error: Type (
) does not have type information.
This is an invalid model. Model input (
 but usage of initializer in graph expects 
' has element type 
Type Error: Data in initializer '
 does not match. 
Type Error: Shape of initializer 
This is an invalid model. Error in Node:
onnxruntime::Graph::VerifyNodeAndOpMatch
 is not a registered function/op
Fatal error: 
) is required but not specified.
) attribute (
. Execution will fail if ORT does not have a specialized kernel for this op
. Error message 
' optype 
Function body initialization failed for node '
onnxruntime::Graph::InitFunctionBodyForNode
Error: Duplicate definition-site for (
onnxruntime::Graph::InitInputsInitializersOutputs
onnxruntime::Graph::PerformTypeAndShapeInferencing
onnxruntime::Graph::ForThisAndAllSubgraphs
onnxruntime::Graph::Resolve
Shouldn't be possible to have NodeArgs that haven't been handled already.
outer_scope_node_args_consumed.empty()
 but different TensorProto.
AddInitializedTensor already has tensor with name 
existing->second == &tensor
onnxruntime::Graph::AddInitializedTensor
sparse_tensor_names_ not in sync with name_to_initial_tensor_
sparse_tensor_names_.count(tensor_name) == 0
onnxruntime::Graph::RemoveInitializedTensor
graph_proto_ is not in sync with name_to_initial_tensor_.
!found
_token_
onnxruntime::Graph::SaveToOrtFormat
 as it still has output edges.
Can't remove node 
node->GetOutputEdgesCount() == 0
onnxruntime::Graph::RemoveNode
Failed to convert dense initializer to sparse
onnxruntime::Graph::ToGraphProto
'was added but does not exist. 
Outer scope node arg name '
onnxruntime::Graph::ToGraphProtoInternal
'. It is not used by any node and should be removed from the model.
Removing initializer '
onnxruntime::Graph::CleanUnusedInitializers
'. It is no longer used by any node.
 must be either specified in graph inputs or graph initializers.
nodes_.size() < static_cast<unsigned int>(std::numeric_limits<int>::max())
onnxruntime::Graph::AllocateNode
nullptr != func_meta_def
onnxruntime::Graph::CreateFusedSubGraphNode
onnxruntime::Graph::FinalizeFuseSubGraph
dst_implicit_input_idx < (int)node->ImplicitInputDefs().size()
onnxruntime::Graph::InlineFunction
Input to set must exist.
input->Exists()
onnxruntime::Graph::SetInputs
onnxruntime::Graph::LoadFromOrtFormat
NodeArg Name is missing. Invalid ORT format model.
onnxruntime::Graph::LoadFromOrtFormat::<lambda_d4d964124cf0bb1a6a87aab9e264ec0e>::operator ()
Initializer tensor is missing. Invalid ORT format model.
Duplicate initializer (dense or ConstantNode): '
Sparse Initializer tensor is missing. Invalid ORT format model.
NodeArg is missing. Invalid ORT format model.
Node is missing. Invalid ORT format model.
Node index is out of range
NodeEdge is missing. Invalid ORT format model.
index < data_.size()
onnxruntime::ConstPointerContainer<class std::vector<class onnxruntime::NodeArg *,class std::allocator<class onnxruntime::NodeArg *> > >::at
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/common/const_pointer_container.h
Domain already set in registry
onnxruntime::OnnxRuntimeOpSchemaRegistry::RegisterOpSet
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\schema_registry.cc
onnxruntime::OnnxRuntimeOpSchemaRegistry::RegisterOpSchemaInternal
known by the checker.
, but it its domain is not
than the operator set version 
, but it its version is higher
IndexedSubGraph contains values not present in the Graph
graph_->GetNode(idx) != nullptr
onnxruntime::GraphViewer::GraphViewer
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph_viewer.cc
Mismatch between Graph and IndexedSubGraph. Input not found:
nodearg
Mismatch between Graph and IndexedSubGraph. Output not found:
Mismatch between Graph and IndexedSubGraph. Node not found: 
Invalid ExecutionOrder
onnxruntime::GraphViewer::GetNodesInTopologicalOrder
Not supported with filtered graph.
filter_info_ == nullptr
onnxruntime::GraphViewer::GetRootNodes
 is till opset 
 is under development and support for this is limited. The operator schemas and or other functionality may change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain 
ONNX Runtime only *guarantees* support for models stamped with official released onnx opset versions. Opset 
onnxruntime::model_load_utils::ValidateOpsetForDomain
 is under development and support for this is limited. The operator schemas and or other functionality could possibly change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain 
ModelProto does not have a graph.
onnxruntime::Model::Model
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\model.cc
Missing opset in the model. All ModelProtos MUST have at least one entry that specifies which version of the ONNX OperatorSet is being imported.
Missing model IR version.
, max supported IR version: 
Unsupported model IR version: 
 model may run depending upon legacy support of some older opset version operators.
ONNX Runtime only *guarantees* support for models stamped with opset version 7 or above for opset domain 'ai.onnx'. Please upgrade your model to opset 7 or higher. For now, this opset 
Failed to load model with error: 
No graph was found in the protobuf.
onnxruntime::Model::Load
Protobuf parsing failed.
<p_fd> less than 0.
<p_fd> is less than 0.
onnxruntime::Model::Save
Protobuf serialization failed.
onnxruntime::Model::SaveToOrtFormat
Null entry in metadata_props. Invalid ORT format model.
onnxruntime::Model::LoadFromOrtFormat
Graph is null. Invalid ORT format model.
onnxruntime::SaveModel
 failed. File doesn't exist
Load model 
system error number 
Attribute expected to have tensor or sparse tensor type
 is null
 expected to have tensor or sparse tensor type: 
Attribute 
 expected to have tensor or sparse type
 expected to have tensor type
 should specify a shape
Negative values are not allowed in a shape specification
Incompatible dimensions
 but has rank 
 expected to have rank 
Dimension mismatch in unification between 
 expected to have rank >
optional(seq(tensor(uint8)))
optional(seq(tensor(uint16)))
optional(seq(tensor(uint32)))
optional(seq(tensor(uint64)))
optional(seq(tensor(int8)))
optional(seq(tensor(int16)))
optional(seq(tensor(int32)))
optional(seq(tensor(int64)))
optional(seq(tensor(float16)))
optional(seq(tensor(float)))
optional(seq(tensor(double)))
optional(seq(tensor(string)))
optional(seq(tensor(bool)))
optional(seq(tensor(complex64)))
optional(seq(tensor(complex128)))
optional(tensor(uint8))
optional(tensor(uint16))
optional(tensor(uint32))
optional(tensor(uint64))
optional(tensor(int8))
optional(tensor(int16))
optional(tensor(int32))
optional(tensor(int64))
optional(tensor(float16))
optional(tensor(float))
optional(tensor(double))
optional(tensor(string))
optional(tensor(bool))
optional(tensor(complex64))
optional(tensor(complex128))
'pads' input must be a 1D (shape: [2 * n_input_dims]) tensor of type int64
Pads has incorrect number of values
output_shape
output_padding
input_ids shall be 2 dimensions
segment_ids input shall be 2 dimensions
word_embedding should have 2 dimensions and dimension size is known.
position_embedding should have 2 dimensions, dimension size known, and same hidden size as word_embedding.
segment_embedding should have 2 dimensions, dimension size known, and same hidden size as word_embedding.
gamma should have 2 dimension, dimension size known, and same hidden size as word_embedding.
beta should have 1 dimension, dimension size known, and same hidden size as word_embedding.
Input tensors of wrong rank (0).
Incompatible dimensions for matrix multiplication
Inputs 0 shall be 3 dimensions
Invalid bias shape
qkv_hidden_sizes
qkv_hidden_sizes should have 3 elements
Inputs 4 shall be 5 dimensions
X_bias
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\contrib_defs.cc
Number of attention heads
Whether every token can only attend to previous tokens. Default value is 0.
Hidden layer sizes of Q, K, V paths in Attention
3D input tensor with shape (batch_size, sequence_length, input_hidden_size)
2D input tensor with shape (input_hidden_size, 3 * hidden_size), where hidden_size = num_heads * head_size
weight
1D input tensor with shape (3 * hidden_size)
Attention mask with shape (batch_size, 1, max_sequence_length, max_sequence_length), (batch_size, past_sequence_length + sequence_length)or (batch_size, sequence_length, past_sequence_length + sequence_length), or index with shape (batch_size) or (2 * batch_size).
past state for key and value with shape (2, batch_size, num_heads, past_sequence_length, head_size).
additional add to QxK' with shape (batch_size, num_heads, sequence_length, sequence_length).
extra_add
3D output tensor with shape (batch_size, append_length, hidden_size)
present state for key and value with shape (2, batch_size, num_heads, past_sequence_length + sequence_length, head_size)
present
Constrain input and output types to float tensors.
Constrain mask index to integer types
QAttention
2D input tensor with shape (input_hidden_size, 3 * hidden_size), hidden_size = num_heads * head_size
scale of quantized input tensor. It's a scalar, which means a per-tensor/layer quantization.
input_scale
scale of weight scale. It's a scalar or a 1D tensor, which means a per-tensor/per-column quantization.Its size should be 3 * hidden_size if it is per-column quantization
weight_scale
Attention mask index with shape (batch_size)
zero point of quantized input tensor.It's a scalar, which means a per-tensor/layer quantization.
input_zero_point
zero point of quantized weight tensor. It's a scalar or a 1D tensor, which means a per-tensor/per-column quantization.Its size should be 3 * hidden_size if it is per-column quantization
weight_zero_point
3D output tensor with shape (batch_size, sequence_length, hidden_size)
Constrain input and output types to int8 tensors.
LongformerAttention
One sided attention windows length W, or half of total window length
window
3D input tensor with shape (batch_size, sequence_length, hidden_size), hidden_size = num_heads * head_size
2D input tensor with shape (hidden_size, 3 * hidden_size)
Attention mask with shape (batch_size, sequence_length)
global_weight
global_bias
Global attention flags with shape (batch_size, sequence_length)
global
Constrain to integer types
The epsilon value to use to avoid division by zero.
2D words IDs with shape (batch_size, sequence_length)
input_ids
2D segment IDs with shape (batch_size, sequence_length)
segment_ids
2D with shape (,hidden_size)
word_embedding
2D with shape (, hidden_size)
position_embedding
segment_embedding
1D gamma tensor for layer normalization with shape (hidden_size)
1D beta tensor for layer normalization  with shape (hidden_size)
2D attention mask with shape (batch_size, sequence_length)
1D mask_index tensor with shape (batch_size)
Constrain input and output integer tensors types
Constrain input and output float tensors types.
QEmbedLayerNormalization
word_embedding_quant
position_embedding_quant
gamma_quant
beta_quant
Scale for word embeddings
word_embedding_scale
Scale for position embeddings
position_embedding_scale
Scale for segment embeddings
segment_embedding_scale
Scale for 1D gamma tensor
gamma_scale
Scale for 1D beta tensor
beta_scale
Zero point for word embeddings
word_embedding_zero_point
Zero point for position embeddings
position_embedding_zero_point
Zero Point for segment embeddings
segment_embedding_zero_point
Zero Point for 1D gamma tensor
gamma_zero_point
Zero Point for 1D beta tensor
beta_zero_point
LayerNorm Output
layernorm_out
Mask Index Output
mask_index_out
Constrain input and output types to float32 tensors.
input tensor
bias tensor
output tensor
Constrain input and output types to float or half tensors.
3D input tensor with shape (batch_size, sequence_length, hidden_size)
3D skip tensor with shape (batch_size, sequence_length, hidden_size)
1D input tensor with shape (hidden_size)
1D skip tensor with shape (hidden_size
1D bias tensor with shape (hidden_size
Saved mean used during training to speed up gradient computation
Saved inverse standard variance used during training to speed up gradient computation.
inv_std_var
Constrain mean and inv_std_var to float tensors.
NGramRepeatBlock
The NGram size.
ngram_size
2D input tensor with shape (batch_size, sequence_length)
2D input tensor with shape (batch_size, vocab_size)
scores
2D output tensor with shape (batch_size, vocab_size)
scores_out
Constrain indices to integer types
Constrain scores input and output types to float tensors.
input_as_shape
extra_shape
Input's shape must be 4-D
border
'Border' attribute must be present and must contain exactly 4 values - (left_border, top_border, right_border, bottom_border)
scale
'Scale' must contain exactly 2 values - (height, width)
) + bottom_border (
) needs to be greater than or equal to the top_border (
Input's height (
) + right_border (
) needs to be greater than or equal to the left_border (
Input's width (
) + scale[0] (
) + scale[1] (
First input does not have rank 2
Second input does not have rank 2
Input axis is invalid: 
Input dimensions are either [C] or [N][C] allowed
inputs are expected to have tensor type and output type should not be null.
positive
both data and indices tensor need to have rank larger than zero.
last dimension of indices must not be larger and rank of data tensor
'pads' input must be a 1D (shape: [input_rank]) or 2D tensor (shape: [1, input_rank]) of type int64
first input tensor has wrong dimension
rois input tensor has wrong dimension
batch_indices shape input tensor has wrong dimension
crop_size shape input tensor has wrong dimension
stash_type
Epsilon
XShape
Zero1D
Axis1D
PrefixShape
NumReducedAxes
SuffixShape
ReducedShape
Flatten
Mean2D
Square
MeanOfSquare
SquareOfMean
VarPlusEpsilon
StdDev
Deviation
Normalized
NormalizedT
Scale
Scaled
Biased
InvStdDev2D
InvStdDev
ERFCX
ERFCXPlus1
Input rank must be >= 2.
 != mat_h:
The inner-most 2 dimensions must have the same size (mat_w:
isinf_only
isnan_only
Both attributes isinf_only and isnan_only cannot be set. Unset both to check for both conditions.
!(isinf_only && isnan_only)
onnxruntime::contrib::RegisterContribSchemas::<lambda_9390aed8e2d795f49afe09f731079323>::operator ()
Optional is expected to have an output.
Attribute 'type' should be a TypeProto and it should specify a type.
Input type is null. Type information is expected for the input.
Optional is expected to have either an input or the type attribute set.
OptionalHasElement is expected to have 1 input.
OptionalHasElement is expected to have 1 output.
OptionalGetElement must have an input element.
Input type is null. Input must have Type information.
Input must be an optional-type value containing an element with type information.
Affine
Value of alpha
Value of beta
1D input tensor
1D output tensor
ImageScaler
Bias applied to each channel, same size as C.
The scale to apply.
Input tensor of shape [N,C,H,W]
Result, has same shape and type as input
A 1-D values of (leftBorder, topBorder, rightBorder, bottomBorder).
A 1-D values of (height, width).
Result, has same type as input, with H and W dimensions reduced.
Threshold value
Input tensor
Output tensor
DynamicSlice
Tensor of data to extract slices from.
1-D tensor of starting indices of corresponding axis in `axes`
1-D tensor of ending indices (exclusive) of corresponding axis in axes
1-D tensor of axes that `starts` and `ends` apply to.
Sliced data tensor.
Constrain input and output types to all tensor types.
GivenTensorFill
The shape of filled tensor
The filled tensor
values
Input data to be scaled
Output data after scaling
GRUUnit
Bool to determine if hidden state is zeroes or passed along for timesteps past the given sequence_length.
drop_states
The previous GRU hidden state.
hidden_prev
Unactivated gate outputs from forget, update, and output gates, pre-activation.
gates
Array of sequence lengths.  len(seq_lengths) should equal batch size N.
seq_lengths
The timestep for this operation.
The new GRU hidden state calculated by this op.
hidden
MeanVarianceNormalization
If 1, mean and variance are computed across channels. Default is 0.
across_channels
If 0, normalize the mean only.  Default is 1.
normalize_variance
Scaling value
The scaled hyperbolic tangent values of the input tensor computed element-wise
SampleOp
Constrain to any tensor type. If the dtype attribute is not provided this must be a valid output type.
MaxpoolWithMask
Constrain input0 and output types to float tensors
signal_ndim
normalized
onesided
Irfft
ComplexMul
input_0
input_1
ComplexMulConj
ConvTransposeWithDynamicPads
Constrain input and output types to float tensors
Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero.
Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero.
Input tensor C. The shape of C should be unidirectional broadcastable to (M, N).
Output tensor of shape (M, N).
Constrain input and output types to float/int tensors.
Whether A should be transposed
Whether B should be transposed
Scalar multiplier for the product of input tensors A * B.
Scalar multiplier for input tensor C.
activation_gamma
ExpandDims
Specified axis to insert a dimension
AttnLSTM
Tokenizer
Strings to tokenize
Tokenized strings
Input/Output is a string tensor
Boolean whether to mark the beginning/end character with start of text character (0x02)/end of text character (0x03).
The string used to pad output tensors when the tokens extracted doesn't match the maximum number of tokens found. If start/end markers are needed, padding will appear outside the markers.
pad_value
An optional string. Token's regular expression in basic POSIX format (pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html#tag_09_03). If set, tokenizer may produce tokens matching the specified pattern. Note that one and only of 'tokenexp' and 'separators' should be set.
tokenexp
an optional list of strings attribute that contains a list of separators - regular expressions to match separators Two consecutive segments in X connected by a separator would be divided into two tokens. For example, if the input is "Hello World!" and this attribute contains only one space character, the corresponding output would be ["Hello", "World!"]. To achieve character-level tokenization, one should set the 'separators' to [""], which contains an empty string.
separators
Minimum number of characters allowed in the output. For example, if mincharnum is 2, tokens such as "A" and "B" would be ignored
mincharnum
MatMulInteger16
N-dimensional matrix A
N-dimensional matrix B
Matrix multiply results from A * B
Constrain input A data types as 16-bit integer tensor
Constrain input B data types as 16-bit integer tensor
Constrain output Y data types as 32-bit integer tensor.T3 must be tensor(uint32) when both T1 and T2 are tensor(uint16),or must be tensor(int32) when either T1 or T2 is tensor(int16).
Scalar multiplier for the product of the input tensors.
Whether A should be transposed on the last two dimensions before doing multiplication
Whether B should be transposed on the last two dimensions before doing multiplication
Matrix multiply results
SparseToDenseMatMul
2-dimensional sparse matrix A. Either COO or CSR format
N-dimensional dense matrix B
sparse_tensor(float)
sparse_tensor(double)
sparse_tensor(int64)
sparse_tensor(int32)
sparse_tensor(uint64)
sparse_tensor(uint32)
MurmurHash3
An input tensor to hash.
32-bit hash value.
Constrain input type to unsigned or signed 32-bit integer tensor, or string tensor. It should be utf-8 encoded if using unicode.
Constrain output type to unsigned and signed 32-bit integer tensor.
Seed for the hashing algorithm, unsigned 32-bit integer, default to 0.
If value is 1, output type is uint32_t, else int32_t. Default value is 1.
GatherND
Tensor of rank r >= 1.
Tensor of rank q >= 1.
indices
Tensor of rank q-1+r-indices[-1].
Constrain input and output types to any tensor type.
Constrain indice type to int32 or int64
WordConvEmbedding
Integer representing the embedding vector size for each word.If not provide, use the fileter size of conv weight
embedding_size
This operator applies convolution to word from left to right with window equal to conv_window_size and stride to 1.Take word 'example' for example, with conv_window_size equal to 2, conv is applied to [ex],[xa], [am], [mp]...If not provide, use the first dimension of conv kernal shape.
conv_window_size
Integer representing the embedding vector size for each char.If not provide, use the char embedding size of embedding vector.
char_embedding_size
Specify batchs of sequence words to embedding
Sequence
Specify weights of conv
Specify bias of conv
Specify embedding vector of char
Constrain to tensor(int32).
Constrain to tensor(float).
constant
Three modes: `constant`(default) - pads with a given constant value, `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis, `edge` - pads with the edge values of array
Input tensor.
Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank] or a 2D tensor of shape [1, 2 * input_rank]. `pads` format (1D example) should be as follow [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
(Optional) A scalar or rank 1 tensor containing a single value to be filled if the mode chosen is `constant` (by default it is 0.0).
Tensor after padding.
Unique
A 1-D input tensor that is to be processed.
A 1-D tensor of the same type as 'x' containing all the unique values in 'x' sorted in the same order that they occur in the input 'x'
A 1-D INT64 tensor of the same size as 'x' containing the indices for each value in 'x' in the output 'uniques'
A 1-D INT64 tensor containing the the count of each element of 'uniques' in the input 'x'
counts
Input can be of any tensor type.
CDist
sqeuclidean
The distance metric to use. If a string, the distance function can be "braycurtis", "canberra", "chebyshev", "cityblock", "correlation", "cosine", "dice", "euclidean", "hamming", "jaccard", "jensenshannon", "kulsinski", "mahalanobis", "matching", "minkowski", "rogerstanimoto", "russellrao", "seuclidean", "sokalmichener", "sokalsneath", "sqeuclidean", "wminkowski", "yule".
metric
2D matrix with shape (M,N)
2D matrix with shape (K,N)
A 2D Matrix that represents the distance between each pair of the two collections of inputs.
Constrains input to only numeric types.
CropAndResize
bilinear
The pooling method. Two modes are supported: 'bilinear' and 'nearest'. Default is 'bilinear'.
Value used for extrapolation, when applicable. Default is 0.0f. 
extrapolation_value
Input data tensor from the previous operator; 4-D feature map of shape (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[y1, x1, y2, x2], ...]. The RoIs' coordinates are normalized in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.
1-D tensor of shape (num_rois,) with each element denoting the index of the corresponding image in the batch.
batch_indices
1-D tensor of 2 elements: [crop_height, crop_width]. All cropped image patches are resized to this size. Both crop_height and crop_width need to be positive.
crop_size
RoI pooled output, 4-D tensor of shape (num_rois, C, crop_height, crop_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].
Constrain types to float tensors.
Constrain types to int tensors.
The first normalization dimension: normalization will be performed along dimensions axis : rank(inputs).
type used for stash mean/inv_std_var
Input data tensor from the previous layer.
Scale tensor.
Bias tensor.
Output data tensor.
Saved inverse standard deviation used during training to speed up gradient computation.
Constrain input types and output Y type to float tensors.
Type of Mean and InvStdDev tensors.
Constrain input and output types (except mean and inv_std_var) to float tensors.
Constrain mean and inv_std_var to be float tensors.
The input data as Tensor.
The output.
The normal input data.
The bias input data that is a 1D tensor.
Inverse
Input tensor. Every matrix in the batch must be invertible.
Output tensor of the same type and shape as the input tensor.
TorchEmbedding
The embedding matrix of size N x M. 'N' is equal to the maximum possible index + 1, and 'M' is equal to the embedding size
Long tensor containing the indices to extract from embedding matrix.
A 0-D scalar tensor. If specified, the entries at `padding_idx` do not contribute to the gradient; therefore, the embedding vector at `padding_idx` is not updated during training, i.e. it remains as a fixed pad.
padding_idx
A 0-D bool tensor. If given, this will scale gradients by the inverse of frequency of the indices (words) in the mini-batch. Default  is ``False``
scale_grad_by_freq
Output tensor of the same type as the input tensor. Shape of the output is * x M, where '*' is the shape of input indices, and 'M' is the embedding size.
Constrain input and output types to all numeric tensors.
Trilu
Boolean. Indicates whether upper or lower part of matrix is retained. Default is true.
upper
Input tensor of rank 2 or higher.
A 0-D tensor containing a single value corresponding to the number diagonals above or the main diagonal to exclude or include.Default value is 0 if it's not specified.
Constrain input and output types to all numeric tensors and bool tensors.
apply softmax to elements for dimensions softmax_axis or higher
broadcast bias across input for dimensions broadcast_axis to softmax_axis-1
The bias (or mask) as Tensor.
(Optional) Seed to the random generator, if not specified we will auto generate one.
The bias input, a vector with the same shape as last dim of data
The residual input, must have the same shape as data
residual
The ratio of random dropout, with value in [0, 1). If this input was not set, or if it was set to 0, the output would be a simple copy of the input. If it's non-zero, output will be a random dropout of input, which is typically the case during training.
ratio
If set to true then it indicates dropout is being used for training. It is an optional value hence unless specified explicitly, it is false. If it is false, ratio is ignored and the operation mimics inference mode where nothing will be dropped from the input data and if mask is requested as output it will contain all ones.
training_mode
The output mask of dropout.
Constrain input 'ratio' types to float tensors.
Constrain output 'mask' types to boolean tensors.
IsAllFinite
If true, check only for Inf, -Inf.
If true, check only for NaN.
Constrain the output to a boolean tensor.
Input tensors to check.
The output scalar. Its value is true if all input tensors are finite. Otherwise, the output value would be false.
Optional
The input element.
Type of the element in the optional output
The optional output enclosing the input element.
Constrains input type to all tensor and sequence types.
Constrains output type to all optional tensor or optional sequence types.
OptionalHasElement
The optional input.
A scalar boolean tensor. If true, it indicates that optional-type input contains an element. Otherwise, it is empty.
Constrains input type to optional tensor and optional sequence types.
Constrains output to a boolean tensor.
OptionalGetElement
Output element in the optional input.
Constrain output type to all tensor or sequence types.
GridSample
Three interpolation modes: bilinear (default), nearest and bicubic.
zeros
Support padding modes for outside grid values: `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound grid locations, border: use border values for out-of-bound grid locations, reflection: use values at locations reflected by the border for out-of-bound grid locations.
padding_mode
If align_corners=1, the extrema (-1 and 1) are considered as referring to the center points of the input's corner pixels. If align_corners=0, they are instead considered as referring to the corner points of the input's corner pixels, making the sampling more resolution agnostic.
4-D tensor of shape (N, C, H, W), where N is the batch size, C is the numbers of channels, H and W are the height and width of the input data.
Input offset, 4-D tensor of shape (N, H_out, W_out, 2), where H_out and W_out are the height and width of grid and output, Grid specifies the sampling pixel locations normalized by the input spatial dimensions. Therefore, it should have most values in the range of [-1, 1]. If grid has values outside the range of [-1, 1], the corresponding outputs will be handled as defined by padding_mode.
4-D tensor of shape (N, C, H_out, W_out).
Constrain input types to all tensor types.
Constrain output types to float tensors.
std::count_if(subgraph_node.InputEdgesBegin(), subgraph_node.InputEdgesEnd(), [input_slot_index](const Node::EdgeEnd& entry) { return entry.GetDstArgIndex() == input_slot_index; }) == 0
onnxruntime::graph_utils::UpdateImplicitInputNameInSubgraph
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph_utils.cc
 in one of the subgraphs.
 cannot be safely updated to 
 Implicit input name 
onnxruntime::graph_utils::CanUpdateImplicitInputNameInSubgraphs
Node must only have one used output
std::all_of(output_edges.cbegin(), output_edges.cend(), [&src_idx](const GraphEdge& edge) { return edge.src_arg_index == src_idx; })
onnxruntime::graph_utils::RemoveNodeWithSingleNodeInSingleUsedOutput
for node: 
Attempting to get index by a name which does not exist:
itr != node_args.end()
onnxruntime::graph_utils::GetIndexFromName
Should be unreachable if CanRemoveNodeAndMergeEdges is in sync with the logic here.
onnxruntime::graph_utils::RemoveNode
Initializer with same name exists. Name:
!graph.GetInitializedTensor(new_initializer.name(), existing)
onnxruntime::graph_utils::AddInitializer
 ImplicitInputs:
 ExplicitInputs:
. Index:
Invalid input index for node 
onnxruntime::graph_utils::ReplaceNodeInput
Can only add a new input at the end of the current ones.
num_explicit_inputs == static_cast<size_t>(target_input_idx)
onnxruntime::graph_utils::AddNodeInput
Failed since multiple edges matched:
onnxruntime::graph_utils::FindPath
Attempting to get an input that does not exist.
index >= 0 && static_cast<size_t>(index) < inputs.size()
onnxruntime::graph_utils::GetNodeInputName
Attempting to get an output that does not exist.
index >= 0 && static_cast<size_t>(index) < outputs.size()
onnxruntime::graph_utils::GetNodeOutputName
TENSOR
UNDEFINED
FLOAT
STRING
GRAPH
FLOATS
STRINGS
TENSORS
GRAPHS
SPARSE_TENSOR
SPARSE_TENSORS
onnxruntime::experimental::utils::SaveInitializerOrtFormat
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph_flatbuffers_utils.cc
onnxruntime::experimental::utils::SaveSparseInitializerOrtFormat
onnxruntime::experimental::utils::SaveAttributeOrtFormat
Graph attribute value was null. Invalid ORT format model.
SaveAttributeOrtFormat: Unsupported attribute type: 
Missing dimensions for initializer. Invalid ORT format model.
onnxruntime::experimental::utils::LoadInitializerOrtFormat
Missing string data for initializer. Invalid ORT format model.
Missing raw data for initializer. Invalid ORT format model.
Missing values for sparse initializer. Invalid ORT format model.
onnxruntime::experimental::utils::LoadSparseInitializerOrtFormat
Missing name for SparseTensor initializer. Invalid ORT format model.
Invalid ORT format model.
Missing indicies for sparse initializer: 
Missing dims for sparse initializer: 
Null string attribute. Invalid ORT format model.
onnxruntime::experimental::utils::LoadAttributeOrtFormat
Null tensor attribute. Invalid ORT format model.
Null graph attribute. Invalid ORT format model.
Empty graph proto from deserialization of ORT format model
Null floats attribute. Invalid ORT format model.
Null ints attribute. Invalid ORT format model.
Null strings attribute. Invalid ORT format model.
Null string in strings attribute. Invalid ORT format model.
Null tensors attribute. Invalid ORT format model.
Null tensor in tensors attribute. Invalid ORT format model.
Not supported
onnxruntime::ViewerFunctionImpl::Body
D:\a\_work\1\s\onnxruntime\onnxruntime\core/graph/function_impl.h
onnxruntime::ViewerFunctionImpl::MutableBody
 is out of bounds.
GraphProto attribute inferencing is not enabled in this InferenceContextImpl instance.
 does not contain a graph.
 optype 
 referenced by function body node 
. No opset import for domain
Cannot infer type and shape for function
 in function opset imports.
No opset registered for domain 
domain_version != -1
onnxruntime::IOTypeConstraintHelper
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\function.cc
'. Error message 
Function body initialization failed for Function '
onnxruntime::InitNestedModelLocalFunction
A node with a function body within a subgraph within another function body is currently not supported in ORT
onnxruntime::UpdateSubgraphsWithinFunctionBody
input_arg->Type() != nullptr
onnxruntime::CreateSchema
fused_function_subgraph
onnxruntime::FunctionImpl::FunctionImpl
_dummy
Resolve subgraph failed:
's number of inputs is different from function body graph's number of input.
Node 
node_in_parent_graph->InputDefs().size() == function_body_graph.GetInputsIncludingInitializers().size()
's number of outputs is different from function body graph's number of outputs.
node_in_parent_graph->OutputDefs().size() == function_body_graph.GetOutputs().size()
tensor rank too small
invalid scales dimension
invalid scales value
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\nchwc_schema_defs.cc
Input tensor must have at least 2 dimensions
Output tensor must have at least 2 dimensions
inputs are expected to have tensor type.
input and zero_point pair is expected to have be same type.
weight and zero_point pair is expected to have same type.
Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output spatial size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding.
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\nhwc_schema_defs.cc
x_scale
x_zero_point
w_scale
w_zero_point
y_scale
y_zero_point
Input data tensor from the previous operator; According to channels_last, dimensions for image case are (N x C x H x W), or (N x H x W x C) where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), or (N x D1 X D2 ... Dn x C) where N is the batch size.
Scale of quantized input 'X'. It must be a scalar.
Zero point tensor for input 'X'. It must be a scalar.
Scale of quantized output 'Y'. It must be a scalar.
Zero point tensor for output 'Y'. It must be a scalar.
Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. with the N and C value keep it value, while the otherdimensions are all 1.
Constrain input and output types to singed/unsigned int8 tensors.
Whether include pad pixels when calculating values for the edges. Default is 0, doesn't count include pad.
The size of the kernel along each axis.
Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.
Whether to use ceil or floor (default) to compute the output shape.
Works on NHWC layout or not? Default not.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input scale. It's a scalar, which means a per-tensor/layer quantization.
Input zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Output scale. It's a scalar, which means a per-tensor/layer quantization.
Output zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Output data tensor from average or max pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Floor value of the dimension is used
Constrain input and output types to 8 bit tensors.
Input data type does not match the expected data type
Input data type does not match the expected data type. Current data type is 
Scale and Zero-point must be a scalar
Scale and Zero-point must be of rank 1
Scale and Zero-point must be of rank 1 and the number of elements should be equal to the number of rows of the corresponding input.
Performs element-wise binary {name} on 8 bit data types (with Numpy-style broadcasting support).
{additionalDocumentation}
{name}
{additionalDocumentation}
First operand.
Input A's scale. It's a scalar, which means a per-tensor/layer quantization.
A_scale
Input A zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
A_zero_point
Second operand.
Input B's scale. It's a scalar, which means a per-tensor/layer quantization.
B_scale
Input B zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
B_zero_point
C_scale
C_zero_point
Result, has same element type as two inputs
Constrain input and output types to 8 bit signed and unsigned tensors.
axis must be in [-rank, rank-1]. input rank was 
Required attribute axis is missing
axis must be in [-rank, rank)
All inputs to Concat must have same rank
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\quantization_defs.cc
The axis along which same quantization parameters are applied. It's optional.If it's not specified, it means per-tensor quantization and input 'x_scale' and 'x_zero_point' must be scalars.If it's specified, it means per 'axis' quantization and input 'x_scale' and 'x_zero_point' must be 1-D tensors.
N-D full precision Input tensor to be quantized.
Scale for doing quantization to get 'y'. It could be a scalar or a 1-D tensor,which means a per-tensor or per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Zero point for doing quantization to get 'y'. It could be a scalar or a 1-D tensor, which means a per-tensoror per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
N-D quantized output tensor. It has same shape as input 'x'.
Constrain 'x', 'y_scale' to float tensors.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensors.
N-D quantized Input tensor to be de-quantized.
Scale for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Zero point for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
N-D full precision output tensor. It has same shape as input 'x'.
Constrain 'x' and 'x_zero_point' to 8-bit integer tensors.
Constrain 'y', 'x_scale' to float tensors.
ReduceSumInteger
An input tensor.
Reduced output tensor.
reduced
Constrain input type to 8-bit integer tensor.
Constrain output data type to 32-bit integer tensor.T2 must be tensor(uint32) when T1 is tensor(uint8),or must be tensor(int32) when T1 is tensor(int8).
A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor.
Keep the reduced dimension or not, default 1 mean keep reduced dimension.
MulInteger
Constrain output to 32 bit tensor
Constrain input types to 8 bit signed and unsigned tensors.
Constrain output types to 32 bit tensors.
Scale of quantized input 'B'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.
b_scale
Zero point tensor for input 'B'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.
b_zero_point
1D input tensor, whose dimension is same as B's last dimension
Constrain input A, b_scale and output Y data type as float tensor.
Constrain input B data type to 8-bit integer tensor.
Scale of quantized input 'A'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'A'.
a_scale
Zero point tensor for input 'A'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'A'.
a_zero_point
Constrain input A data type to 8-bit integer tensor.
Constrain input a_scale, b_scale and output Y data type as float tensor.
C = (A_scale * (A - A_zero_point) + B_scale * (B - B_zero_point))/C_scale + C_zero_point
addition
C = ((A - A_zero_point) * (B - B_zero_point)) * (A_scale * B_scale)/C_scale + C_zero_point
multiplication
QLinearReduceMean
data_scale
data_zero_point
reduced_scale
reduced_zero_point
Coefficient of leakage.
Input X's scale. It's a scalar, which means a per-tensor/layer quantization.
X_scale
Input X's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
X_zero_point
Output Y's scale. It's a scalar, which means a per-tensor/layer quantization.
Y_scale
Output Y's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Y_zero_point
Specify if the RNN is forward, reverse, or bidirectional. Must be one of forward (default), reverse, or bidirectional.
Number of neurons in the hidden layer
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.For example with LeakyRelu, the default alpha is 0.01.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.
Cell clip threshold. Clipping bounds the elements of a tensor in the range of [-threshold, +threshold] and is applied to the input of activations. No clip if not specified.
A list of 3 (or 6 if bidirectional) activation functions for input, output, forget, cell, and hidden. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
Couple the input and forget gates if 1.
The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.
The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, input_size, 4*hidden_size]`.
The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, hidden_size, 4*hidden_size]`.
The bias tensor for input gate. Concatenation of `[Wb[iofc], Rb[iofc]]`, and `[WBb[iofc], RBb[iofc]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 8*hidden_size]`. Optional: If not specified - assumed to be 0.
Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]`.
sequence_lens
Optional initial value of the hidden. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
initial_h
Optional initial value of the cell. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
initial_c
The weight tensor for peepholes. Concatenation of `P[iof]` and `PB[iof]` (if bidirectional) along dimension 0. It has shape `[num_directions, 3*hidde_size]`. Optional: If not specified - assumed to be 0.
W's scale. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
W's zero point. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
R's scale. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
R's zero point. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. 
The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`.
The last output value of the cell. It has shape `[num_directions, batch_size, hidden_size]`.
Constrain seq_lens to integer tensor.
Constrain weights types to 8 bit tensors.
Which axis to concat on
Y's scale.
Y's zero point.
List of tensors/scale/zero_point for concatenation
inputs
Concatenated tensor
Constrain scale types to any float tensor type.
Sequence of (Tensor, Scale, ZeroPoint) tuples. The type is sequence of (T8, TF, T8).
QGemm
Scale of quantized input 'A'. It is a scalar,which means a per-tensor quantization.
Zero point tensor for input 'A'. It is a scalar.
Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). Its type is int32_t and must be quantized with zero_point = 0 and scale = alpha / beta * a_scale * b_scale.
Scale of output 'Y'. It is a scalar, which means a per-tensor quantization. It is optional. The output is full precision(float32) if it is not provided. Or the output is quantized.
Zero point tensor for output 'Y'. It is a scalar, which means a per-tensor quantization. It is optional. The output is full precision(float32) if it is not provided. Or the output is quantized.
Constrain scale types to float tensors.
Constrain input A and its zero point types to 8 bit tensors.
Constrain input B and its zero point types to 8 bit tensors.
Constrain input C to 32 bit integer tensors.
Constrain output zero point types to 8 bit tensors.
Constrain output type to float32 or 8 bit tensors.
Couple the input and forget gates if 1, default 0.
Number of neurons in the hidden layer.
Constrain seq_lens to integral tensors.
The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`
The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, 4*hidden_size, input_size]`.
The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 4*hidden_size, hidden_size]`.
Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]` 
The weight tensor of the query layer in the attention mechanism. Should be of shape `[num_directions, am_query_depth(hidden_size of lstm), am_attn_size]` 
The weight tensor of the memory layer in the attention mechanism. Should be of shape `[num_directions, memory_depth, am_attn_size]` 
The attention_v tensor in the attention mechanism. Should be of shape `[num_directions, am_attn_size]` 
The sequence of the memory (input) for attention mechanism. Should be of `[batch_size, max_memory_step, memory_depth]` 
The sequence length of the input memory for the attention mechanism. Should be of `[batch_size]` 
memory_seq_lens
The weights of attention layer in the attention wrapper. If exists, should be of shape `[num_directions, memory_depth+hidden_size, aw_attn_size]. Please note that attention mechanism context depth is also memory_depth in the attention mechanism.` 
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`
The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`. 
Can not get shape initializer data!
Unsupported type:
Constrain input and output types.
Tensor(scalar, or dims=[1]). First entry in the range.
Tensor(scalar, or dims=[1]). Upper limit of sequence, exclusive.
limit
Tensor(scalar, or dims=[1]). Number that increments start. Defaults to 1.
delta
1-D Tensor of the range.
Unsupported non-raw-data data type!
AQ5@.
<2?~>
=4?~?
++Q5@.{
=2?~>4?~?
++Q5@.Q5@.Q5@.Q5@.{
=2?~>2?~>2?~>2?~>4?~?4?~?4?~?4?~?
\3JCy7
?33{@
l?33{@33{@33{@33{@
SUCCESS
NO_SUCHFILE
NO_MODEL
ENGINE_ERROR
RUNTIME_EXCEPTION
INVALID_PROTOBUF
MODEL_LOADED
NOT_IMPLEMENTED
INVALID_GRAPH
EP_FAIL
GENERAL ERROR
code != static_cast<int>(common::OK)
onnxruntime::common::Status::Status
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\status.cc
SystemError
[ONNXRuntimeError]
Exception
ReturnHr
LogHr
FailFast
%hs(%u)\%hs!%p: 
%hs!%p: 
(caller: %p) 
%hs(%d) tid(%x) %08X %ws
Msg:[%ws] 
CallContext:[%hs] 
[%hs(%hs)]
[%hs]
std::exception: %hs
generic
system
unknown error
D:\a\_work\1\s\onnxruntime\onnxruntime\core\platform\windows\env.cc
onnxruntime
Fatal error: 0 count processors from GetSystemInfo
onnxruntime::`anonymous-namespace'::WindowsEnv::GetNumCpuCores
Fatal error: 0 count processors from GetLogicalProcessorInformation
 fail, errcode = 
open file 
GetFileSizeEx 
Invalid fd was supplied: 
Received negative size from stat call
file_path == nullptr
onnxruntime::`anonymous-namespace'::WindowsEnv::ReadFileIntoBuffer
offset < 0
length > buffer.size()
SetFilePointerEx 
ReadFile 
 fail: unexpected end
MapFileIntoMemory is not implemented on Windows.
, error code: 
DeleteFile() failed - path: 
onnxruntime::`anonymous-namespace'::WindowsEnv::DeleteFolder
RemoveDirectory() failed - path: 
GetFinalPathNameByHandle() failed: 
onnxruntime::`anonymous-namespace'::WindowsEnv::GetCanonicalPath
" when trying to load "
LoadLibrary failed with error 
FreeLibrary failed with error 
Failed to find symbol in library, error code: 
onnxruntime::`anonymous-namespace'::WindowsEnv::FormatLibraryFileName
onnxruntime::LoopDir
D:\a\_work\1\s\onnxruntime\onnxruntime\core/platform/path_lib.h
Failed to parse path root: 
onnxruntime::`anonymous-namespace'::ParsePathRoot
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\path.cc
onnxruntime::Path::Parse
onnxruntime
System
ISink must be provided.
onnxruntime::logging::LoggingManager::LoggingManager
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\logging\logging.cc
default_logger_id must be provided if instance_type is InstanceType::Default
Only one instance of LoggingManager created with InstanceType::Default can exist at any point in time.
Default logger already set. 
onnxruntime::logging::LoggingManager::CreateDefaultLogger
N@length overflow
onnxruntime::ToMBString
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\helper.cc
onnxruntime::ToWideString
Session
enabled_
onnxruntime::profiling::Profiler::StartTime
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\profiler.cc
session_logger != nullptr
onnxruntime::profiling::Profiler::Initialize
Maximum number of events reached, could not record profile event.
onnxruntime::profiling::Profiler::EndTimeAndRecordEvent
Writing profiler data to file 
onnxruntime::profiling::Profiler::EndProfiling
{"cat" : "
"pid" :
"tid" :
"dur" :
"ts" :
"ph" : "X",
"name" :"
"args" : {
" : "
unnamed_thread_pool
Profiler not started yet
onnxruntime::concurrency::ThreadPoolProfiler::Stop
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\threadpool.cc
}, "sub_threads": {
"thread_pool_name": "
{"main_thread": {
LogStart must pair with LogEnd
!points_.empty()
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::LogEnd
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::LogEndAndStart
points_.empty()
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::Reset
", "block_size": [
"thread_id": "
], "core": 
Distribution
DistributionEnqueue
WaitRevoke
UnknownEvent
"core": 
"num_run": 
Nested parallelism not supported
!current_parallel_section
onnxruntime::concurrency::ThreadPool::ParallelSection::ParallelSection
n >= 0
onnxruntime::concurrency::ThreadPool::ParallelFor
More work items than threads
n <= num_threads_+1
onnxruntime::concurrency::ThreadPoolTempl<class onnxruntime::Env>::RunInParallel
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/platform/EigenNonBlockingThreadPool.h
onnxruntime::concurrency::ThreadPoolTempl<class onnxruntime::Env>::RunInParallelSection
bad conversion
unexpected failure
illegal input path:
VIWEF
 is not a valid date
 is not a valid year
 is not a valid day
tensor_type
sequence_type
map_type
onnxruntime::experimental::utils::SaveSequenceTypeOrtFormat
D:\a\_work\1\s\onnxruntime\onnxruntime\core\flatbuffers\flatbuffers_utils.cc
onnxruntime::experimental::utils::SaveMapTypeOrtFormat
onnxruntime::experimental::utils::SaveTensorTypeAndShapeOrtFormat
onnxruntime::experimental::utils::SaveTypeInfoOrtFormat
] for now
We do not support type [
onnxruntime::experimental::utils::SaveValueInfoOrtFormat
 is missing type info.
SaveValueInfoOrtFormat: value_info_proto for 
dim_param value with no name. Invalid ORT format model.
onnxruntime::experimental::utils::LoadTensorDimensionOrtFormat
Null entry in dimensions. Invalid ORT format model.
onnxruntime::experimental::utils::LoadTensorShapeOrtFormat
onnxruntime::experimental::utils::LoadTensorTypeAndShapeOrtFormat
Null value type info in fbs::SequenceType. Invalid ORT format model.
onnxruntime::experimental::utils::LoadSequenceTypeOrtFormat
Null value type info in fbs::MapType. Invalid ORT format model.
onnxruntime::experimental::utils::LoadMapTypeOrtFormat
Null tensor type info. Invalid ORT format model.
onnxruntime::experimental::utils::LoadTypeInfoOrtFormat
Null sequence type info. Invalid ORT format model.
Null map type info. Invalid ORT format model.
 is not supported currently
Type:
Null type info for 
onnxruntime::experimental::utils::LoadValueInfoOrtFormat
Model must have opset imports. Invalid ORT format model.
onnxruntime::experimental::utils::LoadOpsetImportOrtFormat
opset id is null. Invalid ORT format model.
opset import domain is null. Invalid ORT format model.
, has unsupported type: 
 typestr: 
 has inconsistent type 
 has unsupported type 
' has been deprecated since version 
Operator '
, max=
 not in range [min=
) has input size 
 not in allowed input sizes.
) has output size 
 not in allowed output sizes.
has output size 
) in op definition.
) than declared (
) has more inputs (
 is marked single but has an empty string in the graph
)'s input 
) has more outputs (
)'s output 
' appeared multiple times.
Attribute '
 for operator 
Unrecognized attribute: 
Mismatched attribute type in '
' is expected to have field 't'
' is expected to have field 'sparse_tensor'
' is expected to have field 'g'
' is expected to have field 'type_proto'
' is expected to have field 'floats'
' is expected to have field 'ints'
' is expected to have field 'strings'
' is expected to have field 'tensors'
' is expected to have field 'graphs'
' is expected to have field 'type_protos'
 has unknown expected type
' is missing.
Required attribute '
Attribute specification type mismatch.
Duplicate type constraint name
(inputs_.size() - 1) == i
: failed validating the check: 
ONNX Schema 
(outputs_.size() - 1) == i
!(it.GetName().empty())
Invalid data type 
tensor(
optional(
sparse_tensor(
Unsuported type proto value case.
Invalid tensor data type 
optional
opaque
DataTypeUtils::FromDataTypeString - Received invalid data type string 
complex64
complex128
Pow takes input data (Tensor<T>) and exponent Tensor, and
produces one output data (Tensor<T>) where the function `f(x) = x^exponent`,
is applied to the data tensor elementwise.
Type of reduction to apply to loss: none, sum, mean(default). 'none': no reduction will be applied, 'sum': the output will be summed. 'mean': the sum of the output will be divided by the number of elements in the output.
If necessary the right-hand-side argument will be broadcasted to match the
shape of left-hand-side argument. When broadcasting is specified, the second
tensor can either be of element size 1 (including a scalar tensor and any
tensor with rank equal to or smaller than the first tensor), or having its
shape as a contiguous subset of the first tensor's shape. The starting of the
mutually equal shape is specified by the argument "axis", and if it is not set,
suffix matching is assumed. 1-dim expansion doesn't work yet.
For example, the following tensor shapes are supported (with broadcast=1):
  shape(A) = (2, 3, 4, 5), shape(B) = (,), i.e. B is a scalar tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (1, 1), i.e. B is an 1-element tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (5,)
  shape(A) = (2, 3, 4, 5), shape(B) = (4, 5)
  shape(A) = (2, 3, 4, 5), shape(B) = (3, 4), with axis=1
  shape(A) = (2, 3, 4, 5), shape(B) = (2), with axis=0
Attribute `broadcast=1` needs to be passed to enable broadcasting.
This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](Broadcasting.md).
Constrain input and output types to high-precision numeric tensors.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\math\old.cc
subtraction
division
]. Its actual value is: 
'axis' must be in [
Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
The input tensor that's coerced into a 2D matrix of size (NxD) as described above.
The output values with the same shape as input tensor (the original size without coercion).
normalized exponential
softmax
log of softmax
logsoftmax
1 for the first maximum value, and 0 for all others
hardmax
Whether the operator should behave like fmod (default=0 meaning it will do integer mods); Set this to 1 to force fmod treatment
Dividend tensor
Divisor tensor
Remainder tensor
Constrain input and output types to signed numeric tensors.
The exponential of the input tensor computed element-wise
The natural log of the input tensor computed element-wise
The hyperbolic tangent values of the input tensor computed element-wise
First operand, base of the exponent.
Second operand, power of the exponent.
Constrain input X and output types to float/int tensors.
Constrain input Y types to float/int tensors.
Output tensor.
List of tensors for 
data_0
Constrain input and output types to numeric tensors.
Input tensor whose elements to be clipped
Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape).
Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape).
Output tensor with clipped input elements
Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N).
'shape' input must be 1D tensor of type INT64
A 1-D tensor indicates the shape you want to expand to, following the broadcast rule
Constrain input and output types to all tensors.
The sign of the input tensor computed element-wise. It has the same shape and type of the input.
The error function of the input tensor computed element-wise. It has the same shape and type of the input.
If set to 1 will return exclusive sum in which the top element is not included. In other terms, if set to 1, the j-th output element would be the sum of the first (j-1) elements. Otherwise, it would be the sum of the first j elements.
If set to 1 will perform the sums in reverse direction.
An input tensor that is to be processed.
A 0-D tensor. Must be in the range [-rank(x), rank(x)-1]. Negative value means counting dimensions from the back.
Output tensor of the same type as 'x' with cumulative sums of the x's elements
axis tensor can be int32 or int64 only
reduction
const_zero
const_one
target
expanded_target
ignore_index
GatherElements
input_gather_element
loss_NCdd
loss_N1dd
loss_Ndd
weight_gather
loss_unweighted
loss_sum
weight_gather_sum
const_ignore_index
const_zero_target_typed
expanded_target_int64
transform_targets
const_zero_float
const_zero_casted
input_gather_element_transform
squeeze_mask
const_one_float
const_one_casted
weight_gather_temp
weight_gather_temp_1
Target rank must be 1 less than the input rank.
Input and target dimension value mismatch.
Weight rank must be 1.
Input tensor of shape (N, C) or (N, C, d1, d2, ..., dk).
Target tensor of shape (N) or (N, d1, d2, ..., dk). Target element value shall be in range of [0, C). If ignore_index is specified, it may have a value outside [0, C) and the target values should either be in the range [0, C) or have the value ignore_index.
Optional rescaling weight tensor. If given, it has to be a tensor of size C. Otherwise, it is treated as if having all ones.
The negative log likelihood loss
Type of reduction to apply to loss: none, sum, mean (default). 'none': the output is the loss for each sample. 'sum': the output will be summed. 'mean': the sum of the output will be divided by the sum of applied weights.
Specifies a target value that is ignored and does not contribute to the input gradient. It's an optional value.
Constrain input, weight, and output types to floating-point tensors.
Constrain target to integer types
NegativeLogLikelihoodLoss
Shape3D
X_NCD
X_NDC
X_LogSM
X_LogSM_NCD
X_shape
X_Log
log_prob
labels
weights
The predicted outputs with shape [batch_size, class_size], or [batch_size, class_size, D1, D2 , ..., Dk], where K is the number of dimensions.
The ground truth output tensor, with shape [batch_size], or [batch_size, D1, D2, ..., Dk], where K is the number of dimensions. Labels element value shall be in range of [0, C). If ignore_index is specified, it may have a value outside [0, C) and the label values should either be in the range [0, C) or have the value ignore_index.
A manual rescaling weight given to each class. If given, it has to be a 1D Tensor assigning weight to each of the classes. Otherwise, it is treated as if having all ones.
Weighted loss float Tensor. If reduction is 'none', this has the shape of [batch_size], or [batch_size, D1, D2, ..., Dk] in case of K-dimensional loss. Otherwise, it is a scalar.
Log probability tensor. If the output of softmax is prob, its value is log(prob).
SoftmaxCrossEntropyLoss
Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size
Pass 1 to enable broadcasting
broadcast
legacy optimization attribute.
consumed_inputs
If set, defines the broadcast dimensions. See doc for details.
First operand, should share the type with the second operand.
Second operand. With broadcasting can be of smaller size than A. If broadcasting is disabled it should be of the same size.
Result, has same dimensions and type as A
Input tensor of any shape, base of the exponent.
Input tensor of any shape broadcastable to X shape, the exponent component.
Output tensor (same size as X)
Coefficient of leakage default to 0.01.
Coefficient of SELU default to 1.6732.
Coefficient of SELU default to 1.0507.
Coefficient of ELU default to 1.0.
1-D input tensor
Slope tensor. If `Slope` is of size 1, the value is sharedacross different channels
slope
Slope tensor. The shape of slope can be smaller then first input X; if so, its shape must be unidirectional broadcastable to X
Value of alpha default to 0.2
Value of beta default to 0.5
List of tensors for Max.
Output tensor. Same dimension as inputs.
List of tensors for Min
List of tensors for Sum.
List of tensors for Mean.
Minimum value, under which element is replaced by min
Maximum value, above which element is replaced by max
Input tensor A
Input tensor B
Input tensor C, can be inplace.
Whether C should be broadcasted
Scalar multiplier for the product of input tensors A * B, the default value is 1.0.
Scalar multiplier for input tensor C, the default value is 1.0.
Input tensor C
Invalid value for attribute axis
Invalid value for attribute k
Tensor of shape [a_1, a_2, ..., a_n, r]
Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing top K values from the input tensor
Values
Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing the corresponding input tensor indices for the top K values.
Indices
Constrain index tensor to int64
Number of top elements to retrieve
Dimension on which to do the sort.
K input must be a one-dimensional tensor of size 1.
K input must be of type int64.
Axis has less than the requested k elements.
A 1-D tensor containing a single positive value corresponding to the number of top elements to retrieve
First input operand for the logical operator.
Second input operand for the logical operator.
Result tensor.
greater
Constrains input types to all numeric tensors.
Constrains output to boolean tensor.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\logical\old.cc
equal
Enable broadcasting
If set, defines the broadcast dimensions.
Left input tensor for the logical operator.
Right input tensor for the logical operator.
Constrains input to boolean tensor.
Constrains input to float tensors.
Constrains input to integral tensors.
A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor. Accepted range is [-r, r-1] where r = rank(data).
Constrain input and output types to high-precision and 8 bit numeric tensors.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\reduction\old.cc
sum square
product
log sum
log sum exponent
L1 norm
L2 norm
'axis' must be in [-rank(indices), rank(indices)-1]
The axis in which to compute the arg indices. Accepted range is [-r, r-1] where r = rank(data).
Whether to select the last index or the first index if the {name} appears in multiple indices, default is False (first index).
Reduced output tensor with integer data type.
The axis in which to compute the arg indices.
Computes the indices of the {name} elements of the input tensor's element along the
provided axis. The resulting tensor has the same rank as the input if keepdims equal 1.
If keepdims equal 0, then the resulting tensor have the reduced dimension pruned.
The type of the output tensor is integer.
Padding for the beginning and ending along each axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding. DEPRECATION NOTE: auto_pad is only intended to support legacy uses, and for framework authors, one is explicitly encouraged to use explicit padding specified in the pads attribute.
Carries out batch normalization as described in the paper
https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
there are multiple cases for the number of outputs, which we list below:
Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
Output case #2: Y (test mode)
For previous (depreciated) non-spatial cases, implementors are suggested
to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.
Carries out batch normalization as described in the paper
https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
There are five required inputs 'X', 'scale', 'B', 'input_mean' and
'input_var'.
Note that 'input_mean' and 'input_var' are expected to be the estimated
statistics in inference mode (training_mode=False, default),
and the running statistics in training mode (training_mode=True).
There are multiple cases for the number of outputs, which we list below:
Output case #1: Y, running_mean, running_var (training_mode=True)
Output case #2: Y (training_mode=False)
When training_mode=False, extra outputs are invalid.
The outputs are updated as follows when training_mode=True:
running_mean = input_mean * momentum + current_mean * (1 - momentum)
running_var = input_var * momentum + current_var * (1 - momentum)
Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B
where:
current_mean = ReduceMean(X, axis=all_except_channel_index)
current_var =  ReduceVar(X, axis=all_except_channel_index)
Notice that ReduceVar refers to the population variance, and it equals to
sum(sqrd(x_i - x_avg)) / N
where N is the population size (this formula does not use sample size N - 1).
When training_mode=False:
Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B
For previous (depreciated) non-spatial cases, implementors are suggested
to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.
This operator has **optional** inputs/outputs. See [the doc](IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.
Ratio of Dropout must be a scalar.
training_mode of Dropout must be a scalar.
The ratio of random dropout, with value in [0, 1). If this input was not set, or if it was set to 0, the output would be a simple copy of the input. If it's non-zero, output will be a random dropout of the scaled input, which is typically the case during training. It is an optional value, if not specified it will default to 0.5.
The output mask.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\nn\old.cc
) for attribute 'axis'
Invalid value(
A tensor of rank >= axis.
A 2D tensor with the contents of the input tensor, with input dimensions up to axis flattened to the outer dimension of the output and remaining input dimensions flattened into the inner dimension of the output.
Constrain input and output to all tensor types.
Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [-r, r], where r is the rank of the input tensor. Negative value means counting dimensions from the back. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
The number of channels to sum over
Scaling parameter.
The exponent.
Output tensor, which has the shape and type as input tensor
Constrain input and output  types to float tensors.
A list of integers, along which to reduce. The default is to caculate along axes [0,2,3] for calculating mean and variance along each channel. Two variables with the same C-coordinate are associated with the same mean and variance.
Exponent
EX_squared
X_squared
E_Xsquared
Variance
X_variance
Processed_STD
Input tensor must have atleast 2 dimensions
Attribute dilations has incorrect size
Attribute strides has incorrect size
Attribute kernel_shape has incorrect size
Attribute kernel_shape must be specified
Attribute pads has incorrect size
Second input tensor has wrong dimension
Stride along each spatial axis.
The output of each pooling window is divided by the number of elements exclude pad.
average
The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).
The output of each pooling window is maximum number of elements exclude pad.
The storage order of the tensor. 0 is row major, and 1 is column major.
Indices tensor from max pooling across the input tensor. The dimensions of indices are the same as output tensor. The values in indices of are the indices of the selected values during pooling. The indices are computed as flatten 1-D tensor, and the indices do not consider padding. So the values in indices are in [0, N x C x D1 x ... x Dn).
Dilation value along each spatial axis of filter.
Dilation value along each spatial axis of filter. If not present, the dilation defaults to 1 along each spatial axis.
MaxUnpool op must have either two or three inputs.
Input tensor X must have atleast 2 dimensions.
Attribute pads has incorrect size.
Attribute strides has incorrect size.
Attribute kernel_shape has incorrect size.
Attribute kernel_shape must be specified.
'output_shape' must be rank 1 tensor.
'output_shape' must have same number of elements as the shape of input tensor X.
Input data tensor that has to be unpooled. This tensor is typically the first output of the MaxPool op.Dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non-image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input data tensor containing the indices corresponding to elements in the first input tensor X.This tensor is typically the second output of the MaxPool op.Dimensions must be the same as input tensor X. The indices are linear, i.e. computed considering the tensor as flattened 1-D tensor, assuming row-major storage. Also, the linear indices should not consider padding. So the values in indices are in the range [0, N x C x D1 x ... x Dn).
The shape of the output can be explicitly set which will cause pads values to be auto generated. If 'output_shape' is specified, 'pads' values are ignored.
Output data tensor that contains the result of the unpooling.
MaxUnpool
Stride along each axis.
p value of the Lp norm used to pool over the input data, default is 2.0.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimension are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
Output data tensor from Lp pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes.
LpPool
p value of the Lp norm used to pool over the input data.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based indices for the shape array). Or in other words FILTER_IN_CHANNEL should be equal to DATA_CHANNEL. 
Optional 1D bias to be added to the convolution, has size of M.
Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths.
The shape of the convolution kernel. If not present, should be inferred from input W.
dilation value along each spatial axis of the filter.
number of groups input channels and output channels are divided into.
a filter
Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn)
The weight tensor that will be used in the convolutions; has size (C x M/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the weight shape will be (C x M/group x k1 x k2 x ... x kn), where (k1 x k2 x ... x kn) is the dimension of the kernel. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, pad lengths and group count. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
The shape of the output can be explicitly set which will cause pads values to be auto generated. If output_shape is specified pads values are ignored. See doc for details for equations to generate pads
The zero-padding added to one side of the output. This is also called adjs/adjustment in some frameworks.
ConvTranspose
Output data tensor from pooling across the input tensor. Dimensions will be N x C x 1 x 1
If true, compute the mean and variance across all spatial elements If false, compute the mean and variance across per feature.Default is 1.
If set to nonzero, run spatial batch normalization in test mode, default is 0.
is_test
The epsilon value to use to avoid division by zero, default is 1e-5f.
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum), default is 0.9f.
momentum
The input 4-dimensional tensor of shape NCHW.
The scale as a 1-dimensional tensor of size C to be applied to the output.
The bias as a 1-dimensional tensor of size C to be applied to the output.
The running mean (training) or the estimated mean (testing) as a 1-dimensional tensor of size C.
The running variance (training) or the estimated variance (testing) as a 1-dimensional tensor of size C.
The output 4-dimensional tensor of the same shape as X.
The running mean after the BatchNormalization operator. Must be in-place with the input mean. Should not be used for testing.
The running variance after the BatchNormalization operator. Must be in-place with the input var. Should not be used for testing.
Saved mean used during training to speed up gradient computation. Should not be used for testing.
saved_mean
Saved variance used during training to speed up gradient computation. Should not be used for testing.
saved_var
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum).
Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1
Scale tensor of shape (C).
Bias tensor of shape (C).
running (training) or estimated (testing) mean tensor of shape (C).
running (training) or estimated (testing) variance tensor of shape (C).
The output tensor of the same shape as X
The running mean after the BatchNormalization operator.
The running variance after the BatchNormalization operator.
Saved mean used during training to speed up gradient computation.
Saved variance used during training to speed up gradient computation.
This number of op outputs should be 3 when Training_mode = True, but it is not.
This number of op outputs should be 1 when Training_mode = False, but it is not.
If set to true, it indicates BatchNormalization is being used for training, and outputs 1, 2, 3, and 4 would be populated.
input_mean
input_var
running_mean
The running variance after the BatchNormalization operator. This op uses the population size (N) for calculating variance, and not the sample size N-1.
running_var
Constrain mean and variance types to float tensors. It allows all float type for U.
The input 1-dimensional scale tensor of size C.
The input 1-dimensional bias tensor of size C.
The output 4-dimensional tensor of the same shape as input.
InstanceNormalization
(float, default 0.5) the ratio of random dropout
(int, default 0) if nonzero, run dropout in test mode where the output is simply Y = X.
The output mask. If is_test is nonzero, this output is not filled.
The ratio of random dropout
Constrain output mask types to boolean tensors.
The output tensor of the same shape as X.
Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [0, R], where R is the rank of the input tensor. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
If true, compute the mean and variance across per activation. If false, compute the mean and variance across per feature over each mini-batch.
If spatial is true, the dimension of scale is (C). If spatial is false, the dimensions of scale are (C x D1 x ... x Dn)
If spatial is true, the dimension of bias is (C). If spatial is false, the dimensions of bias are (C x D1 x ... x Dn)
If spatial is true, the dimension of the running mean (training) or the estimated mean (testing) is (C). If spatial is false, the dimensions of the running mean (training) or the estimated mean (testing) are (C x D1 x ... x Dn).
If spatial is true, the dimension of the running variance(training) or the estimated variance (testing) is (C). If spatial is false, the dimensions of the running variance(training) or the estimated variance (testing) are (C x D1 x ... x Dn).
This attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>
The coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.
Denote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input "roi", scale = length_resized / length_original, <br/>
if coordinate_transformation_mode is "half_pixel", <br/>
x_original = (x_resized + 0.5) / scale - 0.5, <br/>
if coordinate_transformation_mode is "pytorch_half_pixel", <br/>
x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>
if coordinate_transformation_mode is "align_corners", <br/>
x_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>
if coordinate_transformation_mode is "asymmetric", <br/>
x_original = x_resized / scale, <br/>
if coordinate_transformation_mode is "tf_half_pixel_for_nn", <br/>
x_original = (x_resized + 0.5) / scale, <br/>
if coordinate_transformation_mode is "tf_crop_and_resize", <br/>
x_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1).
type: 
 does not match type of output: 
Input: 
 expected to have tensor or sparse tensor type
 and Output 
 not specified
Value of attribute 
 should be of integer type and specify a type.
 does not specify a valid type.
The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto
Input tensor to be cast.
Output tensor with the same shape as input with type specified by the 'to' argument
Constrain input types. Casting from complex is not supported.
Constrain output types. Casting to complex is not supported.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\tensor\old.cc
Target shape may not have multiple -1 dimensions
Invalid position of 0
Invalid dimension value: 
Invalid Target shape product of 0
Dimension could not be inferred: incompatible shapes
Specified shape for output.
Reshaped data.
reshaped
Shape of the input tensor
Input tensor can be of arbitrary type.
Constrain output to int64 tensor.
Total number of elements of the input tensor
Constrain output to int64 tensor, which should be a scalar though.
axis must be in [-rank, rank-1].
Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs)..
List of tensors for concatenation
concat_result
Constrain output types to any tensor type.
 Value=
Invalid value of attribute 'axis'. Rank=
) and outputs (
Mismatch between number of splits (
) and the split dimension of the input (
Mismatch between the sum of 'split' (
The input is not evenly splittable
The tensor to split
One or more outputs forming list of tensors after splitting
outputs
Which axis to split on. A negative value means counting dimensions from the back. Accepted range is [-rank, rank-1] where r = rank(input).
length of each output. Values should be >= 0.
Only supports `int32_t` or `int64_t` inputs for starts/ends/axes/steps
Slice op must have either three, four or five inputs.
Incorrect or missing input value for starts and ends
Input axes has incorrect length
Input steps has incorrect length
Input axes has invalid data
'step' cannot be 0
1-D tensor of ending indices (exclusive) of corresponding axis in `axes`
1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1.
steps
Invalid attribute perm {
}, input shape = {
A list of integers. By default, reverse the dimensions, otherwise permute the axes according to the values given.
Transposed output.
transposed
Tensor of rank q + r - indices_shape[-1] - 1.
updates
ScatterND
Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
Tensor of int32/int64 indices, of r >= 1 (same rank as input). All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
Tensor of rank r >=1 (same rank and shape as indices)
Tensor of rank r >= 1 (same rank as input).
Input and output types can be of any tensor type.
ScatterElements
data tensor must have rank >= 1
axis must be in [-r, r-1]
Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
Tensor of int32/int64 indices, of any rank q. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
Tensor of rank q + (r - 1).
Tensor of int32/int64 indices, with the same rank r as the input. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
Tensor of the same shape as indices.
List of integers indicating the dimensions to squeeze. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
Tensors with at least max(dims) dimensions.
Reshaped tensor with same data as input.
squeezed
'axes' attribute must not contain any duplicates
values in 'axes' are beyond the bounds of the computed output shape
List of integers indicating the dimensions to be inserted. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(expanded).
Original tensor
expanded
blocksize
Blocksize must be positive
Input tensor must be 4-dimensional
Blocks of [blocksize, blocksize] are moved.
Input tensor of [N,C,H,W], where N is the batch axis, C is the channel or depth, H is the height and W is the width.
Output tensor of [N, C * blocksize * blocksize, H/blocksize, W/blocksize].
SpaceToDepth
DCR (default) for depth-column-row order re-arrangement. Use CRD for column-row-depth order.
Output tensor of [N, C/(blocksize * blocksize), H * blocksize, W * blocksize].
DepthToSpace
'Repeats' input must be 1D tensor of type int64
'Repeats' input has incorrect number of values. The number of values in 'repeats' must be equal to the number of input dimensions.
Input tensor of any shape.
1D int64 tensor of the same length as input's dimension number, includes numbers of repeated copies along input's dimensions.
repeats
Output tensor of the same dimension and type as tensor input. output_dim[i] = input_dim[i] * repeats[i]
Constrain repeat's type to int64 tensors.
Three interpolation modes: nearest (default), linear and cubic. The "linear" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The "cubic" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor).
The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if "mode" is "cubic".
cubic_coeff_a
If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0.
exclude_outside
round_prefer_floor
Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get "nearest" pixel in input tensor from x_original, so this attribute is valid only if "mode" is "nearest".
When coordinate_transformation_mode is "tf_crop_and_resize" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f.
N-D tensor
1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is "tf_crop_and_resize"
The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. Only one of 'scales' and 'sizes' can be specified. If 'size' is needed, the user can use an empty string as the name of 'scales' in this operator's input list.
The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. Only one of 'scales' and 'sizes' can be specified.
sizes
N-D tensor after resizing
Constrain input 'X' and output 'Y' to all tensor types.
Constrain roi type to float or double.
Tensor to copy input into.
Constrain input types to float tensors.
Constrain output types to boolean tensors.
IsNaN
Constrain to all tensor types.
batch_dims
Both `data` and `indices` input tensors in GatherND op need to have rank larger than 0.
Last dimension of `indices` input tensor in GatherND op must not be larger than the rank of `data` tensor
The number of batch dimensions. The gather of indexing starts from dimension of data[batch_dims:]
Tensor of rank q >= 1. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
'pads' input must be a 1D (shape: [2 * input_rank]) tensor of type int64
Supported modes: `constant`(default), `reflect`, `edge`
Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank]. `pads` format should be: [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pad values added at the beginning of axis `i` and xi_end, the number of pad values added at the end of axis `i`.
(Optional) A scalar value to be used if the mode chosen is `constant` (by default it is 0).
constant_value
Constrains input and output to only numeric types.
Constrain input types. Casting from strings and complex are not supported.
Constrain output types. Casting to strings and complex are not supported.
Which axis to concat on.  Default value is 1.
rank must be greater than axis
Optional list of output lengths (see also arg 'split')
outputs...
Which axis to split on
length of each output
List of integers indicate the padding element count at the beginning and end of each axis, for 2D it is the number of pixel. `paddings` rank should be double of the input's rank. `paddings` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
paddings
Three modes: constant(default), reflect, edge
One float, indicates the value to be filled, default is 0
New shape
Number of repeated copies to make of the input tensor.
tiles
Axis along which to repeat.
Output tensor of same shape and type as input.
Constrain tiles and axis's type to int64 tensors.
The scale along width dimension. It takes value greater than or equal to 1.
width_scale
The scale along height dimension. It takes value greater than or equal to 1.
height_scale
Two interpolation modes: nearest(default), bilinear
4-D tensor, [N,C,H,W]
4-D tensor after resizing, [N,C,H,W]
Constrain output types to bool, int32, int64, float16, float, double tensors.
) is not equal to the existing rank value (
Ranks inferred (
Number of elements of attribute 'scales' must be same as rank of input 'X'
Attribute 'scales' must have floats type.
Attribute 'scales' is required.
The scale array along each dimension. It takes value greater than or equal to 1. The number of elements of 'scales' should be the same as the rank of input 'X'.
Two interpolation modes: nearest (default), and linear (including bilinear, trilinear, etc)
The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'.
Incorrect or missing attribute value for starts and ends
Attribute axes has incorrect length
Axes that `starts` and `ends` apply to. It's optional. If not present, will be treated as [0, 1, ..., len(`starts`) - 1].
Starting indices of corresponding axis in `axes`
Ending indices (exclusive) of corresponding axis in axes`
1-D tensor of slice step of corresponding axis in `axes`. Default to 1. 
Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1]
Tensor of int32/int64 indices, of r >= 1 (same rank as input).
Scatter
Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1]
Tensor of int32/int64 indices, of any rank q. All index values are expected to be within bounds. It is an error if any of the index values are out of bounds.
List of non-negative integers, indicate the dimensions to squeeze.
List of non-negative integers, indicate the dimensions to be inserted
OneHot node must have three inputs.
Input 'depth' must be a scalar or rank 1 tensor.
Input 'depth' must have exactly one element.
Input 'values' must be rank 1 tensor.
Input 'values' must have exactly two elements.
Indices tensor must have rank >= 1
'axis' must be in [-rank(indices)-1, rank(indices)]
(Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor.
Input tensor containing indices. The values must be non-negative integers. Any entries in the 'indices' input tensor with values outside the range [0, depth) will result in one-hot representation with all 'off_value' values in the output tensor.In case 'indices' is of non-integer type, the values will be casted to int64 before use.
Scalar specifying the number of classes in one-hot tensor. This is also the size of the one-hot dimension (specified by 'axis' attribute) added on in the output tensor. The values in the 'indices' input tensor are expected to be in the range [0, depth). In case 'depth' is of non-integer type, it will be casted to int64 before use.
depth
Rank 1 tensor containing exactly two elements, in the format [off_value, on_value], where 'on_value' is the value used for filling locations specified in 'indices' input tensor, and 'off_value' is the value used for filling locations other than those specified in 'indices' input tensor. 
Tensor of rank one greater than input tensor 'indices', i.e. rank(output) = rank(indices) + 1. The data type for the elements of the output tensor is the same as the type of input 'values' is used.
Constrain to any tensor type.
OneHot
(Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected.
Rank 1 tensor of booleans to indicate which slices or data elements to be selected. Its length can be less than the input length alone the axis or the flattened input size if axis is not specified. In such cases data slices or elements exceeding the condition length are discarded.
condition
Tensor of rank r if axis is specified. Otherwise output is a Tensor of rank 1.
Constrains to boolean tensors.
Compress
Which axis to split on. 
Attribute value for pads is required
Attribute pads has incorrect length
List of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D it is the number of pixels. `pads` rank should be double of the input's rank. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
One float, indicates the value to be filled.
sparse_value
value_int
value_ints
value_float
value_floats
value_string
value_strings
One and only one of the attributes 'value', 'value_*' or 'sparse_value' must be specified for a Constant node.
Attribute 'value_int' expect an integer.
Attribute 'value_ints' expect a list of integers.
Attribute 'value_float' expect a float.
Attribute 'value_floats' expect a list of floats.
Attribute 'value_string' expect a string.
Attribute 'value_strings' expect a list of strings.
TypeAndShapeInferenceFunction implementation incomplete: this line should never be reached.
The value for the elements of the output tensor.
The value for the elements of the output tensor in sparse format.
The value for the sole element for the scalar, int64, output tensor.
The values for the elements for the 1D, int64, output tensor.
The value for the sole element for the scalar, float32, output tensor.
The values for the elements for the 1D, float32, output tensor.
The value for the sole element for the scalar, UTF-8 string, output tensor.
The values for the elements for the 1D, UTF-8 string, output tensor.
Output tensor containing the same value of the provided tensor.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\generator\old.cc
Attribute 'value' of Constant node must exist with 'Tensor' data.
Only one of the attributes 'value' or 'sparse_value' must be specified for a Constant node.
One of the attributes 'value' or 'sparse_value' must be specified for a Constant node.
Computes an one-layer simple RNN. This operator is usually supported
via some custom implementation such as CuDNN.
Notations:
`X` - input tensor
`i` - input gate
`t` - time step (t-1 means previous time step)
`Wi` - W parameter weight matrix for input gate
`Ri` - R recurrence weight matrix for input gate
`Wbi` - W parameter bias vector for input gate
`Rbi` - R parameter bias vector for input gate
`WBi` - W parameter weight matrix for backward input gate
`RBi` - R recurrence weight matrix for backward input gate
`WBbi` - WR bias vectors for backward input gate
`RBbi` - RR bias vectors for backward input gate
`H` - Hidden state
`num_directions` - 2 if direction == bidirectional else 1
Activation functions:
  Relu(x)                - max(0, x)
  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
  Sigmoid(x)             - 1/(1 + e^{-x})
  (NOTE: Below are optional)
  Affine(x)              - alpha*x + beta
  LeakyRelu(x)           - x if x >= 0 else alpha * x
  ThresholdedRelu(x)     - x if x >= alpha else 0
  ScaledTanh(x)          - alpha*Tanh(beta*x)
  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
  Softsign(x)            - x/(1 + |x|)
  Softplus(x)            - log(1 + e^x)
Equations (Default: f=Tanh):
  - Ht = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi)
Computes an one-layer GRU. This operator is usually supported via some custom
implementation such as CuDNN.
Notations:
`X` - input tensor
`z` - update gate
`r` - reset gate
`h` - hidden gate
`t` - time step (t-1 means previous time step)
`W[zrh]` - W parameter weight matrix for update, reset, and hidden gates
`R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates
`Wb[zrh]` - W bias vectors for update, reset, and hidden gates
`Rb[zrh]` - R bias vectors for update, reset, and hidden gates
`WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates
`RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates
`WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates
`RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates
`H` - Hidden state
`num_directions` - 2 if direction == bidirectional else 1
Activation functions:
  Relu(x)                - max(0, x)
  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
  Sigmoid(x)             - 1/(1 + e^{-x})
  (NOTE: Below are optional)
  Affine(x)              - alpha*x + beta
  LeakyRelu(x)           - x if x >= 0 else alpha * x
  ThresholdedRelu(x)     - x if x >= alpha else 0
  ScaledTanh(x)          - alpha*Tanh(beta*x)
  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
  Softsign(x)            - x/(1 + |x|)
  Softplus(x)            - log(1 + e^x)
Equations (Default: f=Sigmoid, g=Tanh):
  - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)
  - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)
  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0
  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0
  - Ht = (1 - zt) (.) ht + zt (.) Ht-1
Computes an one-layer LSTM. This operator is usually supported via some
custom implementation such as CuDNN.
Notations:
`X` - input tensor
`i` - input gate
`o` - output gate
`f` - forget gate
`c` - cell gate
`t` - time step (t-1 means previous time step)
`W[iofc]` - W parameter weight matrix for input, output, forget, and cell gates
`R[iofc]` - R recurrence weight matrix for input, output, forget, and cell gates
`Wb[iofc]` - W bias vectors for input, output, forget, and cell gates
`Rb[iofc]` - R bias vectors for input, output, forget, and cell gates
`P[iof]`  - P peephole weight vector for input, output, and forget gates
`WB[iofc]` - W parameter weight matrix for backward input, output, forget, and cell gates
`RB[iofc]` - R recurrence weight matrix for backward input, output, forget, and cell gates
`WBb[iofc]` - W bias vectors for backward input, output, forget, and cell gates
`RBb[iofc]` - R bias vectors for backward input, output, forget, and cell gates
`PB[iof]`  - P peephole weight vector for backward input, output, and forget gates
`H` - Hidden state
`num_directions` - 2 if direction == bidirectional else 1
Activation functions:
  Relu(x)                - max(0, x)
  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
  Sigmoid(x)             - 1/(1 + e^{-x})
  (NOTE: Below are optional)
  Affine(x)              - alpha*x + beta
  LeakyRelu(x)           - x if x >= 0 else alpha * x
  ThresholdedRelu(x)     - x if x >= alpha else 0
  ScaledTanh(x)          - alpha*Tanh(beta*x)
  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
  Softsign(x)            - x/(1 + |x|)
  Softplus(x)            - log(1 + e^x)
Equations (Default: f=Sigmoid, g=Tanh, h=Tanh):
  - it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)
  - ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)
  - ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)
  - Ct = ft (.) Ct-1 + it (.) ct
  - ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)
  - Ht = ot (.) h(Ct)
foward
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM.
The sequence output for the hidden is optional if 0. Default 0.
output_sequence
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. It is optional if `output_sequence` is 0.
A list of 2 (or 4 if bidirectional) activation functions for update, reset, and hidden gates. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
The weight tensor for the gates. Concatenation of `W[zrh]` and `WB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, input_size]`.
The recurrence weight tensor. Concatenation of `R[zrh]` and `RB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, hidden_size]`.
The bias tensor for the gates. Concatenation of `[Wb[zrh], Rb[zrh]]` and `[WBb[zrh], RBb[zrh]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 6*hidden_size]`. Optional: If not specified - assumed to be 0
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\rnn\old.cc
One (or two if bidirectional) activation function for input gate. The activation function must be one of the activation functions specified above. Optional: Default `Tanh` if not specified.
The weight tensor for input gate. Concatenation of `Wi` and `WBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, input_size]`.
The recurrence weight tensor. Concatenation of `Ri` and `RBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, hidden_size]`.
The bias tensor for input gate. Concatenation of `[Wbi, Rbi]` and `[WBbi, RBbi]` (if bidirectional). The tensor has shape `[num_directions, 2*hidden_size]`. Optional: If not specified - assumed to be 0.
When computing the output of the hidden gate, apply the linear transformation before multiplying by the output of the reset gate.
First input tensor must have rank 3
Carries out batch normalization as described in the paper
https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
There are five required inputs 'X', 'scale', 'B', 'input_mean' and
'input_var'.
Note that 'input_mean' and 'input_var' are expected to be the estimated
statistics in inference mode (training_mode=False, default),
and the running statistics in training mode (training_mode=True).
There are multiple cases for the number of outputs, which we list below:
Output case #1: Y, running_mean, running_var (training_mode=True)
Output case #2: Y (training_mode=False)
When training_mode=False, extra outputs are invalid.
The outputs are updated as follows when training_mode=True:
running_mean = input_mean * momentum + current_mean * (1 - momentum)
running_var = input_var * momentum + current_var * (1 - momentum)
Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B
where:
current_mean = ReduceMean(X, axis=all_except_channel_index)
current_var =  ReduceVar(X, axis=all_except_channel_index)
Notice that ReduceVar refers to the population variance, and it equals to
sum(sqrd(x_i - x_avg)) / N
where N is the population size (this formula does not use sample size N - 1).
The computation of ReduceMean and ReduceVar uses float to avoid overflow for float16 inputs.
When training_mode=False:
Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B
For previous (depreciated) non-spatial cases, implementors are suggested
to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = input_shape[i] * strides[i]` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.
Constrain input and output types to float and 8 bit tensors.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\nn\defs.cc
The output of each pooling window is maximum number of elements exclude pad. 
RoIs tensor must have 2 dimensions
pooled_shape
Attribute pooled_shape has incorrect length
Attribute pooled_shape must be specified
ROI pool output shape (height, width).
Multiplicative spatial scale factor to translate ROI coordinates from their input scale to the scale used when pooling.
spatial_scale
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
RoIs (Regions of Interest) to pool over. Should be a 2-D tensor of shape (num_rois, 5) given as [[batch_id, x1, y1, x2, y2], ...].
RoI pooled output 4-D tensor of shape (num_rois, channels, pooled_shape[0], pooled_shape[1]).
MaxRoiPool
dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis.
Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis.
Scale tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Zero point tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Scale tensor for input 'w'. It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M).
Zero point tensor for input 'w'. It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M).
Scale tensor for output 'y'. It's a scalar, which means a per-tensor/layer quantization.
Zero point tensor for output 'y'. It's a scalar, which means a per-tensor/layer quantization.
Optional 1D bias to be added to the convolution, has size of M. Bias must be quantized using scale = x_scale * w_scale and zero_point = 0
Constrain filter type to 8-bit integer tensor.
Constrain output type to 8-bit integer tensor.
Constrain bias type to 32-bit integer tensor.
The shape of the convolution kernel. If not present, should be inferred from input 'w'.
dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each spatial axis.
Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0.The value represent the number of pixels added to the beginning and end part of the corresponding axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number ofpixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaultsto 0 along start and end of each spatial axis.
number of groups input channels and output channels are divided into. default is 1.
Zero point tensor for input 'x'. It's optional and default value is 0. It's a scalar, which means a per-tensor/layer quantization.
Zero point tensor for input 'w'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M)
Constrain input x and its zero point data type to 8-bit integer tensor.
Constrain input w and its zero point data type to 8-bit integer tensor.
Constrain output y data type to 32-bit integer tensor.
dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each axis.
Stride along each spatial axis. If not present, the stride defaults to 1 along each axis.
The pads attribute cannot be used simultaneously with auto_pad attribute
Additional elements added to the side with higher coordinate indices in the output. Each padding value in "output_padding" must be less than the corresponding stride/dilation dimension. By default, this attribute is a zero vector. Note that this attribute doesn't directly affect the computed output values. It only controls the selection of the computed values, so changing this attribute only adds or removes output elements. If "output_shape" is explicitly provided, "output_padding" does not contribute additional size to "output_shape" but participates in the computation of the needed padding amount. This is also called adjs or adjustment in some frameworks.
Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1.
lp pool
Constrain scale and bias types to float tensors.
Constrain mean and variance types to float tensors.
The output tensor of the same shape as input.
Input matrix
Matrix after normalization
The axis on which to apply normalization, -1 mean last axis.
The order of the normalization, only 1 or 2 are supported.
LpNormalization
The lambd value for the Shrink formulation. Default is 0.5.
lambd
The bias value added to output. Default is 0.
Shrink
ngram_indexes
ngram_indexes must be non-empty with no negative values
Input tensor must have rank 1 or 2
Input for n-gram extraction
Ngram results
Input is ether string UTF-8 or int32/int64
1-D tensor of floats
Maximum n-gram length. If this value is 3, 3-grams will be used to generate the output.
max_gram_length
Minimum n-gram length. If this value is 2 and max_gram_length is 3, output may contain counts of 2-grams and 3-grams.
min_gram_length
Maximum number of items (integers/strings) to be skipped when constructing an n-gram from X. If max_skip_count=1, min_gram_length=2, max_gram_length=3, this operator may generate 2-grams with skip_count=0 and skip_count=1, and 3-grams with skip_count=0 and skip_count=1
max_skip_count
List of strings n-grams learned from the training set. Either this or pool_int64s attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
pool_strings
List of int64 n-grams learned from the training set. Either this or pool_strings attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
pool_int64s
The starting indexes of 1-grams, 2-grams, and so on in pool. It is useful when determining the boundary between two consecutive collections of n-grams. For example, if ngram_counts is [0, 17, 36], the first index (zero-based) of 1-gram/2-gram/3-gram in pool are 0/17/36. This format is essentially identical to CSR (or CSC) sparse matrix format, and we choose to use this due to its popularity.
ngram_counts
list of int64s (type: AttributeProto::INTS). This list is parallel to the specified 'pool_*' attribute. The i-th element in ngram_indexes indicate the coordinate of the i-th n-gram in the output tensor.
list of floats. This attribute stores the weight of each n-gram in pool. The i-th element in weights is the weight of the i-th n-gram in pool. Its length equals to the size of ngram_indexes. By default, weights is an all-one tensor.This attribute is used when mode is "IDF" or "TFIDF" to scale the associated word counts.
The weighting criteria. It can be one of "TF" (term frequency), "IDF" (inverse document frequency), and "TFIDF" (the combination of TF and IDF)
TfIdfVectorizer
Input shape must have either [C] or [1,C] dimensions where C > 0
UTF-8 strings to normalize
UTF-8 Normalized strings
string enum that cases output to be lowercased/uppercases/unchanged. Valid values are "LOWER", "UPPER", "NONE". Default is "NONE"
case_change_action
Boolean. Whether the identification of stop words in X is case-sensitive. Default is false
is_case_sensitive
List of stop words. If not set, no word would be removed from X.
stopwords
Environment dependent string that denotes the locale according to which output strings needs to be upper/lowercased.Default en_US or platform specific equivalent as decided by the implementation.
locale
StringNormalizer
Element type of tensor or sparse tensor input was unknown
Input was expected to have tensor or sparse tensor type. Got 
 does not match existing output type of 
Input element type of 
Output was expected to have tensor type. Got 
Element type of input was unknown
Input was expected to have either tensor or sequence type. Got 
 was not a tensor.
Scan input 
 outputs. Expected 
Graph attribute inferencing returned type information for 
 was not
Scan 'body' subgraph outputs should all be tensors but output 
 is invalid for a tensor of rank 
 axis value 
) is not equal to number of scan inputs (
Number of scan input axes specified (
) is not equal to number of scan outputs (
Number of scan output axes specified (
Optional tensor specifying lengths of the sequences in a batch. If this input is not specified, all sequences are assumed to be of the maximum sequence length (the dimension of the sequence axis of the scan_input tensors).
Initial values of the loop's N state variables followed by M scan_inputs
initial_state_and_scan_inputs
Final values of the loop's N state variables followed by K scan_outputs
final_state_and_scan_outputs
The graph run each iteration. It has N+M inputs: (loop state variables..., scan_input_elts...). It has N+K outputs: (loop state variables..., scan_output_elts...). Each scan_output is created by concatenating the value of the specified scan_output_elt value at the end of each iteration of the loop. It is an error if the dimensions of these values change across loop iterations.
An attribute specifying the number of scan_inputs M. 
An optional list of M flags. The i-th element of the list specifies the direction to be scanned for the i-th scan_input tensor: 0 indicates forward direction and 1 indicates reverse direction. If omitted, all scan_input tensors will be scanned in the forward direction.
directions
Int64 tensor
All Tensor types
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\controlflow\old.cc
 was 
Loop 'body' subgraph outputs should all be tensors but output 
A maximum trip-count for the loop specified at runtime. Optional. Pass empty string to skip.
A boolean termination condition. Optional. Pass empty string to skip.
The initial values of any loop-carried dependencies (values that change across loop iterations)
v_initial
Final N loop carried dependency values then K scan_outputs
v_final_and_scan_outputs
The graph run each iteration. It has 2+N inputs: (iteration_num, condition, loop carried dependencies...). It has 1+N+K outputs: (condition, loop carried dependencies..., scan_outputs...). Each scan_output is created by concatenating the value of the specified output value at the end of each iteration of the loop. It is an error if the dimensions or data type of these scan_outputs change across loop iterations.
tensor of int64, which should be a scalar.
tensor of bool, which should be a scalar.
An optional list of K flags, one for each scan_output. The i-th element of the list specifies whether the i-th scan_output should be constructed by appending or prepending a new value in each iteration: 0 indicates appending and 1 indicates prepending. If omitted, all scan_output tensors will be produced by appending a value in each iteration.
An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input.
An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output.
then_branch
else_branch
then_branch and else_branch produce different number of outputs. 
 but subgraphs produce 
If node has 
 else=
 then=
Mismatched type for output 
Mismatched tensor element type for output 
Condition for the if
Values that are live-out to the enclosing scope. The return values in the `then_branch` and `else_branch` must be of the same shape and same data type.
Graph to run if condition is true. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the else_branch.
Graph to run if condition is false. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the then_branch.
Only bool
Values that are live-out to the enclosing scope. The return values in the `then_branch` and `else_branch` must be of the same data type. The `then_branch` and `else_branch` may produce tensors with the same element type and different shapes. If corresponding outputs from the then-branch and the else-branch have static shapes S1 and S2, then the shape of the corresponding output variable of the if-node (if present) must be compatible with both S1 and S2 as it represents the union of both possible shapes.For example, if in a model file, the the first output of `then_branch` is typed float tensor with shape [2] and the first output of `else_branch` is another float tensor with shape [3], If's first output should have (a) no shape set, or (b) a shape of rank 1 with neither `dim_value` nor `dim_param` set, or (c) a shape of rank 1 with a unique `dim_param`. In contrast, the first output cannot have the shape [2] since [2] and [3] are not compatible.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\logical\defs.cc
Constrains input/output to boolean tensors.
First operand, input to be shifted.
Second operand, amounts of shift.
Constrain input and output types to integer tensors.
Direction of moving bits. It can be either "RIGHT" (for right shift) or "LEFT" (for left shift).
less_equal
greater_equal
 or UNDEFINED. Got: 
 expected to have: 
Attribute expected to have a one-dim tensor
Attribute expected to have a one-dim sparse tensor
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\generator\defs.cc
Shape input must be a one-dimensional tensor.
Invalid shape value: 
(Optional) The value of the output elements.Should be a one-element tensor. If not specified, it defaults to a tensor of value 0 and datatype float32
1D tensor. The shape of the expected output tensor. If empty tensor is given, the output would be a scalar. All values must be >= 0.
Output tensor of shape specified by 'input'.If attribute 'value' is specified, the value and datatype of the output tensor is taken from 'value'.If attribute 'value' is not specified, the value in the output defaults to 0, and the datatype defaults to float32.
Constrain input types.
Constrain output types to be numerics.
Input tensor must be 2-dimensional
(Optional) Index of the diagonal to be populated with ones. Default is 0. If T2 is the output, this op sets T2[i, i+k] = 1. k = 0 populates the main diagonal, k > 0 populates an upper diagonal,  and k < 0 populates a lower diagonal.
(Optional) The data type for the elements of the output tensor. If not specified,the data type of the input tensor T1 is used. If input tensor T1 is also notspecified, then type defaults to 'float'.
2D input tensor to copy shape, and optionally, type information from.
Output tensor, same shape as input tensor T1.
Constrain input types. Strings and complex are not supported.
Constrain output types. Strings and complex are not supported.
EyeLike
Lower boundary of the output values.
Upper boundary of the output values.
The data type for the elements of the output tensor. If not specified, default is TensorProto::FLOAT.
The shape of the output tensor.
Output tensor of random values drawn from uniform distribution
The mean of the normal distribution.
The standard deviation of the normal distribution.
The data type for the elements of the output tensor. Default is TensorProto::FLOAT.
Output tensor of random values drawn from normal distribution
(Optional) The data type for the elements of the output tensor, if not specified, we will use the data type of the input tensor.
Input tensor to copy shape and optionally type information from.
Output type must be int32 or int64
Input tensor must have rank 2
sample_size
Number of times to sample.
(Optional) The data type for the elements of the output tensor, if not specified, we will use int32.
Input tensor with shape [batch_size, class_size], where class_size is the number of all possible outcomes. Each value along the axis zero represents the unnormalized log-probability of each corresponding outcome in a batch.
Output tensor with shape [batch_size, sample_size], where sample_size is the number of times to sample. Each value along the axis zero represents the outcome of the corresponding sample in a batch.
Constrain output types to integral tensors.
loop_body_attribute
cond_out
current
range
sub_result
sub_result_casted
delta_casted
div_result
ceil_result
ceil_result_relu
ceil_result_relu_int
ceil_result_relu_bool
variadic_output
All inputs to 'Range' op must be of the same type
Scalar. First entry for the range of output values.
Scalar. Exclusive upper limit for the range of output values.
Scalar. Value to step by.
A 1-D tensor with same type as the inputs containing generated range of values.
Constrain input types to common numeric type tensors.
X_random
X_greater
The data type for the elements of the output tensor. if not specified, we will use the data type of the input tensor.
All values in input have to be in the range:[0, 1].
The returned output tensor only has values 0 or 1, same shape as input tensor.
Constrain output types to all numeric tensors and bool tensors.
Bernoulli
Input to 'Range' op should be scalars (Tensor with only one element and shape empty)
Wrong op_type name for running propagation: 
) vs (
 broadcasting: (
Invalid rank for 
The input tensor of rank >= axis.
The output values with the same shape as the input tensor.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\math\defs.cc
Coefficient of SELU default to 1.67326319217681884765625 (i.e., float32 approximation of 1.6732632423543772848170429916717).
Coefficient of SELU default to 1.05070102214813232421875 (i.e., float32 approximation of 1.0507009873554804934193349852946).
Coefficient of ELU.
X_alpha
Elu_Result
The Alpha value in Celu formula which control the shape of the unit. The default value is 1.0.
Value of alpha.
Value of beta.
HardSwish
X_ReduceMax
X_Sub
X_Exp
X_ReduceSum
Softmax(input, axis) = Exp(input) / ReduceSum(Exp(input), axis=axis, keepdims=1) 
LogSoftmax(input, axis) = Log(Softmax(input, axis=axis))
Hardmax(element in input, axis) = 1 if the element is the first maximum value along the specified axis, 0 otherwise
The softsign (x/(1+|x|)) values of the input tensor computed element-wise
Dimension on which to do the sort. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
Whether to return the top-K largest or smallest elements.
Whether to return the elements in sorted order.
The sine of the input tensor computed element-wise
The cosine of the input tensor computed element-wise
The tangent of the input tensor computed element-wise
The arcsine of the input tensor computed element-wise
The arccosine of the input tensor computed element-wise
The arctangent of the input tensor computed element-wise
The hyperbolic sine values of the input tensor computed element-wise
The hyperbolic cosine values of the input tensor computed element-wise
The hyperbolic arcsine values of the input tensor computed element-wise
The hyperbolic arccosine values of the input tensor computed element-wise
The hyperbolic arctangent values of the input tensor computed element-wise
input and zero_point pair is expected to have same type.
N-dimensional quantized matrix a
scale of quantized input a
zero point of quantized input a
N-dimensional quantized matrix b
scale of quantized input b
zero point of quantized input b
scale of quantized output y
zero point of quantized output y
Quantized matrix multiply results from a * b
Constrain input a and its zero point data type to 8-bit integer tensor.
Constrain input b and its zero point data type to 8-bit integer tensor.
Constrain output y and its zero point data type to 8-bit integer tensor.
QLinearMatMul
Zero point tensor for input 'A'. It's optional and default value is 0. It could be a scalar or N-D tensor. Scalar refers to per tensor quantization whereas N-D refers to per row quantization. If the input is 2D of shape [M, K] then zero point tensor may be an M element vector [zp_1, zp_2, ..., zp_M]. If the input is N-D tensor with shape [D1, D2, M, K] then zero point tensor may have shape [D1, D2, M, 1]. 
Zero point tensor for input 'B'. It's optional and default value is 0. It could be a scalar or a N-D tensor, Scalar refers to per tensor quantization whereas N-D refers to per col quantization. If the input is 2D of shape [K, N] then zero point tensor may be an N element vector [zp_1, zp_2, ..., zp_N]. If the input is N-D tensor with shape [D1, D2, K, N] then zero point tensor may have shape [D1, D2, 1, N]. 
Constrain output Y data type as 32-bit integer tensor.
Constrain input and output types to floating-point tensors.
Number of input tensors does not match the operands in the equation.
Ellipsis represents incompatible dimensions.
 does not match the equation indices.
Rank of input 
equation
Einsum expression string.
Operands
Inputs
Constrain input and output types to all numerical tensor types.
Einsum
This attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>
The coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.
Denote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input "roi", scale = length_resized / length_original, <br/>
if coordinate_transformation_mode is "half_pixel", <br/>
x_original = (x_resized + 0.5) / scale - 0.5, <br/>
if coordinate_transformation_mode is "pytorch_half_pixel", <br/>
x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>
if coordinate_transformation_mode is "align_corners", <br/>
x_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>
if coordinate_transformation_mode is "asymmetric", <br/>
x_original = x_resized / scale, <br/>
if coordinate_transformation_mode is "tf_crop_and_resize", <br/>
x_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1).
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\tensor\defs.cc
The (first) input tensor will be cast to produce a tensor of the same type as this (second input) tensor.
target_type
Output tensor produced by casting the first input tensor to have the same type as the second input tensor.
CastLike
Target shape may not have multiple -1 dimensions.
Invalid position of 0.
Invalid Target shape product of 0. Product cannot be 0 in combination with -1
(Optional) By default, when any value in the 'shape' input is equal to zero the corresponding dimension value is copied from the input tensor dynamically. allowzero=1 indicates that if any value in the 'shape' input is set to zero, the zero value is honored, similar to NumPy.
(Optional) Starting axis for slicing the shape. Default value is 0.Negative value means counting dimensions from the back.
(Optional) Ending axis for slicing the shape. Negative value means counting dimensions from the back. If omitted, sizes of all axes upto (including) the last one will be included.
Optional length of each output. Values should be >= 0.Sum of the values must be equal to the dim value at 'axis' specified.
'step' cannot be 0 for Slice
Input rank for starts and ends should be the same: (
The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. One of 'scales' and 'sizes' MUST be specified and it is an error if both are specified. If 'sizes' is needed, the user can use an empty string as the name of 'scales' in this operator's input list.
Constrain input and output types to all tensor and sequence types.
(Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
Rank 1 tensor of booleans to indicate which slices or data elements to be selected. Its length can be less than the input length along the axis or the flattened input size if axis is not specified. In such cases data slices or elements exceeding the condition length are discarded.
(Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor. Negative value means counting dimensions from the back. Accepted range is [-r-1, r] where r = rank(indices).
Input tensor containing indices. Any entries in the 'indices' input tensor with values outside the range [-depth, depth-1] will result in one-hot representation with all 'off_value' values in the output tensor.In case 'indices' is of non-integer type, the values will be casted to int64 before use.
Scalar specifying the number of classes in one-hot tensor. This is also the size of the one-hot dimension (specified by 'axis' attribute) added on in the output tensor. The values in the 'indices' input tensor are expected to be in the range [-depth, depth-1]. In case 'depth' is of non-integer type, it will be casted to int64 before use.
(Optional) Whether map positive infinity to true. Default to 1 so that positive infinity induces true. Set this attribute to 0 if positive infinity should be mapped to false.
detect_positive
(Optional) Whether map negative infinity to true. Default to 1 so that negative infinity induces true. Set this attribute to 0 if negative infinity should be mapped to false.
detect_negative
IsInf
When True (nonzero), yield X, otherwise yield Y
values selected at indices where condition is True
values selected at indices where condition is False
Tensor of shape equal to the broadcasted shape of condition, X, and Y.
Constrain to boolean tensors.
'input' must have rank >= 2
'sequence_lens' must have rank of 1
(Optional) Specify which axis is time axis. Must be one of 0 (default), or 1.
time_axis
(Optional) Specify which axis is batch axis. Must be one of 1 (default), or 0.
batch_axis
Tensor of rank r >= 2.
Tensor specifying lengths of the sequences in a batch. It has shape `[batch_size]`.
Tensor with same shape of input.
ReverseSequence
(Optional) Whether to sort the unique elements in ascending order before returning as output. Must be one of 0, or 1 (default).
(Optional) The dimension to apply unique. If not specified, the unique elements of the flattened input are returned. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
A N-D input tensor that is to be processed.
A tensor of the same type as 'X' containing all the unique values or subtensors sliced along a provided 'axis' in 'X', either sorted or maintained in the same order they occur in input 'X'
A 1-D INT64 tensor containing indices of 'Y' elements' first occurance in 'X'. When 'axis' is provided, it contains indices to subtensors in input 'X' on the 'axis'. When 'axis' is not provided, it contains indices to values in the flattened input tensor. 
A 1-D INT64 tensor containing, for elements of 'X', its corresponding indices in 'Y'. When 'axis' is provided, it contains indices to subtensors in output 'Y' on the 'axis'. When 'axis' is not provided, it contains indices to values in output 'Y'. 
inverse_indices
A 1-D INT64 tensor containing the count of each element of 'Y' in input 'X'
(Optional) A scalar value to be used if the mode chosen is `constant` (by default it is 0, empty string or False).
A 0-D tensor containing a single value corresponding to the number diagonals above or below the main diagonal to exclude or include. Default value is 0 if it's not specified.
Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization.
Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified.
Constrain 'x' to float or int32 tensor.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\quantization\old.cc
N-D quantized input tensor to be de-quantized.
Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified.
Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.
An input tensor with shape [num_batches, spatial_dimension, 4]. The single box data format is indicated by center_point_box.
boxes
An input tensor with shape [num_batches, num_classes, spatial_dimension]
Integer representing the maximum number of boxes to be selected per batch per class. It is a scalar. Default to 0, which means no output.
max_output_boxes_per_class
Float representing the threshold for deciding whether boxes overlap too much with respect to IOU. It is scalar. Value range [0, 1]. Default to 0.
iou_threshold
Float representing the threshold for deciding when to remove boxes based on score. It is a scalar.
score_threshold
selected indices from the boxes tensor. [num_selected_indices, 3], the selected index format is [batch_index, class_index, box_index].
selected_indices
Integer indicate the format of the box data. The default is 0. 0 - the box data is supplied as [y1, x1, y2, x2] where (y1, x1) and (y2, x2) are the coordinates of any diagonal pair of box corners and the coordinates can be provided as normalized (i.e., lying in the interval [0, 1]) or absolute. Mostly used for TF models. 1 - the box data is supplied as [x_center, y_center, width, height]. Mostly used for Pytorch models.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\object_detection\old.cc
output_height
output_width
Multiplicative spatial scale factor to translate ROI coordinates from their input spatial scale to the scale used when pooling, i.e., spatial scale of the input feature map X relative to the input image. E.g.; default is 1.0f. 
default 1; Pooled output Y's height.
default 1; Pooled output Y's width.
Number of sampling points in the interpolation grid used to compute the output value of each pooled output bin. If > 0, then exactly sampling_ratio x sampling_ratio grid points are used. If == 0, then an adaptive number of grid points are used (computed as ceil(roi_width / output_width), and likewise for height). Default is 0.
sampling_ratio
The pooling method. Two modes are supported: 'avg' and 'max'. Default is 'avg'.
RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[x1, y1, x2, y2], ...]. The RoIs' coordinates are in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.
RoI pooled output, 4-D tensor of shape (num_rois, C, output_height, output_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].
RoiAlign
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\object_detection\defs.cc
Scale for doing quantization to get 'y'. It can be a scalar, which means per-tensor/layer quantization, or a 1-D Tensor for per-axis quantization.
Zero point for doing quantization to get 'y'. It can be a scalar, which means a per-tensor/layer quantization, or a 1-D tensor for per-axis quantization. Default value is uint8 typed 0 if it's not specified.
(Optional) The axis of the quantization dimension of the input tensor. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input)
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\quantization\defs.cc
Scale for input 'x'. It can be a scalar, which means a per-tensor/layer dequantization, or a 1-D tensor for per-axis dequantization.
Zero point for input 'x'. It can be a scalar, which means a per-tensor/layer dequantization, or a 1-D tensor for per-axis dequantization. It's optional. 0 is the default value when it's not specified.
(Optional) The axis of the dequantizing dimension of the input tensor. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input)
Quantized output tensor
Output zero point. It's a scalar, which means a per-tensor/layer quantization.
Constrain 'x' to float tensor.
Constrain 'y_zero_point' and 'y' to 8-bit unsigned integer tensor.
Q_Min
Q_Max
X_Min
X_Min_Adjusted
X_Max
X_Max_Adjusted
X_Range
Min_Scaled
Initial_ZeroPoint_FP
Clipped_ZeroPoint_FP
Rounded_ZeroPoint_FP
Zeropoint
Loop 'body' subgraph outputs should all be tensors or sequences but output 
Loop 'body' subgraph scan outputs should all be tensors but output 
All Tensor and Sequence types
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\controlflow\defs.cc
Final N loop carried dependency values then K scan_outputs. Scan outputs must be Tensors.
An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input. Negative value for an axis means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output. Negative value for an axis means counting dimensions from the back. Accepted range is [-r, r-1].
Attribute dtype should be of integer type and specify a type.
(Optional) The data type of the tensors in the output sequence. The default type is 'float'.
Empty sequence.
SequenceEmpty
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\sequence\defs.cc
SequenceConstruct is expected to have at least 1 input.
 is null. Type info is expected.
Input type for input at index 
Element type of inputs are expected to be the same.
Tensors.
Sequence enclosing the input tensors.
Constrain input types to any tensor type.
SequenceConstruct
Input Sequence and Tensor are expected to have type info. Current type is null.
 Tensor=
Input Sequence and Tensor are expected to have the same elem type. Sequence=
Input sequence.
input_sequence
Input tensor to be inserted into the input sequence.
Position in the sequence where the new tensor is inserted. It is optional and default is to insert to the back of the sequence. Negative value means counting positions from the back. Accepted range in `[-n, n]`, where `n` is the number of tensors in 'input_sequence'. It is an error if any of the index values are out of bounds. It must be a scalar(tensor of empty shape).
position
Output sequence that contains the inserted tensor at given position.
Constrain position to integral tensor. It must be a scalar(tensor of empty shape).
SequenceInsert
Input type for input at index 0 is null. Type info is expected.
Position of the tensor in the sequence. Negative value means counting positions from the back. Accepted range in `[-n, n - 1]`, where `n` is the number of tensors in 'input_sequence'. It is an error if any of the index values are out of bounds. It must be a scalar(tensor of empty shape).
Output tensor at the specified position in the input sequence.
SequenceAt
Output sequence that has the tensor at the specified position removed.
SequenceErase
Length of input sequence. It must be a scalar(tensor of empty shape).
Constrain output to integral tensor. It must be a scalar(tensor of empty shape).
SequenceLength
Only supports `int32_t` or `int64_t` inputs for split
Input 'split' can not be empty.
 sum of split values=
Sum of split values not equal to 'input' dim size on 'axis'. 'axis' dim size=
Length of each output. It can be either a scalar(tensor of empty shape), or a 1-D tensor. All values must be >= 0. 
One or more outputs forming a sequence of tensors after splitting
Constrain split size to integral tensor.
Constrain output types to all tensor types.
Which axis to split on. A negative value means counting dimensions from the back. Accepted range is [-rank, rank-1].
Keep the split dimension or not. Default 1, which means we keep split dimension. If input 'split' is specified, this attribute is ignored.
SplitToSequence
new_axis must be either 0 or 1
], Value=
Invalid value of attribute 'axis'. Accepted range=[
Which axis to concat on. Accepted range in `[-r, r - 1]`, where `r` is the rank of input tensors. When `new_axis` is 1, accepted range is `[-r - 1, r]`. 
Insert and concatenate on a new axis or not, default 0 means do not insert new axis.
Sequence of tensors for concatenation
ConcatFromSequence
axes as an input and attribute cannot be specified at the same time.
Defines behaviour if 'axes' is empty. Default behaviour with 'false' is to reduce all axes. When axes is empty and this attribute is set to true, input tensor will not be reduced,and the output tensor would be equivalent to input tensor.
Optional input list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor if 'noop_with_empty_axes' is false, else act as an Identity op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1] where r = rank(data).
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\reduction\defs.cc
The shape format of inputs X, initial_h and outputs Y, Y_h. If 0, the following shapes are expected: X.shape = [seq_length, batch_size, input_size], Y.shape = [seq_length, num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape = [num_directions, batch_size, hidden_size]. If 1, the following shapes are expected: X.shape = [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length, num_directions, hidden_size], initial_h.shape = Y_h.shape = [batch_size, num_directions, hidden_size].
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\rnn\defs.cc
The shape format of inputs X, initial_h, initial_c and outputs Y, Y_h, Y_c. If 0, the following shapes are expected: X.shape = [seq_length, batch_size, input_size], Y.shape = [seq_length, num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape = initial_c.shape = Y_c.shape = [num_directions, batch_size, hidden_size]. If 1, the following shapes are expected: X.shape = [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length, num_directions, hidden_size], initial_h.shape = Y_h.shape = initial_c.shape = Y_c.shape = [num_directions, batch_size, hidden_size].
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\optional\defs.cc
Data to be selected
The indices, based on 0 as the first index of any dimension.
Selected output data as an array
The input must be a tensor of a numeric type or string. The output will be of the same tensor type.
ArrayFeatureExtractor
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\traditionalml\defs.cc
Data to be binarized
Binarized output data
The input must be a tensor of a numeric type. The output will be of the same tensor type.
Values greater than this are mapped to 1, others to 0.
threshold
Binarizer
cast_to
TO_FLOAT
TO_INT64
TO_STRING
The input map that is to be cast to a tensor
A tensor representing the same data as the input map, ordered by their keys
The input must be an integer map to either string or float.
map(int64, string)
map(int64, float)
The output is a 1-D tensor of string, float, or integer.
A string indicating the desired element type of the output tensor, one of 'TO_FLOAT', 'TO_STRING', 'TO_INT64'.
DENSE
Indicates whether to only output as many values as are in the input (dense), or position the input based on using the key of the map as the index of the output (sparse).<br>One of 'DENSE', 'SPARSE'.
map_form
If the value of map_form is 'SPARSE,' this attribute indicates the total length of the output tensor.
max_map
CastMap
Input data
Output data. If strings are input, the output values are integers, and vice versa.
The input must be a tensor of strings or integers, either [N,C] or [C].
The output is a tensor of strings or integers. Its shape will be the same as the input shape.
The strings of the map. This sequence must be the same length as the 'cats_int64s' sequence
cats_strings
The integers of the map. This sequence must be the same length as the 'cats_strings' sequence.
cats_int64s
_Unused
A string to use when an input integer value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
default_string
An integer to use when an input string value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
default_int64
CategoryMapper
A dictionary.
A 1-D tensor holding values from the input dictionary.
The input must be a map from strings or integers to either strings or a numeric type. The key and value types cannot be the same.
map(string, int64)
map(int64, double)
map(string, float)
map(string, double)
The output will be a tensor of the value type of the input map. It's shape will be [1,C], where C is the length of the input dictionary.
A string vocabulary array.<br>One and only one of the vocabularies must be defined.
string_vocabulary
An integer vocabulary array.<br>One and only one of the vocabularies must be defined.
int64_vocabulary
DictVectorizer
An ordered collection of tensors, all with the same element type.
The output array, elements ordered as the inputs.
The input type must be a tensor of a numeric type.
The size of each input in the input list
inputdimensions
FeatureVectorizer
Data to be processed.
Imputed output data
The input type must be a tensor of a numeric type, either [N,C] or [C]. The output type will be of the same tensor type and shape.
Value(s) to change to
imputed_value_floats
A value that needs replacing.
replaced_value_float
Value(s) to change to.
imputed_value_int64s
replaced_value_int64
Imputer
Label encoder has only one input.
Label encoder has only one output.
keys_strings
keys_int64s
keys_floats
Only one of keys_*'s can be set in label encoder.
Input type is not string tensor but key_strings is set
Input type is not int64 tensor but keys_int64s is set
Input type is not float tensor but keys_floats is set
values_strings
values_int64s
values_floats
Only one of values_*'s can be set in label encoder.
Input data. It can be either tensor or scalar.
Output data.
The input type is a tensor of any shape.
Output type is determined by the specified 'values_*' attribute.
A list of strings. One and only one of 'keys_*'s should be set.
A list of ints.
A list of floats.
A list of strings. One and only one of 'value_*'s should be set.
A string.
An integer.
A float.
default_float
LabelEncoder
classlabels_strings
classlabels_ints
intercepts
Input's shape should be 1D or 2D
Data to be classified.
Classification outputs (one class per example).
Classification scores ([N,E] - one score for each class and example
The input must be a tensor of a numeric type, and of of shape [N,C] or [C]. In the latter case, it will be treated as [1,C]
The output will be a tensor of strings or integers.
A collection of weights of the model(s).
coefficients
A collection of intercepts.
Indicates whether to do OvR or multinomial (0=OvR is the default).
multi_class
Class labels when using string labels. One and only one 'classlabels' attribute must be defined.
Class labels when using integer labels. One and only one 'classlabels' attribute must be defined.
Indicates the transform to apply to the scores vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
post_transform
LinearClassifier
Data to be regressed.
Regression outputs (one per target, per example).
The input must be a tensor of a numeric type.
Indicates the transform to apply to the regression output vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Weights of the model(s).
Weights of the intercepts, if used.
The total number of regression targets, 1 if not defined.
targets
LinearRegressor
Data to be encoded, a tensor of shape [N,C] or [C]
Encoded output data
One of 'MAX,' 'L1,' 'L2'
Normalizer
Data to be encoded.
Encoded output data, having one more dimension than X.
List of categories, ints.<br>One and only one of the 'cats_*' attributes must be defined.
List of categories, strings.<br>One and only one of the 'cats_*' attributes must be defined.
If true and category is not present, will return all zeros; if false and a category if not found, the operator will fail.
OneHotEncoder
Data to be scaled.
Scaled output data.
First, offset by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.
Second, multiply by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.<br>Must be same length as 'offset'
Scaler
Class scores (one per class per example), if prob_a and prob_b are provided they are probabilities for each class, otherwise they are raw scores.
The input must be a tensor of a numeric type, either [C] or [N,C].
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used. Its size will match the bactch size of the input.
LINEAR
The kernel type, one of 'LINEAR,' 'POLY,' 'RBF,' 'SIGMOID'.
kernel_type
List of 3 elements containing gamma, coef0, and degree, in that order. Zero if unused for the kernel.
kernel_params
vectors_per_class
support_vectors
First set of probability coefficients.
prob_a
Second set of probability coefficients. This array must be same size as prob_a.<br>If these are provided then output Z are probability estimates, otherwise they are raw scores.
prob_b
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Class labels if using string labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
Class labels if using integer labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
SVMClassifier
Regression outputs (one score per target per example).
The input type must be a tensor of a numeric type, either [C] or [N,C].
Chosen support vectors
Flag indicating whether the regression is a one-class SVM or not.
one_class
Support vector coefficients.
The number of support vectors.
n_supports
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
SVMRegressor
Input of shape [N,F]
N, Top class for each point
The class score for each class, for each point, a tensor of shape [N,E].
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used.
Tree id for each node.
nodes_treeids
Node id for each node. Ids may restart at zero for each tree, but it not required to.
nodes_nodeids
Feature id for each node.
nodes_featureids
Thresholds to do the splitting on for each node.
nodes_values
Popularity of each node, used for performance and may be omitted.
nodes_hitrates
The node kind, that is, the comparison to make at the node. There is no comparison to make at a leaf node.<br>One of 'BRANCH_LEQ', 'BRANCH_LT', 'BRANCH_GTE', 'BRANCH_GT', 'BRANCH_EQ', 'BRANCH_NEQ', 'LEAF'
nodes_modes
Child node if expression is true.
nodes_truenodeids
Child node if expression is false.
nodes_falsenodeids
For each node, define what to do in the presence of a missing value: if a value is missing (NaN), use the 'true' or 'false' branch based on the value in this array.<br>This attribute may be left undefined, and the defalt value is false (0) for all nodes.
nodes_missing_value_tracks_true
The id of the tree that this node is in.
class_treeids
node id that this weight is for.
class_nodeids
The index of the class list that each weight is for.
class_ids
The weight for the class in class_id.
class_weights
classlabels_int64s
Indicates the transform to apply to the score. <br> One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
Base values for classification, added to final class score; the size must be the same as the classes or can be left unassigned (assumed 0)
base_values
TreeEnsembleClassifier
N classes
Node id for each node. Node ids must restart at zero for each tree and increase sequentially.
Child node if expression is true
Child node if expression is false
For each node, define what to do in the presence of a NaN: use the 'true' (if the attribute value is 1) or 'false' (if the attribute value is 0) branch based on the value in this array.<br>This attribute may be left undefined and the defalt value is false (0) for all nodes.
The id of the tree that each node is in.
target_treeids
The node id of each weight
target_nodeids
The index of the target that each weight is for
target_ids
The weight for each target
target_weights
The total number of targets.
n_targets
Defines how to aggregate leaf values within a target. <br>One of 'AVERAGE,' 'SUM,' 'MIN,' 'MAX.'
aggregate_function
TreeEnsembleRegressor
The input values
The output map
The output will be a sequence of string or integer maps to float.
seq(map(string, float))
seq(map(int64, float))
The keys when using string keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
The keys when using int keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
ZipMap
Input data.
The input type must be a tensor of integers or strings, of any shape.
The output type will be a tensor of strings or integers, and will have the same shape as the input.
A list of labels.
classes_strings
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\traditionalml\old.cc
 target=
 source=
Mismatched type:
Mismatched tensor element type:
Mismatched sparse tensor element type:
source sequence type missing element type.
target sequence type missing element type.
ConstantFill
==> Context: 
 is required to be non-empty.
value_info
' of 
Field '
 is required but missing.
elem_type
key_type
value_type
Unrecognized type value case (value_info name: 
data_type
) to UNDEFINED is not allowed
setting data_type field (tensor name: 
float_data
int32_data
string_data
int64_data
raw_data
double_data
uint64_data
) is stored externally and should not have data field.
Data of TensorProto ( tensor name: 
, but it doesn't exist or is not accessible.
) should be stored in 
) is stored externally but doesn't have a location.
TensorProto ( tensor name: 
) is 0-element but contains data!
TensorProto (tensor name: 
) should contain one and only one value field.
) should not be stored in raw_data field
STRING data (tensor name: 
' instead of '
' should be stored in field '
values of data_type '
Unrecognized data_type (tensor name: 
 values, but NNZ is 
) has 
Sparse tensor indices (
] out of range [0, 
) index value at position [
Sparse tensor (
] not in sorted order.
) first dimension size does not equal NNZ.
) second dimension size does not match rank of tensor.
] out of range.
] not in lexicographic sorted order.
sparse_tensor_proto
) must have rank 1.
Sparse tensor values (
) must have a dense-rank > 0
) dimensions are not positive.
) must have INT64 type.
) must have rank 1 or 2.
) has no index values.
type field and data field mismatch in attribute 
) should not contain more than one value field.
Attribute (name: 
) should refer to attribute in parent node.
op_type
) has zero input and zero output.
, type: 
NodeProto (name: 
Warning: Checker does not support models with experimental ops: 
No opset import for domain '
 with domain_version of 
No Op registered for 
 is deprecated in domain_version of 
Op registered for 
 OpType: 
Bad node spec for node. Name: 
graph
' has been used as graph input names multiple times.
Graph must be in single static assignment (SSA) form, however '
Tensor initializers must have a non-empty name
 initializer name is not unique
 in initializer but not in graph input
Sparse tensor initializers must have a non-empty name
 sparse initializer name is not unique across initializers and sparse_initializers
 is not output of any previous nodes.
name: 
' of node: 
Nodes in a graph must be topologically sorted, however input '
' has been used as output names multiple times.
 already exists.
Data for input  
optional_type
opaque_type
sparse_tensor_type
NOT_SET
 inferred=
type case mismatch. existing=
type case unsupported. existing=
type case unsupported for symbolic shape inference. inferred=
 models with experimental operators: 
Warning: Shape inference does not support
. No schema registered for this operator.
Warning: Unsupported operator 
Shape inference error(s): 
Container for generated shape data cannot be nullptr when enable_data_propagation option is set.
 were provided
 inputs but 
Graph has 
, node name: 
(op_type:
Inferred elem type differs from existing elem type: (
Inferred shape and existing shape differ in rank: (
Inferred shape and existing shape differ in dimension 
unk__
) is not equal to the existing dim value (
Dimension value inferred (
Number of elements of input 'sizes' must be same as rank of input 'X'
Input 'sizes' must have int64 element type.
Number of elements of input 'scales' must be same as rank of input 'X'
Input 'scales' must have float element type.
FLOATFLOATSGRAPHGRAPHSINTINTSSPARSE_TENSORSPARSE_TENSORSSTRINGSTRINGSTENSORTENSORSTYPE_PROTOTYPE_PROTOSUNDEFINED
DEFAULTEXTERNAL
BFLOAT16BOOLCOMPLEX128COMPLEX64DOUBLEFLOATFLOAT16INT16INT32INT64INT8STRINGUINT16UINT32UINT64UINT8UNDEFINED
IR_VERSIONIR_VERSION_2017_10_10IR_VERSION_2017_10_30IR_VERSION_2017_11_3IR_VERSION_2019_1_22IR_VERSION_2019_3_18IR_VERSION_2019_9_19IR_VERSION_2020_5_8_START_VERSION
EXPERIMENTALSTABLE
onnx.AttributeProto
onnx.ValueInfoProto
onnx.NodeProto
onnx.TrainingInfoProto
onnx.ModelProto
onnx.StringStringEntryProto
onnx.TensorAnnotation
onnx.GraphProto
onnx.TensorProto.Segment
onnx.TensorProto
onnx.SparseTensorProto
onnx.TensorShapeProto.Dimension
onnx.TensorShapeProto
onnx.TypeProto.Tensor
onnx.TypeProto.Sequence
onnx.TypeProto.Map
onnx.TypeProto.Optional
onnx.TypeProto.SparseTensor
onnx.TypeProto.Opaque
onnx.TypeProto
onnx.OperatorSetIdProto
onnx.FunctionProto
MAPOPTIONALSEQUENCESPARSE_TENSORTENSORUNDEFINED
MAPOPTIONALSEQUENCESPARSE_TENSORTENSORUNDEFINED
onnx.SequenceProto
onnx.MapProto
onnx.OptionalProto
OHG G
>@>p>
ProcessInfo
UTCReplace_AppSessionGuid
PartA_PrivTags
schemaVersion
runtimeVersion
isRedist
SessionCreationStart
UTCReplace_AppSessionGuid
PartA_PrivTags
EvaluationStop
EvaluationStart
SessionCreation
UTCReplace_AppSessionGuid
PartA_PrivTags
schemaVersion
sessionId
irVersion
OrtProgrammingProjection
modelProducerName
modelProducerVersion
modelDomain
usefp16
domainToVersionMap
modelGraphName
modelMetaData
loadedFrom
executionProviderIds
RuntimeError
UTCReplace_AppSessionGuid
PartA_PrivTags
schemaVersion
hResult
sessionId
errorCode
errorCategory
errorMessage
function
RuntimePerf
UTCReplace_AppSessionGuid
PartA_PrivTags
schemaVersion
sessionId
totalRuns
totalRunDuration
ExecutionProviderEvent
UTCReplace_AppSessionGuid
PartA_PrivTags
adapterLuidLowPart
adapterLuidHighPart
Microsoft.ML.ONNXRuntime
D:\a\_work\1\s\onnxruntime\build\Windows\RelWithDebInfo\RelWithDebInfo\Microsoft.CognitiveServices.Speech.extension.onnxruntime.pdb
.text
.text$di
.text$mn
.text$mn$00
.text$x
.text$yd
.idata$5
.00cfg
.CRT$XCA
.CRT$XCL
.CRT$XCU
.CRT$XCZ
.CRT$XDA
.CRT$XDZ
.CRT$XIA
.CRT$XIZ
.CRT$XLA
.CRT$XLC
.CRT$XLD
.CRT$XLZ
.CRT$XPA
.CRT$XPZ
.CRT$XTA
.CRT$XTZ
.gfids
.giats
.rdata
.rdata$T
.rdata$r
.rdata$voltmd
.rdata$zETW0
.rdata$zETW1
.rdata$zETW2
.rdata$zETW9
.rdata$zzzdbg
.tls$
.tls$ZZZ
.xdata
.xdata$x
.edata
.idata$2
.idata$3
.idata$4
.idata$6
.data
.data$r
.data$rs
.pdata
_RDATA
.rsrc$01
.rsrc$02
@08~f
@08~f
"^&^*^.00V4J
FVH$Ja
0vFVH
NV8Xm
Z6\"^
NLP4R2
.b0@2
<R>R@
"2$^(H*
"2$^(H*
>F@.B
"2$^(H*
<F>.@
"4$"&$((**"|
H ,"&
&H(,*$,*.
BHD,F&H*JH>
Z`\(Z|>zL
N(^(`
^> NNP6R4
8H:,<&>*@&8
(8*",$.(&
486"8$:(2
`&l(:*x,*.
:$<T>
"X$,&
 F".$
`08~f
HEITI
$b&,(
 b.* 
0"P$"&}
j d"6
$n&v$D(
DFF.H
$X&`(
**,40
2X4X6`8
:*<4@
BXDXFpHpJ`L
N0P4TDV`T^X`TPZ`T^\`T^^`T^``T^b`T^d`T^f`T^h`T^j`T^l`T^n`T^p`T^r`T^t`T^v`T^x`T^z`Th|`T
F .",
:j<<@^B
DxFPH(F
DvFNH(FXB
NNP(N
B`DdF(H
B`DdF(H
:j<:@^B
FRH(F
BhDfF(H\B
D~FPH(FHB
D~FPH(F<B
LvNBL
BjDhF(HfB
FRH(F
PRRNT6X
Zz\P^(\
Zz\N^(\^X
drf~h
jrl~nzpnrjvM
XtZl\N^(\
vhxfz(|
vnxfz(|
X^Zd\(`
BhDfF(J
BhDfF(J
*X,,.
!!B`C
$4&"($*("
XjZ^^
`zbRd(bE
`tbPd(b
^|f>h
^^`fb(d
^hj>l
^^`fb(df^
`tbPd(b
^|jFl
^^`fb(d
^vnhp|r
thvXx6|y
^^`fb(d
8j:X>
B\D,F
H$J(B
NdPRR
T|VRX
Zd\0`
dhf|hhjhlXp
r~tJv(t
phr`t(v
pnr`t(v
(X*:.^0
4h688":$<(4
2~4d68D"F <(4P0
2~4d68H"J <(4
N|PvRhTRV0Z
\~^P`(^
\~^P`(^
Zvbhd|fvhhj|lvnhp|rhthvXx6|
0h2z486"> @(<
"t$8&"($*("
:X<:@
DtF8H"J$L(D!
\R^4b
fRh(f
bhdff(h
jhn`p(r
jhn`p(r
vhz`|(~~v8
vhz`|(~Xv
z~|J~(|Fv
z~|J~(|
vhz`|(~Pv
z~|J~(|
vhz`|(~
@XB,D
<l>p@,B
<l>p@,B
.p0p2,4
 p$v&,(
 p$v&,(
"^$,,
p v",$
! B`C
 j"R&V(
*z,\.40"2$4(,
8l:|<
DlFRJ
LtNPP(N
TtVPX(V
TtVPX(VJR
TtVPX(V
\v^R`(^
fhhjj
lhnjp
rvtjvXx:|
j X$-
*8,".$0((1
(8*"2$4(0
*86"8$0((@$
DzFjH
JzLjN
VlXjZj^
bRd(b1
^l`hb(dr^
bRd(b>^
bRd(b
bRd(b`^
bRd(bn^y
h^jplXnXp$r~p
h.tdh-
^l`hb(d
(8*":$<(0
"t$X&4("* ,($
"t$d&4("* ,($
6"8(:
.F042
&@((*$,
.b2^4
@n6NHRJ
:L<.>,6V:
 F"N$A
6`>V@">
V&X|Z
Dh\"D
"^$,&
"^$,0
n t",$
6^8X:
B`D4H
N8P"R$T(LPH
LRT(LRH
LRT(L|H
LRT(L
HnJhL(T
HnJhL(T
a$B`C
A#B`C
$~&F(
*~,b.
0~2b4
6~8f:
<`>2B
FjH~J
LjN~P
RjT~V
XjZ~\
^j`~b
djf~h
jjl~n
pjr~tpvjxf|
0X2,:
8"04,
0PB(0X,
0X2,>
,j.n0,2
6"8r,
0PB(0
,l.f0(B6,
0PB(0\,
0PB(0*,.D
.~0PB(0X,
.~0PB(0
,h.f0(B
,h.f0(B
 8""$$&((
 ^",$
 ^",2
 ^",:
 `"V$(&p(
(V*V,(.
2~4"2
6*806r
z:t<t>t@.B
p6p6>
p p"2$
*l,b.J0
2p426
<l>b@JBzP!
 z"X$f"m
&R(Z,T.
$V&0*
<p>p@2B|@u
 t"n$B&
8J:j<*>FT
*$,H:
$B&r(
`60J>
`6 R>
`6 R>
8F:@<
8F:.<,6
:F<N6(8
8F:.<,6D8
8F:.<,6
"d$:&h*
*L,..,"(
p6@k>
@6@n>
D6F:>
F$H|>
@FBLD$
6F8L:
&J*2,
6L:n<
:D>nBpD
.L0422
"($t&*$q
.L0422
 "I-K
< ,"&
l z"4$*
2L4.6,&
A"B`C
.40"2$4
,n(H6
"L$4&2
 H".$,
z X"f 4
8,$.$0R2
@hJ(@
@$L(J
@hJ@@.4~>
@hJNN
8L:@<
BLD@F"4
8L:@<"@
BLD@F
2D*04
*42"4$6(8t*E
 H>4@^B:D*B
 d(>*<,4:e
FLHLJ
,L.L0( 
"L$L&
0H2,4"6P866U
>n@tB
:"N&F(.*
@HB,D&F,>
L$N.P
 N"6$4,
>H@,B&D,<
J$L:N
x`vL,zz
*F,Z 6$
!IB`C
AIB`C
.L0Z&6(
2~4H6x8
> @(B
JtL$N\J
6ddlf(h
(H*4,2F
$B&,$)
*B,**
.D0".9
("2L4
 |"t$(&"($*
0@2f0T4
^:`><@\D
& (.*2,R.
lzn~p$r
vHxLz$.
0H2442:xBHJ4L2@$B$D
FHHZ^l`Hh4j2^$`$b
dHfZ:(>
ZH\Z|n~
N$P$R*T
b0d,f0h(j0l.n
, &"&$&"
(z*",
0F2442
L"H$.&,.L"H$.&,8
4 ""$$(&B
a|:`C
 f"B 
&D(^$
*f,B*
0f2B0
6f8B6
<f>B<
BfDBB
HfJBH
NfPBN
TfVBT
Zf\BZ
`fbB`
ffhBf
lfnBl
rftBr
xFz^v
|f~B|
 R"8  $
&R(8& *
,R.8, 0
!?:`C
A%:`C
a':`C
!4<`C
A6<`C
a8<`C
*p,^.
0p2^4
>p@^B
DpF^H
RtTpVbX~Zp\^`
jpl^n
xpz^|
(Z*~,
:p<j>
FZH~J
XpZj\
hpjpl^n
pprjt
(X*R,
6p8^:
<p>^@
JpL^N
PXRXT
^p`^bddXfRh
"N$p&%
*:,$*
0:2$0
6 8H:
<:>*<
BLD4F
(~*x,
<"DZ:
\B^.\
`Xb(`
dNf.d}
hHj.h
T$lVn
T$pVr
vLx.v
zP|.z
NtDT)
:0<~>p:F(
(.@.B
vLPNI
"L$4&2(
&V(4&t,0*
.V04.t402
6N826 :
P8@HR 
 N"8  $)
&N(8& *Z,<*1
.N08. 2Z4<21
6N886 :
<N>8< @
BND8B F
HNJ6H L
PNR8P T
VNX<V Z
,6.*0
@HPX`
},0&?
.N*>(M
40Z2(4"6:8X:
>X@RBtLNH>F
h0VN*P"R:TXV|XRZl\`^L`tnNj4h>f
rr*t"v:xXz
&X(R*l,X.R0
8V:.<*> @bBxDZF^HXJRVi
XNT6R>P
$0Z"\,^^`tbRdbf`hPjrvPr4p>n
xVz*|"~,
AN<`C
*v@(?
AJ>@(?
!5<`C
A7<`C
&v@)?
AF>@)?
a9<`C
AJ>@(?
AF>@)?
\ z"n$X.
4n6^8
:n<^>
HnJ^L
NnP^R
XjZ,\"^,`Xb
hnj^l
AN<`C
*v@(?
AJ>@(?
!5<`C
A7<`C
&v@)?
AF>@)?
a9<`C
AJ>@(?
AF>@)?
\ z"n$X.
4n6^8
:n<^>
HnJ^L
NnP^R
XjZ,\"^,`Xb
hnj^l
8@HR`C
(p*X,
.X0R2
<p>X@
BXDRF
R4P:N4L:"4 :
AS8@HPX`ht`C
7v`8?
!B<`C
AD<`C
aF<`C
+vP9?
&j(4*J,
0^2~4l6j8
BjD4F<H
L^N~PlRjT
bld^f~hTj^l
vXx~zl|j~
A>P5?
A>P5?
=> 7?
=> 7?
" :"^$
&^(~*n,^.
FHJ<L<N<P
\.^8` bpd0f*h jbl0n*p r|t4v*x 
&N"> a
*p,X.j0p2j4-
b(v<J>h@hBzDXF~HpJdP
RNN6L>
*pTXVdX^Z`\tbJ^:
n V"|$X&R4
:p<X>
@XB^D
L4J:44240>.
A6:`C
A6B`C
B>`=?
F>0>?
F>0>?
(**",,.f0*2"4,6^<
BXDXF
\p^^`
bpd^f
tpv^x
 v@??
AK>@??
AG:`C
A?>P@?
!7<`C
AG:`C
A?>P@?
AO%3`
(**",,.f0*2"4,6^<
BpD^F
\p^^`
bpd^f
tpv^x
M!pB?
m1pB?
M#pB?
M9pB?
MCpB?
=2pE?
.N*>(e
40`2(4"6:8X:
>X@LBvHND>(e
40`2(4"6:8XJ
NXPLRvXNT>(
Zp\X^b`XbLd|jNf:
|0rn.p8r t\v
xjz\|^~`
@0\Z(\X!
v0dZ(\X=
rZ(\XY
lZ(\X
(H,2.20:2
!G<`C
Av J?
o> J?
AI<`C
aK<`C
=vPK?
k>PK?
"vpL?
 v@M?
!X<`C
AZ<`C
a\<`C
9v@O?
g>@O?
A):`C
o> J?
k>PK?
g>@O?
z n"b,
2n4b6
8n:b<
BxD0F"H,J\L
RnTbV
fnhbj
lnnbp
zn|b~
j j"j$j&j(j*j,j.j0j2j4j6j8j:j<d>6
8@HR`C
8@HPX`,
8@HPX`hvpU?
J ((4(6
F"T0V0X"ZJ\
h:lJp
(6P]?
Xfp]?
(6p]?
(6P]?
XfP]?
Microsoft.CognitiveServices.Speech.extension.onnxruntime.dll
OrtGetApiBase
OrtSessionOptionsAppendExecutionProvider_CPU
FindClose
FindFirstFileW
FindNextFileW
GetLastError
MultiByteToWideChar
WideCharToMultiByte
api-ms-win-core-processenvironment-l1-1-0.dll
api-ms-win-core-file-l1-1-0.dll
api-ms-win-core-errorhandling-l1-1-0.dll
api-ms-win-core-string-l1-1-0.dll
?_Xlength_error@std@@YAXPEBD@Z
_Mtx_init_in_situ
_Mtx_destroy_in_situ
_Mtx_lock
_Mtx_unlock
?_Throw_C_error@std@@YAXH@Z
??0?$basic_streambuf@DU?$char_traits@D@std@@@std@@IEAA@XZ
??1?$basic_streambuf@DU?$char_traits@D@std@@@std@@UEAA@XZ
?_Pninc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@IEAAPEADXZ
??1?$basic_ios@DU?$char_traits@D@std@@@std@@UEAA@XZ
??0?$basic_ios@DU?$char_traits@D@std@@@std@@IEAA@XZ
??0?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAA@PEAV?$basic_streambuf@DU?$char_traits@D@std@@@1@_N@Z
??1?$basic_ostream@DU?$char_traits@D@std@@@std@@UEAA@XZ
?_Lock@?$basic_streambuf@DU?$char_traits@D@std@@@std@@UEAAXXZ
?_Unlock@?$basic_streambuf@DU?$char_traits@D@std@@@std@@UEAAXXZ
?imbue@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAXAEBVlocale@2@@Z
?setbuf@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAPEAV12@PEAD_J@Z
?showmanyc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAA_JXZ
?sync@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAHXZ
?uflow@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAHXZ
?xsgetn@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAA_JPEAD_J@Z
?xsputn@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAA_JPEBD_J@Z
?_Xout_of_range@std@@YAXPEBD@Z
?write@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@PEBD_J@Z
?read@?$basic_istream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@PEAD_J@Z
?uncaught_exception@std@@YA_NXZ
?sputc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHD@Z
?sputn@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAA_JPEBD_J@Z
?setstate@?$basic_ios@DU?$char_traits@D@std@@@std@@QEAAXH_N@Z
?_Osfx@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAXXZ
?flush@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@XZ
?_Xbad_alloc@std@@YAXXZ
?_Getcvt@_Locinfo@std@@QEBA?AU_Cvtvec@@XZ
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@P6AAEAVios_base@1@AEAV21@@Z@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@_K@Z
?_Xbad_function_call@std@@YAXXZ
??0?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@IEAA@XZ
??1?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
?sputc@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@QEAAG_W@Z
?sputn@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@QEAA_JPEB_W_J@Z
?_Pninc@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@IEAAPEA_WXZ
??1?$basic_ios@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
?setstate@?$basic_ios@_WU?$char_traits@_W@std@@@std@@QEAAXH_N@Z
??0?$basic_ios@_WU?$char_traits@_W@std@@@std@@IEAA@XZ
?_Osfx@?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAXXZ
?flush@?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV12@XZ
??0?$basic_iostream@_WU?$char_traits@_W@std@@@std@@QEAA@PEAV?$basic_streambuf@_WU?$char_traits@_W@std@@@1@@Z
??1?$basic_iostream@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
?_Lock@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@UEAAXXZ
?_Unlock@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@UEAAXXZ
?imbue@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAXAEBVlocale@2@@Z
?setbuf@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAPEAV12@PEA_W_J@Z
?showmanyc@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAA_JXZ
?sync@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAHXZ
?uflow@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAGXZ
?xsgetn@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAA_JPEA_W_J@Z
?xsputn@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAA_JPEB_W_J@Z
MSVCP140_APP.dll
_purecall
__std_terminate
__std_exception_copy
__std_exception_destroy
_CxxThrowException
__CxxFrameHandler4
memcpy
memmove
memset
memchr
memcmp
__C_specific_handler
__std_type_info_destroy_list
VCRUNTIME140_APP.dll
VCRUNTIME140_1_APP.dll
_invalid_parameter_noinfo_noreturn
abort
__acrt_iob_func
fflush
__stdio_common_vfprintf
__stdio_common_vsprintf
_errno
strtod
_dclass
_fdclass
strerror
calloc
_close
_read
_write
ceilf
_initterm
_initterm_e
_callnewh
malloc
_seh_filter_dll
_configure_narrow_argv
_initialize_narrow_environment
_initialize_onexit_table
_register_onexit_function
_execute_onexit_table
_crt_atexit
_cexit
api-ms-win-crt-runtime-l1-1-0.dll
api-ms-win-crt-stdio-l1-1-0.dll
api-ms-win-crt-convert-l1-1-0.dll
api-ms-win-crt-string-l1-1-0.dll
api-ms-win-crt-math-l1-1-0.dll
api-ms-win-crt-heap-l1-1-0.dll
api-ms-win-crt-filesystem-l1-1-0.dll
InitOnceBeginInitialize
InitOnceComplete
ReleaseSRWLockExclusive
AcquireSRWLockExclusive
WakeAllConditionVariable
SleepConditionVariableSRW
QueryPerformanceCounter
GetCurrentProcessId
GetCurrentThreadId
GetSystemTimeAsFileTime
InitializeSListHead
api-ms-win-core-synch-l1-2-0.dll
api-ms-win-core-synch-l1-1-0.dll
api-ms-win-core-profile-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-0.dll
api-ms-win-core-sysinfo-l1-1-0.dll
api-ms-win-core-interlocked-l1-1-0.dll
GetEnvironmentVariableA
CreateDirectoryA
CreateDirectoryW
DeleteFileW
GetFileAttributesA
GetFileAttributesW
GetFileSizeEx
GetFinalPathNameByHandleW
ReadFile
RemoveDirectoryW
SetFilePointerEx
CreateFile2
IsDebuggerPresent
OutputDebugStringW
CloseHandle
RaiseFailFastException
HeapAlloc
HeapFree
GetProcessHeap
WaitForSingleObject
Sleep
GetCurrentThread
SetThreadDescription
GetSystemInfo
GetLogicalProcessorInformation
FreeLibrary
GetModuleFileNameA
GetProcAddress
SetThreadAffinityMask
FormatMessageA
FormatMessageW
LoadPackagedLibrary
WakeConditionVariable
GetCurrentProcessorNumber
PathCchRemoveBackslash
PathCchRemoveFileSpec
EventRegister
EventUnregister
EventSetInformation
EventWriteTransfer
GetSystemTimePreciseAsFileTime
api-ms-win-core-file-l1-2-0.dll
api-ms-win-core-debug-l1-1-0.dll
api-ms-win-core-handle-l1-1-0.dll
api-ms-win-core-errorhandling-l1-1-2.dll
api-ms-win-core-heap-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-3.dll
api-ms-win-core-libraryloader-l1-2-0.dll
api-ms-win-core-processtopology-obsolete-l1-1-0.dll
api-ms-win-core-localization-l1-2-0.dll
api-ms-win-core-libraryloader-l2-1-0.dll
api-ms-win-core-processthreads-l1-1-1.dll
api-ms-win-core-path-l1-1-0.dll
api-ms-win-eventing-provider-l1-1-0.dll
api-ms-win-core-sysinfo-l1-2-0.dll
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@H@Z
??0_Lockit@std@@QEAA@H@Z
??1_Lockit@std@@QEAA@XZ
_Xtime_get_ticks
_Query_perf_counter
_Query_perf_frequency
??Bid@locale@std@@QEAA_KXZ
?classic@locale@std@@SAAEBV12@XZ
?_Getgloballocale@locale@std@@CAPEAV_Locimp@12@XZ
?always_noconv@codecvt_base@std@@QEBA_NXZ
?_Getcat@?$ctype@D@std@@SA_KPEAPEBVfacet@locale@2@PEBV42@@Z
?widen@?$ctype@_W@std@@QEBA_WD@Z
?_Getcat@?$ctype@_W@std@@SA_KPEAPEBVfacet@locale@2@PEBV42@@Z
?in@?$codecvt@DDU_Mbstatet@@@std@@QEBAHAEAU_Mbstatet@@PEBD1AEAPEBDPEAD3AEAPEAD@Z
?out@?$codecvt@DDU_Mbstatet@@@std@@QEBAHAEAU_Mbstatet@@PEBD1AEAPEBDPEAD3AEAPEAD@Z
?unshift@?$codecvt@DDU_Mbstatet@@@std@@QEBAHAEAU_Mbstatet@@PEAD1AEAPEAD@Z
?_Getcat@?$codecvt@DDU_Mbstatet@@@std@@SA_KPEAPEBVfacet@locale@2@PEBV42@@Z
?getloc@ios_base@std@@QEBA?AVlocale@2@XZ
?getloc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEBA?AVlocale@2@XZ
?sbumpc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHXZ
?sgetc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHXZ
?snextc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHXZ
?_Init@?$basic_streambuf@DU?$char_traits@D@std@@@std@@IEAAXXZ
?imbue@?$basic_ios@DU?$char_traits@D@std@@@std@@QEAA?AVlocale@2@AEBV32@@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@F@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@_J@Z
??0?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAA@PEAV?$basic_streambuf@_WU?$char_traits@_W@std@@@1@_N@Z
??1?$basic_ostream@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
??6?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV01@I@Z
??0?$basic_istream@DU?$char_traits@D@std@@@std@@QEAA@PEAV?$basic_streambuf@DU?$char_traits@D@std@@@1@_N@Z
??1?$basic_istream@DU?$char_traits@D@std@@@std@@UEAA@XZ
?_Ipfx@?$basic_istream@DU?$char_traits@D@std@@@std@@QEAA_N_N@Z
??5?$basic_istream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@AEAF@Z
?get@?$basic_istream@DU?$char_traits@D@std@@@std@@QEAAHXZ
?_Fiopen@std@@YAPEAU_iobuf@@PEB_WHH@Z
?id@?$ctype@D@std@@2V0locale@2@A
?id@?$ctype@_W@std@@2V0locale@2@A
?id@?$codecvt@DDU_Mbstatet@@@std@@2V0locale@2@A
?widen@?$basic_ios@DU?$char_traits@D@std@@@std@@QEBADD@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@P6AAEAV01@AEAV01@@Z@Z
?put@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@D@Z
??0?$basic_iostream@DU?$char_traits@D@std@@@std@@QEAA@PEAV?$basic_streambuf@DU?$char_traits@D@std@@@1@@Z
??1?$basic_iostream@DU?$char_traits@D@std@@@std@@UEAA@XZ
?cerr@std@@3V?$basic_ostream@DU?$char_traits@D@std@@@1@A
?_Xinvalid_argument@std@@YAXPEBD@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@I@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@PEBX@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@_N@Z
_Thrd_hardware_concurrency
?_Syserror_map@std@@YAPEBDH@Z
?_Winerror_map@std@@YAHH@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@K@Z
??6?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV01@H@Z
?clear@?$basic_ios@DU?$char_traits@D@std@@@std@@QEAAXH_N@Z
_Thrd_id
??4?$_Yarn@D@std@@QEAAAEAV01@PEBD@Z
?_New_Locimp@_Locimp@locale@std@@CAPEAV123@AEBV123@@Z
?_Locimp_Addfac@_Locimp@locale@std@@CAXPEAV123@PEAVfacet@23@_K@Z
?_Init@locale@std@@CAPEAV_Locimp@12@_N@Z
?out@?$codecvt@_WDU_Mbstatet@@@std@@QEBAHAEAU_Mbstatet@@PEB_W1AEAPEB_WPEAD3AEAPEAD@Z
??0?$codecvt@_WDU_Mbstatet@@@std@@QEAA@_K@Z
??1?$codecvt@_WDU_Mbstatet@@@std@@MEAA@XZ
?_Decref@facet@locale@std@@UEAAPEAV_Facet_base@3@XZ
?_Incref@facet@locale@std@@UEAAXXZ
?id@?$codecvt@_WDU_Mbstatet@@@std@@2V0locale@2@A
?clog@std@@3V?$basic_ostream@DU?$char_traits@D@std@@@1@A
??0_Locinfo@std@@QEAA@PEBD@Z
??1_Locinfo@std@@QEAA@XZ
?_Getfalse@_Locinfo@std@@QEBAPEBDXZ
?_Gettrue@_Locinfo@std@@QEBAPEBDXZ
?c_str@?$_Yarn@D@std@@QEBAPEBDXZ
??0facet@locale@std@@IEAA@_K@Z
??1facet@locale@std@@MEAA@XZ
?id@?$numpunct@D@std@@2V0locale@2@A
__std_type_info_compare
__RTtypeid
__std_type_info_name
__current_exception
__current_exception_context
strncpy_s
terminate
strcmp
strncmp
_get_stream_buffer_pointers
fclose
fgetc
fgetpos
fputc
fread
fsetpos
_fseeki64
fwrite
setvbuf
ungetc
_lock_file
_unlock_file
wcsftime
_localtime64_s
tolower
strtoll
strtoull
localeconv
sqrtf
_fdsign
floorf
rintf
remainderf
floor
strnlen
_aligned_free
_aligned_malloc
bsearch
_strtoi64
ldexp
_invalid_parameter_noinfo
__stdio_common_vswprintf
__stdio_common_vsnprintf_s
_wsopen_s
_fstat64i32
_beginthreadex
_sopen_s
_difftime64
_gmtime64_s
_mktime64
isspace
_stat64i32
api-ms-win-crt-time-l1-1-0.dll
api-ms-win-crt-locale-l1-1-0.dll
api-ms-win-crt-utility-l1-1-0.dll
LocalFree
api-ms-win-core-heap-l2-1-0.dll
.?AVbad_array_new_length@std@@
.?AVbad_alloc@std@@
.?AVexception@std@@
.?AVFatalException@protobuf@google@@
.?AVOnnxRuntimeException@onnxruntime@@
.?AVNotImplementedException@onnxruntime@@
.?AU?$default_delete@VIExecutionProvider@onnxruntime@@@std@@
.?AV<lambda_78d2ff8fcf22c6166aa97abbb5fd0d75>@@
.?AV<lambda_6b9436f4089e82f5864d5365b56a5e02>@@
.?AV<lambda_3435a69bc2a4a58cf25c9601fa916799>@@
.P6AXPEAX@Z
.?AUException@Ort@@
.?AVlogic_error@std@@
.?AV<lambda_7afdd6f6db24c890469fd5278509941d>@@
.?AV<lambda_a4fe3bd39dcd0107f90455cb45c21429>@@
.?AV<lambda_ca87e505bf8a7e1f26579083c3683d94>@@
.?AVbad_cast@std@@
.?AVruntime_error@std@@
.?AVexception@detail@nlohmann@@
.?AVother_error@detail@nlohmann@@
.?AU?$default_delete@VCPUExecutionProvider@onnxruntime@@@std@@
.?AV<lambda_739930acb5d4a4b1d92f387c9190b820>@@
.?AV<lambda_73f4f6c8b9b724afe3a51b52c953b043>@@
.?AV<lambda_b32e5f2bc2fafd58a4afcda5e8537c65>@@
.?AV<lambda_90fa7e4386c5622637b0b1880f5ca8f3>@@
.?AV<lambda_73b1da0ad8cd1f5530ce77a072f70a46>@@
.?AU?$default_delete@VModel@onnxruntime@@@std@@
.?AV<lambda_c89e6783ea7ba65dd2bbca371d42018d>@@
.?AVout_of_range@std@@
.?AVout_of_range@detail@nlohmann@@
.?AVtype_error@detail@nlohmann@@
.?AVinvalid_iterator@detail@nlohmann@@
.?AVparse_error@detail@nlohmann@@
.?AVInferenceError@onnx@@
.?AVSchemaError@onnx@@
.?AV<lambda_b1b7fca51e482a233c6ad913e37a4670>@@
.?AV<lambda_79b1e3e4a047d410dc120a32d9f13caa>@@
.P6AXAEAUInferenceContext@onnx@@@Z
.?AV<lambda_6922b57be4edd39a89a7cea9e2ebb658>@@
.?AV<lambda_716d92b2455b6dca0a3e195a50699167>@@
.?AV<lambda_0fb4e93f4014e9a9ed52287648f86c91>@@
.?AV<lambda_3a80fca790cdb0fce14ddaedefa20351>@@
.?AV<lambda_519fe9cae569b1ad1c3f73288fa352d4>@@
.?AV<lambda_b35f6304ab9b91e067de16d773b507fb>@@
.?AV<lambda_ab7cc530eb49a3a15082dbc27eb613da>@@
.?AV<lambda_8fef7dbb6b3e81cda489ebe45ab449bb>@@
.?AV<lambda_d522df09ab9335db57f0cfc8c09d6630>@@
.?AV<lambda_daa97a08fba16356a015278e0f3ca1ed>@@
.?AV<lambda_888c8332848e83c225ef5f5587c3b38e>@@
.?AV<lambda_18dbcf0a6112b471cd3435637c32f0f8>@@
.?AV<lambda_de00575298e9c7ead3b243890c596395>@@
.?AV<lambda_598c6d249dbd14226af8e69fe738f910>@@
.?AV<lambda_7965ceabe5f45db89655ad0a7fd04cd6>@@
.?AV<lambda_dcbbb9aee7454d5a0feb975df66a7001>@@
.?AV<lambda_33c11271a908f4f215dd361ca0be165e>@@
.?AV<lambda_02dc3923ff80c6ae48f6f7d0552bad14>@@
.?AV<lambda_114e4f8c07e367eddb98d202f70e1c27>@@
.?AV<lambda_61a830e6f94472550f401a07bc054c29>@@
.?AV<lambda_adedb98ee19cb4d9a4a46a5fd17584b5>@@
.?AV<lambda_45c70c0d7c84bb60ff92f35bb1b93d0f>@@
.P6APEAVOpKernel@onnxruntime@@AEBVOpKernelInfo@1@@Z
.?AV<lambda_9ad4dd46fb7ebf522a3e85e715143745>@@
.?AV<lambda_a7f558f1dd0bc6dfbc34073d8010b2d2>@@
.?AU?$LeakyRelu@M@functors@onnxruntime@@
.?AU?$Relu@M@functors@onnxruntime@@
.?AU?$Relu@N@functors@onnxruntime@@
.?AU?$Sigmoid@M@functors@onnxruntime@@
.?AU?$Sigmoid@N@functors@onnxruntime@@
.?AU?$Tanh@M@functors@onnxruntime@@
.?AU?$Tanh@N@functors@onnxruntime@@
.?AU?$Abs@M@functors@onnxruntime@@
.?AU?$Abs@N@functors@onnxruntime@@
.?AU?$Abs@C@functors@onnxruntime@@
.?AU?$Abs@F@functors@onnxruntime@@
.?AU?$Abs@H@functors@onnxruntime@@
.?AU?$Abs@_J@functors@onnxruntime@@
.?AU?$Abs@E@functors@onnxruntime@@
.?AU?$Abs@G@functors@onnxruntime@@
.?AU?$Abs@I@functors@onnxruntime@@
.?AU?$Abs@_K@functors@onnxruntime@@
.?AU?$Floor@M@functors@onnxruntime@@
.?AU?$Reciprocal@M@functors@onnxruntime@@
.?AU?$Reciprocal@N@functors@onnxruntime@@
.?AU?$Sqrt@M@functors@onnxruntime@@
.?AU?$Sqrt@N@functors@onnxruntime@@
.?AU?$Exp@M@functors@onnxruntime@@
.?AU?$Exp@N@functors@onnxruntime@@
.?AV<lambda_95dd41682914710e4e8d31623057e7d3>@@
.?AV<lambda_acccfeb1e0041e26bf01c6097464f8c5>@@
.?AV<lambda_23a1bb0478ab7117c6dff4712434f02b>@@
.?AV<lambda_13046178b359e9c81742cfc406e97a28>@@
.?AV<lambda_e576f81a67738395c7b2b5774df9a9e6>@@
.?AV<lambda_9e7e87298c6741b4ec8ed0a6456adc35>@@
.?AV<lambda_f711efc9e33c8814de65d5fed61d7d7b>@@
.?AV<lambda_2e36b47c0b35a1b78ab3e2daaa7c5208>@@
.?AV<lambda_71a7fcf63fe63e7115dc2b32c5b3bde5>@@
.?AV<lambda_b51cf357ad6acfdf19263dcdcc3d9e57>@@
.?AV<lambda_de0690e164792b53d65bc1c1d051a1bb>@@
.?AV<lambda_04a053d9287fc146500ea7158f178603>@@
.?AV<lambda_eb610ec4c1ba2ee2f371c8f8541bff95>@@
.?AV<lambda_0eb1c82669a9a9098341056a7159769f>@@
.?AV<lambda_2e098a1c981ad02f01e4203abb39ccc3>@@
.?AV<lambda_cee3b4dd214c58e3bda89cd1d17f2a33>@@
.?AV<lambda_0fa14e0c348ed3017a38eb97cee09524>@@
.?AV<lambda_1516ce509842e7002886a3533819cb83>@@
.?AV<lambda_bf8e9a99ad926869def2c865754256b2>@@
.?AV<lambda_0d25eff6968fde540e49da9389ef8701>@@
.?AV<lambda_71c3b665db06d94a27cb005b95351a30>@@
.?AV<lambda_4d5e8f52539d7b1512da825129736cac>@@
.?AV<lambda_ea638a800acf5ef947d9895c94c04562>@@
.?AV<lambda_0385abfaef506cac5165d4d2b4c7ecc3>@@
.?AV<lambda_48813fe4537d3b115d868f99a1d25e0d>@@
.?AV<lambda_6a4c61f2b4befdad04c4488376ee8ba7>@@
.?AV<lambda_55c350adfde8ac6bd9a00204b24ba96a>@@
.?AV<lambda_59d8acbb35668d76553fcdb87d75be9b>@@
.?AV<lambda_2d5080a6f5d70d1027512848632ba44f>@@
.?AV<lambda_a5fbe571a251fb604ad2b480580cc76b>@@
.?AV<lambda_1ab7060bf709e6890ff53a0d80bb8cf5>@@
.?AV<lambda_0eb6d36a1e572b96903c06e9975f6aa3>@@
.?AV<lambda_55516238922eb666def71419d606fbee>@@
.?AV<lambda_5e986d8d54ac11e9537c3be07a635569>@@
.?AV<lambda_6dcde8f3935fcb410660f26c17172b9a>@@
.?AV<lambda_35b4ad7503a02f4a81944df838e5a579>@@
.?AV<lambda_c6a56551a85732582804098ed80c9fb0>@@
.?AV<lambda_3737cccf52f52050f818e2f26f25ffea>@@
.?AV<lambda_0736746d817c31c51fce207b52ada565>@@
.?AV<lambda_a983769408c484edae48835df1b06ffa>@@
.?AV<lambda_3569b04d379d95c345dffc147f7b94dd>@@
.?AV<lambda_82a82efebe07e5ae66c1dba7f7b1d0eb>@@
.?AV<lambda_349643858d539033044d1d649dec237b>@@
.?AV<lambda_305677983a5a9935addb16bf86321e8d>@@
.?AV<lambda_2fd31ca8bad4e5f142a2b5dfaff21801>@@
.?AV<lambda_7ad2abdb9d04286d775eb1928c7b7267>@@
.?AV<lambda_8e138b7d90664b9b073b07f3b9a88877>@@
.?AV<lambda_2a220a526da965cfd243a774de182b4f>@@
.?AV<lambda_9f3412b7c8b5e0fcfb6de75e19c2b20a>@@
.?AV<lambda_f80caf07313f1968c393099405f1b983>@@
.?AV<lambda_b012fd74acd70f9f2681f982ebb30583>@@
.?AV<lambda_d98acd54af1553e36890c98a685b0b7b>@@
.?AV<lambda_78dbc7f6c4933e58e34ef6be1a2ff7a7>@@
.?AV<lambda_fa9b4ded894aa76a12ed158813083596>@@
.?AV<lambda_270d1bd9fc78130be8d86e67c8f2ce05>@@
.?AV<lambda_81a02adb5ff83ba8ab585a5b795b05ad>@@
.?AV<lambda_116979593b1f64e5f55211fbc71db2d0>@@
.?AV<lambda_74ee6ad543f27310b05a4adf9a7be67d>@@
.?AV<lambda_4bec17fbab3a578476488dd028797422>@@
.?AV<lambda_5544c6f775d367a8b22497c127edf5eb>@@
.?AV<lambda_7fea215feaa82e3153664ad1fcc9f440>@@
.?AV<lambda_1eeda2d106d394e62d7fd8de2d23ad48>@@
.?AV<lambda_ceb94943cdad79a1266f9792313d7537>@@
.?AV<lambda_821f1e8c03e1c9965f7043e0547d5d5d>@@
.?AV<lambda_dacc60142a8d7fe115059ddfa024c65f>@@
.?AV<lambda_765516292e5be57b6b0a4f3fc843dfee>@@
.?AV<lambda_0aeb3b3202e2e34a7d6b98b623e6a327>@@
.?AV<lambda_b765106161737954a77d8a171216f44e>@@
.?AV<lambda_432c0fbab4ccd64eefecf0c6cfc89332>@@
.?AV<lambda_7cf9f7011f71cbc7a7f9f1e7bd9d9e44>@@
.?AV<lambda_5a5fc68c4068eb1de24eefff3968df88>@@
.?AV<lambda_f66e8601ea32ff7b33b7feafbaeaff41>@@
.?AV<lambda_f16edf5cdd807d431b24c8b686f2ae9b>@@
.?AV<lambda_02871f30a7ce451399da82fe783f932a>@@
.?AV<lambda_c60aa8fc78ffaf341f1d54c884d3f799>@@
.?AV<lambda_4ce86fe204f71dba32306ac9854bc206>@@
.?AV<lambda_ddd8493ebb39a49cc2643ed4269af499>@@
.?AV<lambda_e5db1942e7340c738b6ebdc5da682efe>@@
.?AV<lambda_1f8675d15ee5efaa8f5579945c6d118a>@@
.?AV<lambda_6c91c6f34bd8327dc22f6b7f8735fd5b>@@
.?AV<lambda_786b2ff03846fcfa21d00bf234deaff2>@@
.?AV<lambda_30e1101d7025e2d839d1daa9ac434cd1>@@
.?AV<lambda_115059020db09aa13bab825ad518034e>@@
.?AV<lambda_5820733bf712edf4856ad2454498e68c>@@
.?AV<lambda_e77a57374f1e055f8281ce5dd65e8ebd>@@
.?AV<lambda_6e3cb65d29853e95007cf81c805209f2>@@
.?AV<lambda_33215563a6aacb86deff746a6aa28a6c>@@
.?AV<lambda_e1a7abf114b955966097bd83c14de705>@@
.?AV<lambda_0251dfdaad61cfa5b2a46c99b78d27e8>@@
.?AV<lambda_9800a6d45ddc69dc425addf83da8e9e3>@@
.?AV<lambda_310ceee0e4c58a7a83d7d00319ed9410>@@
.?AV<lambda_42580b4f3e49f7dcfbf37d76233bd856>@@
.?AV<lambda_d48cb9baeb37d51a45fff2e006fd2ed3>@@
.?AV<lambda_e08a75ecff8a2a27b308be3f8dfddc66>@@
.?AV<lambda_3b97251de202434e86d007c33f9345a1>@@
.?AV<lambda_c646dd14edaacae64487e0b96ad575f5>@@
.?AV<lambda_f30a6117225d3cb8e4a11f826263726e>@@
.?AV<lambda_b9ad0ccbf56c00a46342640cba7cdc2c>@@
.?AV<lambda_d0c5713ac46ee06d27e6324a463b7bee>@@
.?AV<lambda_1fd04ff7ed408ca4ebed6e8107f19670>@@
.?AV<lambda_fd4f2bbf00caf507fea1cc6053ab984e>@@
.?AV<lambda_3f0ef66d0b0de67b55e854d697da2fff>@@
.P6A?AV?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@AEAUOrtValue@@_J1@Z
.P6A?AV?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@AEBUOrtValue@@_J1@Z
.?AV<lambda_0f619f3ff08e9e7659a763308b991cbe>@@
.?AV<lambda_138b12d2a19d941ed2e5665ad50fc6cb>@@
.?AV<lambda_4bd02c7b372889e26c922fb97a0c9ac3>@@
.?AV<lambda_bbed65651851398ae9e91eb41072a5f9>@@
.?AV<lambda_e7ad5c511f7f0ca88484948ab82410f1>@@
.?AV<lambda_86dd40270c718f299cd5113909653b31>@@
.?AV<lambda_a1b033c1238f74f04d136673bf3141a7>@@
.?AV<lambda_1cd5cfe6b76bb3ba1c53203d58a4eedd>@@
.?AV<lambda_72e83488395612e0f6a2602b726a187c>@@
.?AV<lambda_f55fed088cc6887bf534564a0809769f>@@
.?AV<lambda_c6728963f8bb91595df67d14c61fd8fa>@@
.?AV<lambda_b2b5b00a4ad3647a9a40b4f0dbb0745d>@@
.?AV<lambda_f2842527842316c8394eef731b560fea>@@
.?AV<lambda_a32f11f3f6edc3a900d9d34015d67705>@@
.?AV<lambda_cc7060560dae87f5475ce357b0faca8e>@@
.?AV<lambda_11002e821957b929b79aa649ecf0a381>@@
.?AV<lambda_ecc9b9120eb4793427a94169f5623a5b>@@
.?AV<lambda_7b13e0aa9183a7266252ed7dbdd54f99>@@
.?AV<lambda_038eb253b7f4e93118566e43dda81530>@@
.?AV<lambda_f8dbfaed9d55440bb15cbf009ac934a6>@@
.?AV<lambda_88cacdca8b660ada94d8f522e9f11bdd>@@
.?AV<lambda_33ab9233a6e2a6fe6c24d1963cbc3111>@@
.?AV<lambda_51f7b34ad2d14ff9bfb03559ccadc81f>@@
.?AV<lambda_1221b4097effa32a8dd388b4455dd2c1>@@
.?AV<lambda_88f211d79a091f6a481688e49635f453>@@
.?AV<lambda_8205a59784c4f81abae5636754370a87>@@
.?AV<lambda_03e7406b29b220fa131a6585ce48dcd2>@@
.?AV<lambda_2a3f9f19c48a100998729328075237dc>@@
.?AV<lambda_8ffce33af8696a7a42fa073f6875aacb>@@
.?AV<lambda_8f0d91faf2fd476a9a61179d9b72837d>@@
.?AV<lambda_ef1755d3dc9c2a6da40e08422cf4f664>@@
.?AV<lambda_95c74ffd32a4d994a62a191daf0fff27>@@
.?AV<lambda_337593ad4f874bae98bb3aa9ea22758d>@@
.?AV<lambda_ee954de93bf759bd8b1f4b4c9716ded3>@@
.?AV<lambda_e4fd1e1090be16100e1685f2f4877667>@@
.?AV<lambda_95aae9bbb822c713ca9677b3a07b3381>@@
.P6AMMMM@Z
.?AV<lambda_7d40fd05acaf32e2efee452cda59a5a2>@@
.?AV<lambda_3410038a349fbad62fb0cd42ca2fc595>@@
.?AV<lambda_0f2ad18a551e793a8bddf1de1dc21689>@@
.?AV<lambda_9cf24a11d7a47ec83a2235f766fd2a5c>@@
.?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AUMLFloat16@onnxruntime@@
.?AUBFloat16@onnxruntime@@
.?AV?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@
.?AV?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@
.?AV<lambda_d8a9ac16dd775f4bb1f670ae469711dc>@@
.?AV<lambda_d63de458c7355252fdf7dac6af546a6c>@@
.?AU?$default_delete@VIAllocator@onnxruntime@@@std@@
.?AU?$default_delete@VBFCArena@onnxruntime@@@std@@
.?AV<lambda_c9c94e4a7d5ae844e1f9d0f784dced0b>@@
.?AV<lambda_f7fefea6bfb8182e95c707a77e7f4a8f>@@
.?AV<lambda_535c714f3912f6e19812f86aced1c234>@@
.?AV<lambda_d77ac61f6238a68ec5589d982d5615ac>@@
.?AV<lambda_e1a8783767138f2900763c385a76ace5>@@
.?AV<lambda_31e4b4a2d49d229e0e58bbade49550ff>@@
.?AV<lambda_a641b8f1e5dd6615c70f20c32f700fce>@@
.?AV<lambda_50c8fe897e68e43b1818d88f70a689d9>@@
.?AV<lambda_0443539308e5b1117b55e6de227ed40c>@@
.?AV<lambda_46f2340c6974a9abf9bf427b63a5b9bc>@@
.?AV<lambda_c21643d1fb44758b12325da46a2d32c5>@@
.?AV<lambda_4404716c35945f1da6a07154c932397d>@@
.?AV<lambda_d5d62f4b858abcded92348c54a906570>@@
.?AV<lambda_1123ca3288c22333dcfbc6780e56f3b6>@@
.?AV<lambda_957302132dd7fea31b11af321304eee3>@@
.?AV<lambda_9de7ed3747c068fd694551112d802911>@@
.?AV<lambda_d2e668c941b29e0c58674cef7fa23f2c>@@
.?AV<lambda_2369f292b0f42fbecffef8359e85ebdc>@@
.?AV<lambda_c8a671616559eac778e178004f6bff38>@@
.?AV<lambda_76259788010337ce84c7523a6ac9ea2f>@@
.?AV<lambda_47e575137926bdb4c6da3cd254bbf347>@@
.?AV<lambda_56112085461402060b9fcd1813ada6f0>@@
.?AV<lambda_2314020bbb2bcb9dacfa0af3f7ebfa1d>@@
.?AV<lambda_f663e1cb5f92583d40a80c3711b532b4>@@
.?AV<lambda_854a3a76655e0ae1c9e2878289036568>@@
.?AV<lambda_c007df17e8115f08c5c6e2ce7e2201c0>@@
.?AV<lambda_e318b9a1ac6011cec45976779008bc1d>@@
.P6A?AVStatus@common@onnxruntime@@AEBVNode@2@AEAVGraph@2@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV56@AEBUResolveOptions@42@@Z
.?AUPriorityNodeCompare@onnxruntime@@
.?AV<lambda_0457fc55cb15f22bdcba75f54e0aa1c1>@@
.?AUNodeCompare@onnxruntime@@
.?AV<lambda_a047e4fa7a019da5da5dcb5093bd2da9>@@
.?AV<lambda_0a3d98e003a8310444f50c395f4ee870>@@
.?AV<lambda_56c3ac63d8a5c9a2d5ed84f082ef3cf5>@@
.?AV<lambda_5a471c0e331ecac30327327b781715bc>@@
.?AV<lambda_49ccb288b38bc111b2959e907bfdd8e7>@@
.?AV<lambda_70a7cafce997c1d7f642703664353219>@@
.?AV<lambda_9390aed8e2d795f49afe09f731079323>@@
.?AV<lambda_1cd6b5a2cebd273f7225f466512c43d5>@@
.?AV<lambda_814de60c7177af03b3ddc9e5c36d561a>@@
.?AV<lambda_7d629299b17d3241cda0057fa57cac3b>@@
.?AV<lambda_076f399d54601fd1059236c6a3813828>@@
.?AV<lambda_78621caf55ac03a4deb4ebb6d320ce8f>@@
.?AV<lambda_860b5cff89ff5f292872db2aaa19c52a>@@
.?AV<lambda_9e039da5781458d9f2e0d572b3cc8d18>@@
.?AV<lambda_bce84f647e20c57856d03ed6208ba6c9>@@
.?AV<lambda_9a36e00d72a5d737ec77f3dedc2d9072>@@
.?AV<lambda_29460ba72c9a9f61937f695b212c2385>@@
.?AV<lambda_e74921842af68f126d6a963647d9b662>@@
.?AV<lambda_9d8771d050eb3774da949f76ff7b2f7a>@@
.?AV<lambda_d49bbfb4942fd85adb6441f849e70bf8>@@
.?AV<lambda_e7f381725b47e4a5cf7649db595fbdf3>@@
.?AV<lambda_12dd4c4dcfd6c2d8effe6071c823bd43>@@
.?AV<lambda_104e5d4f3c346a5807a7db11389af990>@@
.?AV<lambda_2d30aee68f6d7fc70a227ffb90481678>@@
.?AV<lambda_98f67966096a245ba60cb535f4355420>@@
.?AV<lambda_26de9b5e95466f00708e3ae83a84c608>@@
.?AV<lambda_1c17b461588ff1b22a6f9497bff5b28b>@@
.?AV<lambda_6a32611970906250c6b47d8292ad00e7>@@
.?AV<lambda_423c7f4514cb0f580d17c1969d94ab4d>@@
.?AV<lambda_e15d10c4385b9adab7c3b2967076a5a0>@@
.?AV<lambda_893ec3becb9cd41d9efbc7eea98d41c9>@@
.?AV<lambda_cc4bc3c6927d9351454759e8077d0a48>@@
.?AV<lambda_71ef653055b00e102f19330e0f78a252>@@
.?AV<lambda_03c395c29c547f11867e2aba27fc822a>@@
.?AV<lambda_a9ad92a14c7791713a13c8f77948b581>@@
.?AV<lambda_4ee11195e6ac34d8802828c9de8931d7>@@
.?AV<lambda_3b79ba1930d9045b1d0a1c3e7b558aa7>@@
.P6A?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV01@0@Z
.?AV<lambda_bcef20d2b13b7b49fdebd823a7e734e1>@@
.P6AXAEAVOpSchema@onnx@@@Z
.?AV<lambda_581e172f6e6bf6d53a792d4f2adbb4c0>@@
.?AV<lambda_f0be09c6ec8e17e7ac33afa3db53ce78>@@
.?AV<lambda_680b87823779380f32485d5ed8cbcf84>@@
.?AV<lambda_c2fef1cfbd08e9e21bcb74b985df87e6>@@
.?AV<lambda_a7a0686f23e7f9337eaa10f069ee321b>@@
.?AV<lambda_c7733fbf1e7357c5a2b00aac2ede4865>@@
.?AV<lambda_2ed99b1b7f84cedcec6ea06ce6c01dc5>@@
.?AV<lambda_fc59cfd6180e7962f9dbfcf6d01970a3>@@
.?AV<lambda_b58abd66dfb794261458d2caeeba2a75>@@
.?AV<lambda_f9fcc66b14829c5756eb43c20bdf984b>@@
.?AV<lambda_7a5892277686c5fc70de8922cd945035>@@
.?AV<lambda_77bbe4874254ed84a312b5fa826a83d3>@@
.?AV<lambda_85740bb65c1a7256d972833e138b25dd>@@
.?AV<lambda_7361ba811d5ff92bf50e102c73312480>@@
.?AV<lambda_672376956558218714cb97c30f1f09fd>@@
.?AV<lambda_b3cbfd0276cf0ad6f3b58532d60f239f>@@
.?AV<lambda_14407bcf8cfc66db9a85fd2745a31d94>@@
.?AV<lambda_ef5c424a4193a85193eb7ea4c70aae69>@@
.?AV<lambda_a8b00e76dfe980214923eafc43926fd4>@@
.?AV<lambda_9289ae269610356b68d5c3f46e89bf66>@@
.?AV<lambda_08db83bf9ac8665fc4de47cb08668b85>@@
.?AV<lambda_b48de96003057f4b051b72f0b9baa2ee>@@
.?AV<lambda_539862c5b8039ccfff5acf2ed512ba97>@@
.?AV<lambda_3361a7c3c06ae8fda0091b29a15bc377>@@
.?AVResultException@wil@@
.?AVrange_error@std@@
.?AV<lambda_1c511d989171b0ae840c900d36af6cdf>@@
.?AV<lambda_ad8ca076531a0e62bdc4758313aec8ec>@@
.?AV<lambda_9cfecf4c86183e59841b56095d1dec6f>@@
.?AV<lambda_0b4cc153b058489c05500d0b394c47a0>@@
.?AV<lambda_429bffec90bbca49494510e27e518b79>@@
.?AV<lambda_5033badb7240167b30b90523bec68adf>@@
.?AV<lambda_3525a67688acab3a16549c70f50b343d>@@
.?AVValidationError@checker@onnx@@
.?AV<lambda_59d0c8449581e17e31aa5d36d4e1dfcc>@@
.?AVinvalid_argument@std@@
.?AV<lambda_5fe773ac1f878f81aadf16bc155901d0>@@
.?AV<lambda_abb9581c367ec240a8c0e5afd8181e99>@@
.?AV<lambda_be82f0d3082d1770e6fe9b6560ab180a>@@
.?AV<lambda_c6cc7a538d9c817426d2f4671032805a>@@
.?AV<lambda_33763db33c7430e0074fd25b65b4479f>@@
.?AV<lambda_0af4c846dd5af6632beb77ffbd6469c9>@@
.?AV<lambda_aec81523952d967a50c07470b5814993>@@
.?AV<lambda_5c5ac1f6c71d812ad45802a5c8ea5757>@@
.?AV<lambda_fd266a9166d0b10d35a0d8f14994daa2>@@
.?AV<lambda_2e20e62e8d812957e92321838accac54>@@
.?AV<lambda_22aeb0e20ec618f43aaa785665edaa1d>@@
.?AV<lambda_1249aa664b6dd8c7cf40d23fbaec080e>@@
.?AV<lambda_458163864faccd230ccf1ce10d3e187d>@@
.?AV<lambda_6f010deb824d03b6370449d6f782b9da>@@
.P6A_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@1@AEAVFunctionProto@1@@Z
.?AV<lambda_6f05a8b4f6851ad7c85a3a3bcb9b9104>@@
.?AV<lambda_2f4103e1c4a1773101a6c1f055d56df4>@@
.?AV<lambda_a4015e490e3e9078f9108a810d677815>@@
.?AV<lambda_c9fe283d46d2f293dcb8573f075d3809>@@
.?AV<lambda_d08789fec1ddb2ea31a7e42b01821aaa>@@
.?AV<lambda_43d76a454d7e446551a32b163679964a>@@
.?AV<lambda_9c03d71b3e2a72420d0112f6f3840dd4>@@
.?AV<lambda_27a631d2450c357a52927c1dfbd2efda>@@
.?AV<lambda_58fbb8df4116cc5ed49a05a90528c0bc>@@
.?AV<lambda_a345bf27d2a96610b3b006a123df813d>@@
.?AV<lambda_fbf4f22e77a262ac13623763b425fa95>@@
.?AV<lambda_922ea2af44b61076061b9738fd44abd8>@@
.?AV<lambda_fcf7b72cb8688ac639f6066c6f9347c9>@@
.?AV<lambda_fe5b044a59055ca66e7af958ee5f5bc3>@@
.?AV<lambda_51967558c7fd075e660195f4e6702ce2>@@
.?AV<lambda_8dc767ccba8e089e41f89b04cb108c10>@@
.?AV<lambda_7c61692eadeb4ccd34c8bb00529bfb83>@@
.?AV<lambda_6bb3fafba21860621ead2400f83d0ab0>@@
.?AV<lambda_655336b29940dd8dbdcd42ec2ee05996>@@
.?AV<lambda_0afff8b6c40408852605b1495798325e>@@
.?AV<lambda_9148a73a32272a5a33edca914c11c2a4>@@
.?AV<lambda_556d3d9e1da4d900ac4beace2594775f>@@
.?AV<lambda_fdb0134f4d01b5f723238dd45cc4059f>@@
.?AV<lambda_aa88e462824a3ef64606c92b2b205d10>@@
.?AV<lambda_6b0122b627329aed747a7281e017781a>@@
.?AV<lambda_4cd868df938477ea9946d2d55c43c695>@@
.?AV<lambda_727130accb380845b50f2c19a2b46d02>@@
.?AV<lambda_d3c7976f3f38539a50838a16dd62ccb2>@@
.?AV<lambda_6711c07c0f8ab9cb8e9a7125cbe3a01a>@@
.?AV<lambda_747f5a5054cea5042105b3988bb8e54a>@@
.?AV<lambda_7c393e0ced2515f63b0674de1e1229b1>@@
.?AV<lambda_6aeba50936d3f6c7b11f3c24b58165e0>@@
.?AV<lambda_006f042491572090b778a6887556c541>@@
.?AV<lambda_d2d693a490e9887da5a024c703dc8e3e>@@
.?AV<lambda_edad1d56ba5861f241ccb72d3e98208e>@@
.?AV<lambda_2cdbc5f873c2ce32c36481fab53d6870>@@
.?AV<lambda_4bfaa77b47cc3b72c0199e4158dcfdd3>@@
.?AV<lambda_3050f982855d87e103d3099ed68136e7>@@
.?AV<lambda_a26d879b56b4c4dd33ee8f6ff5f1da50>@@
.?AV<lambda_bc30b190ccdc11003b68eaf48bc55331>@@
.?AV<lambda_66cabf3c04f8f57705ecc5d1dde38596>@@
.?AV<lambda_90811df5034c6b064f00ff028e410b34>@@
.?AV<lambda_af999ce2e03a2039dbf31c1ff13e0675>@@
.?AV<lambda_f20c684c9a749a148b4d30f212c71a01>@@
.?AV<lambda_c9e45910c6dad78e6e958bb0527b44e1>@@
.?AV<lambda_d655da6f0498ff82874b3d8a213ddf66>@@
.?AV<lambda_242966bc823a6ea57016299e4846b19a>@@
.?AV<lambda_ef1b5ee9690bf60d6d8ba03dec70f0fc>@@
.?AV<lambda_9cc2379234b917d77614797746e75684>@@
.?AV<lambda_0f569c3741dec4cbd25547f5cfa47a1f>@@
.?AV<lambda_13bf14abed62c4ddb7d24aa834c66cd3>@@
.?AV<lambda_8bbb4bb940b6248f0079a061cca5209e>@@
.?AV<lambda_a4fb1c1b5f905e04c31cbbe6c165878a>@@
.?AV<lambda_dec8978adb68f88cd37c14b215792fcb>@@
.?AV<lambda_6665c408830d0dff611752f43635ad2f>@@
.?AV<lambda_acdb2664af6229da1e4c43d330c314d8>@@
.?AV<lambda_45e1f6e47762148b282b3bb16964d9a7>@@
.?AV<lambda_5151cdb5e2d0e967b0ff9b516f4dde5e>@@
.?AV<lambda_08b89006bb2cd45177aec966a5a64a25>@@
.?AV<lambda_d125101b1e77d289ab0937ad814f16d4>@@
.?AV<lambda_845fb0d365668e61a65e09bae6280c09>@@
.?AV<lambda_36945aef9b69b8bc246158e60ded74ff>@@
.?AV<lambda_048b899a3305cb2c0c070dd18e5b4d17>@@
.?AV<lambda_af2c39467b4484bc2a2f611cf533daa7>@@
.?AV<lambda_4c81a7b179f9e26e2d05ebefbb83c381>@@
.?AV<lambda_cc9e076beb57119667e5b07bb3c48707>@@
.?AV<lambda_673e4ce19ce5833538c9ec8e56f2275c>@@
.?AV<lambda_522944c70ac483ca59ad2373ac030c86>@@
.?AV<lambda_7ca26f875a5bd8018609c044fb5616a1>@@
.?AV<lambda_6367df6aa050372a33bd7465b9bffebf>@@
.?AV<lambda_40f74427ec28f20a5d59b70a3f7ba162>@@
.?AV<lambda_913ebb992bc3e09bdf2737529cebbf5a>@@
.?AV<lambda_c2634be0290355aa32c42903b822d942>@@
.?AV<lambda_6105a132d5626ddb9b2ed4958c88e1e2>@@
.?AV<lambda_f9b942c519c5abdf8c9e76770faf15a7>@@
.?AV<lambda_64e20fef6bc734aa72d77b8028e3b077>@@
.?AV<lambda_d9adada7822ba67bc618dd6220c7e11e>@@
.?AV<lambda_2bed918e0092d38de095a3dfcc39bb6a>@@
.?AV<lambda_031e8dfd8d6a123502d9ec2194443e60>@@
.?AV<lambda_577697c65f7f30ab5c890fb5e643c3c6>@@
.?AV<lambda_42f0399bf2e271e6e951294a5aec23bb>@@
.?AV<lambda_6dd6cf995614bc7c2e490d548728e197>@@
.?AV<lambda_d30ba908d7a4df45178218a83c8b90aa>@@
.?AV<lambda_7dbc984020fde247f30ce0431c9445e7>@@
.?AV<lambda_40d7d549b7296d37bd8a375a6a32735f>@@
.?AV<lambda_da7c0e243075d823e83aad5424aee4f1>@@
.?AV<lambda_bb245b6c588ba3a259962707ee90e1f2>@@
.?AV<lambda_f1490410ee527b42f3bd28e691dae2a7>@@
.?AV<lambda_f29a7766eb7b22af0fb124b7fabd1324>@@
.?AV<lambda_4dd0efe07882b79b8bac3f8f2023e7c8>@@
.?AV<lambda_cc810076352af54d8ab1334d58ef2ac8>@@
.?AV<lambda_4c0d5472c0e9893aea307d804bd55070>@@
.?AV<lambda_4ae79009ffed4baaf3b13205e614d6ec>@@
.?AV<lambda_50bf1563c4f2a658d5a1f8997cf7d841>@@
.?AV<lambda_90e67d7cf9c8fca59bac4a84fc304da2>@@
.?AV<lambda_e3ece229d743061e7008260e800aa786>@@
.?AV<lambda_b79d623619c8b488913a18719fb07ba7>@@
.?AV<lambda_1d7aed3977eb6b0e8500a44cbf6dc587>@@
.?AV<lambda_47f0845d7b66643be4c58515f34249ea>@@
.?AV<lambda_53687b87e8fc26669694bb154ed06213>@@
.?AV<lambda_85b8c9439e9295f048404909acdf29d3>@@
.?AV<lambda_486023130535c54dc87259934f24df6e>@@
.?AV<lambda_3354f944db7877754471d985be3fe29b>@@
.?AV<lambda_f78d8769dd40946ef61ad5956cbf10fe>@@
.?AV<lambda_918e9ac22ca80c25edd2a286064c2722>@@
.?AV<lambda_be9619b5fb1d1db7cf718b1fda3d5e82>@@
.?AV<lambda_2369389c848e11c0cf2fa8c55ee9bc1b>@@
.?AV<lambda_0847b334bbfd42737aafe7ba61663e74>@@
.?AV<lambda_61155733672bad5b1a1677020dbf30f2>@@
.?AV<lambda_4b94da34bdfcb505ddcef5cb50b95e3d>@@
.?AV<lambda_a4ad4e98f1a94b9237ebaa976e8eb831>@@
.?AV<lambda_253a3836eec6c1ddbcb7d28211e21bd6>@@
.?AV<lambda_712b3a1726a5ab1ce39d1b3e7f50d979>@@
.?AV<lambda_92e611cd061380e16cd955fad14a7b28>@@
.?AV<lambda_d401a94f28006a3b3118d2e8218a3957>@@
.?AV<lambda_57b4e734a8f319c201f732e76dc19318>@@
.?AV<lambda_f01e87ef597d7dc3f33e6877997ee749>@@
.?AV<lambda_113fc5cdb3f9f5e45a498eccec03db60>@@
.?AV<lambda_1abf5a492f2ce98320288d0a19f9a732>@@
.?AV<lambda_b86aa8ef1de0593a5547f08d792c1565>@@
.?AV<lambda_d70c00502c59385fd81a95257fd26b78>@@
.?AV<lambda_dfdd7885f2409b865180b051dead44b8>@@
.?AV<lambda_62f1ce9bc208e37c7e5739c8f36388ed>@@
.?AV<lambda_6a3bd940152ae2677fd2b897f7b984e8>@@
.?AV<lambda_2bf767e58fd6076f82b597352ebe6a94>@@
.?AV<lambda_3f849c6f51e31293c619565ac636bda7>@@
.?AV<lambda_510b48fcc953c4af1dbcb4b8cf19756a>@@
.?AV<lambda_1f77acb4e34034b00a5a2150384c9d77>@@
.?AV<lambda_874d535e153c7e2cc7bc8cf3f159ba49>@@
.?AV<lambda_16aeacf7ad4b53ba550defbc9c03abde>@@
.?AV<lambda_5e0f6565dc7aa7f6ebc79fe2fd37d8ea>@@
.?AV<lambda_f4d85bd911255cc25b789888dd092506>@@
.?AV<lambda_d6d6a472b26fc7f192d382e93bba1d57>@@
.?AV<lambda_65ea036252223d30a37862dfd4f7bc69>@@
.?AV<lambda_cc94c000691b360f8686beca1108599b>@@
.?AV<lambda_9c23f807f5b88acf4c74334fd51de3b9>@@
.?AV<lambda_c6a4c758ec4a05da2df0a96bda1f195f>@@
.?AV<lambda_b881ee6a3336741e3e3697374c374936>@@
.?AV<lambda_1e6c58f2c47fbfdcb340ca8aa595e354>@@
.?AV<lambda_03c53d5c540d06d25e58298bd3e2675f>@@
.?AV<lambda_348952d4e8cb4d6ca40b91f67d9fe4cc>@@
.?AV<lambda_3ce4407e5879111e6c1a6435d36077e4>@@
.?AV<lambda_16bdac8a01801cd7a5fcb1f21cc7a9f0>@@
.?AV<lambda_c765ee4079d8132e5b64fd41ad2c9a7d>@@
.?AV<lambda_5e0adb550519bb305a282a49bc052ff5>@@
.?AV<lambda_d0fdf4211aa9516cbe57f435cdbb747f>@@
.?AV<lambda_edcbc83438e6dd39d1d927db086748d9>@@
.?AV<lambda_57db475e5df80ef36653d188ca9951ac>@@
.?AV<lambda_1f3bf02585dcf20edf66f391042bccc5>@@
.?AV<lambda_aecfda1830c0ee30e0e4a23c265062da>@@
.?AV<lambda_b6dee4d13517d8cf66ef1e240c3ec6a4>@@
.?AV<lambda_0031e1631721c75a1f7a0e71cb748ed7>@@
.?AV<lambda_dcbbb46dcb2ccb38f1b7e3e89a0ca172>@@
.?AV<lambda_2dc16cf30de15202e0434934c8ec0571>@@
.?AV<lambda_c9cc85b6189178098c01bbceb71ba127>@@
.?AV<lambda_f013722fb06ba87b6ded393d910c85c6>@@
.?AV<lambda_84e0d1c8300760043597f8486883bb16>@@
.?AV<lambda_68f8064281287c2a20e44f23c72be5d5>@@
.?AV<lambda_b0ef8716b08a7c90da37b162fe225b7a>@@
.?AV<lambda_bb618da91ef45dc5293c089a74c35488>@@
.?AV<lambda_82b38e81208f4cf45ccff9cab1f1ab56>@@
.?AV<lambda_5169332acacd2cda6014329563a49097>@@
.?AV<lambda_b0f9e3c706f87be7af57692823441e06>@@
.?AV<lambda_3e2860b55958cf532cc6672e843fd5e5>@@
.?AV<lambda_d8059ce711ce14c36533947d64fa5a34>@@
.?AV<lambda_5a03cad439a535c73c9479bab198ff8a>@@
.?AV<lambda_221457049dd6e599b1e592be3898266a>@@
.?AV<lambda_6bf7af48e7a4158e20b4f833c15de130>@@
.?AV<lambda_a6d62ed7a3aadce21a3a08f0b111f7e9>@@
.?AV<lambda_0b84cd883df2cf8f5da7751da99be58c>@@
.?AV<lambda_3bf9d7b5239a137326d2c5fa821fa737>@@
.?AV<lambda_88b1496ecc213c07fd24b30bb5c856e7>@@
.?AV<lambda_c277816ed3e96f001ac0003fb11da190>@@
.?AV<lambda_19a25a0e0bced01a01388502a5fb897a>@@
.?AV<lambda_965a3b769c39b0bedf189a3ea0545ea9>@@
.?AV<lambda_939f4702fdcc80c80258913a08838422>@@
.?AV<lambda_ee988755aabf6d6b8cbe1162f42f9b60>@@
.?AV<lambda_6d0547d7d9e564311a780ca9dc7db655>@@
.?AV<lambda_81de0b469ab0f1e7bc6d7cfef2665991>@@
.?AV<lambda_0a786afdc494302a03a8347211af4f5e>@@
.?AV<lambda_8a900b8b41180a41f1571bb2c4cf6f8e>@@
.?AV<lambda_91fdf8e96bd0363c4307fa79933bf9ee>@@
.?AV<lambda_ec38228ee8b8eb97ec41ac102234721a>@@
.?AV<lambda_6db08e7b535fdfa2ab543d6397b422f2>@@
.?AV<lambda_1cdda74d195f4dc7bbdbaed3ee174bf7>@@
.?AV<lambda_348a4c4053fb0e4fb238401e94ac3418>@@
.?AV<lambda_b24067cfb776b28c2465a46fad4c39cd>@@
.?AV<lambda_b3ffb2b19f45444139b13fc0568f9537>@@
.?AV<lambda_d86f3bcde641b4c18df519c60bc10d09>@@
.?AV<lambda_e6687d53b2ff8a73e462a3df53da446b>@@
.?AV<lambda_8da27afb1f9e2f39230ce8504a3b22f1>@@
.?AV<lambda_56054d16adda54f2046f2f8778fd36d1>@@
.?AV<lambda_58e45bcf81f2eb4f6ae6b3f124defb13>@@
.?AV<lambda_217211e0b9216fbae93bbaf0026e78ee>@@
.?AV<lambda_a131928ffa9f4254777de03dab7a31a7>@@
.?AV<lambda_28d76a4078a4a8dbd4ec44ed08d36b25>@@
.?AV<lambda_8226f92ae14eb377c8291a622693e68d>@@
.?AV<lambda_20ce3835ea17537cf13d089eb1a443c1>@@
.?AV<lambda_1147aa6d38b42c0a8559813b3004180f>@@
.?AV<lambda_18e0b70d8d5a276d72055cc8661094dd>@@
.?AV<lambda_4e978ba75a8a0f3f4d2d1e75d74ac4de>@@
.?AV<lambda_c5677617c2b0074bdccd3f6596388b76>@@
.?AV<lambda_64826d400df5e2683a863a4dbb954602>@@
.?AV<lambda_cd453f5abbb4020fb3775475830cd8d1>@@
.?AV<lambda_2106de50a90423f7f3e101a627b3ccb6>@@
.?AV<lambda_d2aedfced5017e33ef2fd58df23b739b>@@
.?AV<lambda_5dddc316c01bb02791c37b03fa523bb0>@@
.?AV<lambda_96fe9f03daad80a6076c498e634c5f49>@@
.?AV<lambda_00b59445cb71ad9abff9006cdec65ab0>@@
.?AV<lambda_2d779c3a3c8b726adf3efb1bfd3cbb40>@@
.?AV<lambda_37fc46271b5a9d577e78557058b76819>@@
.?AV<lambda_06e5eb766e97cbbd1e9836fc044820b5>@@
.?AV<lambda_ddff9a77cb22aafff303a88b4705bee2>@@
.?AV<lambda_d73f309e1e17ba4988eef7d15e33e2b5>@@
.?AV<lambda_b1c0cff63caf505f6536baee30943a62>@@
.?AV<lambda_c4dc4b2967ca7204e8ba49b0607e0250>@@
.?AV<lambda_1d718ae1c6eee88a5015989ae3eac075>@@
.?AV<lambda_52be072c62487a4543b8a1a3d2fbad23>@@
.?AV<lambda_e41de5887194c6f47359224ea1f4265d>@@
.?AV<lambda_a935037996bf9e3d7f1925320992d343>@@
.?AV<lambda_02cf852cc5a543f808433f03632ba155>@@
.?AV<lambda_aa831217bcc44892538d39aae8c330f6>@@
.?AV<lambda_9283763b81fbf1c4441399956127b6eb>@@
.?AV<lambda_2a976ac88d60c988f6c82762c8669484>@@
.?AV<lambda_62526b7eac31a4fea5091c2f348a5e23>@@
.?AV<lambda_73119717ae86d28cb548ac4543eb73ed>@@
.?AV<lambda_d7d65f11678621cb189879800cf53faf>@@
.?AV<lambda_9f22cccb787c8b0be66f7b40706128ae>@@
.?AV<lambda_a45f274125d5aab3ada44bd6d91ed7f6>@@
.?AV<lambda_53958a524045125d538038a834c170f9>@@
.?AV<lambda_1476157c6a284e4f379191854345eea5>@@
.?AV<lambda_0aa1cbb10b7e27c8eaa9e1c4d936a012>@@
.?AV<lambda_2997ea06f466f3cb7af7580139e0e9b1>@@
.P6AXAEAUDataPropagationContext@onnx@@@Z
.?AVZeroCopyInputStream@io@protobuf@google@@
.?AVZeroCopyOutputStream@io@protobuf@google@@
.?AV?$basic_stringbuf@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_streambuf@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ostringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_ostream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ios@DU?$char_traits@D@std@@@std@@
.?AVios_base@std@@
.?AV?$_Iosb@H@std@@
.?AVCopyingInputStreamAdaptor@io@protobuf@google@@
.?AVCopyingOutputStreamAdaptor@io@protobuf@google@@
.?AVCopyingInputStream@io@protobuf@google@@
.?AVCopyingOutputStream@io@protobuf@google@@
.?AVFileInputStream@io@protobuf@google@@
.?AVCopyingFileInputStream@FileInputStream@io@protobuf@google@@
.?AVFileOutputStream@io@protobuf@google@@
.?AVCopyingFileOutputStream@FileOutputStream@io@protobuf@google@@
.?AVOstreamOutputStream@io@protobuf@google@@
.?AVCopyingOstreamOutputStream@OstreamOutputStream@io@protobuf@google@@
.?AVMessageLite@protobuf@google@@
.?AV?$basic_stringbuf@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_stringstream@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$basic_iostream@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_istream@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_ios@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_ostream@_WU?$char_traits@_W@std@@@std@@
.?AVtype_info@@
.?AV_Ref_count_base@std@@
.?AVIDataTransfer@onnxruntime@@
.?AVCPUDataTransfer@onnxruntime@@
.?AV?$_Func_base@XPEA_K@std@@
.?AV?$_Func_base@XPEAD@std@@
.?AV?$_Func_base@XPEAPEAUOrtValue@@@std@@
.?AV?$_Ref_count_obj2@VIAllocatorImplWrappingOrtAllocator@onnxruntime@@@std@@
.?AV?$_Ref_count_resource@PEAVIExecutionProvider@onnxruntime@@U?$default_delete@VIExecutionProvider@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3435a69bc2a4a58cf25c9601fa916799>@@XPEA_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6b9436f4089e82f5864d5365b56a5e02>@@XPEAD@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_78d2ff8fcf22c6166aa97abbb5fd0d75>@@XPEAPEAUOrtValue@@@std@@
.?AV?$_Ref_count_resource@PEAXP6AXPEAX@Z@std@@
.?AUOrtAllocatorImpl@onnxruntime@@
.?AUOrtAllocator@@
.?AUOrtDefaultCpuAllocator@@
.?AV?$_Func_base@_NH@std@@
.?AVISchemaRegistry@onnx@@
.?AVIOnnxRuntimeOpSchemaCollection@onnxruntime@@
.?AVOpKernel@onnxruntime@@
.?AV?$_Func_base@PEAVOpKernel@onnxruntime@@AEBVOpKernelInfo@2@@std@@
.?AVOnnxRuntimeOpSchemaRegistry@onnxruntime@@
.?AUCustomOpKernel@onnxruntime@@
.?AV?$_Ref_count_obj2@VKernelRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VOnnxRuntimeOpSchemaRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VCustomRegistry@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ca87e505bf8a7e1f26579083c3683d94>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4fe3bd39dcd0107f90455cb45c21429>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7afdd6f6db24c890469fd5278509941d>@@PEAVOpKernel@onnxruntime@@AEBVOpKernelInfo@3@@std@@
.?AVIAllocator@onnxruntime@@
.?AUOrtAllocatorImplWrappingIAllocator@onnxruntime@@
.?AVIAllocatorImplWrappingOrtAllocator@onnxruntime@@
.?AUProviderHost@onnxruntime@@
.?AUNodeAttributes_Iterator@onnxruntime@@
.?AUTensorShapeProto_Dimension_Iterator@onnxruntime@@
.?AUNode__NodeIterator@onnxruntime@@
.?AUNode__EdgeIterator@onnxruntime@@
.?AUTensorShapeProto_Dimension_Iterator_Impl@onnxruntime@@
.?AUNodeAttributes_Iterator_Impl@onnxruntime@@
.?AUNode__NodeIterator_Impl@onnxruntime@@
.?AUNode__EdgeIterator_Impl@onnxruntime@@
.?AUProviderHostImpl@onnxruntime@@
.?AVCPUAllocator@onnxruntime@@
.?AV?$basic_istringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_istream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_filebuf@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ifstream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ofstream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ostringstream@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$_Func_base@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AVIExecutionProvider@onnxruntime@@
.?AVGraphTransformer@onnxruntime@@
.?AVExLibLoader@onnxruntime@@
.?AVInsertCastTransformer@onnxruntime@@
.?AVInferenceSession@onnxruntime@@
.?AVAllocator@flatbuffers@@
.?AVDefaultAllocator@flatbuffers@@
.?AVMemcpyTransformer@onnxruntime@@
.?AVCPUExecutionProvider@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@$$V@std@@
.?AV?$_Ref_count_obj2@V?$unordered_map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@UFuncInfo@FuncManager@onnxruntime@@U?$hash@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@U?$equal_to@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@UFuncInfo@FuncManager@onnxruntime@@@std@@@2@@std@@@std@@
.?AV?$_Ref_count_obj2@VAllocatorManager@onnxruntime@@@std@@
.?AV?$_Ref_count_resource@PEAVCPUExecutionProvider@onnxruntime@@U?$default_delete@VCPUExecutionProvider@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAVModel@onnxruntime@@U?$default_delete@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_73b1da0ad8cd1f5530ce77a072f70a46>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_90fa7e4386c5622637b0b1880f5ca8f3>@@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b32e5f2bc2fafd58a4afcda5e8537c65>@@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_73f4f6c8b9b724afe3a51b52c953b043>@@VStatus@common@onnxruntime@@$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_739930acb5d4a4b1d92f387c9190b820>@@VStatus@common@onnxruntime@@$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c89e6783ea7ba65dd2bbca371d42018d>@@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AVISink@logging@onnxruntime@@
.?AVLoggingWrapper@@
.?AV?$basic_stringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_iostream@DU?$char_traits@D@std@@@std@@
.?AV?$_Func_base@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_base@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@P6AXAEAUInferenceContext@onnx@@@ZXAEAU12@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_79b1e3e4a047d410dc120a32d9f13caa>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b1b7fca51e482a233c6ad913e37a4670>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33c11271a908f4f215dd361ca0be165e>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dcbbb9aee7454d5a0feb975df66a7001>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7965ceabe5f45db89655ad0a7fd04cd6>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_598c6d249dbd14226af8e69fe738f910>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_de00575298e9c7ead3b243890c596395>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_18dbcf0a6112b471cd3435637c32f0f8>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_888c8332848e83c225ef5f5587c3b38e>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_daa97a08fba16356a015278e0f3ca1ed>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d522df09ab9335db57f0cfc8c09d6630>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8fef7dbb6b3e81cda489ebe45ab449bb>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ab7cc530eb49a3a15082dbc27eb613da>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b35f6304ab9b91e067de16d773b507fb>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_519fe9cae569b1ad1c3f73288fa352d4>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3a80fca790cdb0fce14ddaedefa20351>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0fb4e93f4014e9a9ed52287648f86c91>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_716d92b2455b6dca0a3e195a50699167>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6922b57be4edd39a89a7cea9e2ebb658>@@X$$QEAVOpSchema@onnx@@@std@@
.?AVRemoveDuplicateCastTransformer@onnxruntime@@
.?AVRewriteRule@onnxruntime@@
.?AVRuleBasedGraphTransformer@onnxruntime@@
.?AVAttentionFusion@onnxruntime@@
.?AVBiasGeluFusion@onnxruntime@@
.?AVBiasSoftmaxFusion@onnxruntime@@
.?AVCastElimination@onnxruntime@@
.?AVCommonSubexpressionElimination@onnxruntime@@
.?AVConvActivationFusion@onnxruntime@@
.?AVConvAddFusion@onnxruntime@@
.?AVConvBNFusion@onnxruntime@@
.?AVConvMulFusion@onnxruntime@@
.?AVDivMulFusion@onnxruntime@@
.?AVEliminateDropout@onnxruntime@@
.?AVDynamicQuantizeMatMulFusion@onnxruntime@@
.?AVEmbedLayerNormFusion@onnxruntime@@
.?AVExpandElimination@onnxruntime@@
.?AVFastGeluFusion@onnxruntime@@
.?AVGeluApproximation@onnxruntime@@
.?AVGeluFusion@onnxruntime@@
.?AVGemmActivationFusion@onnxruntime@@
.?AVGemmTransposeFusion@onnxruntime@@
.?AVEliminateIdentity@onnxruntime@@
.?AVLayerNormFusion@onnxruntime@@
.?AVSimplifiedLayerNormFusion@onnxruntime@@
.?AVMatMulAddFusion@onnxruntime@@
.?AVMatMulIntegerToFloatFusion@onnxruntime@@
.?AVMatMulScaleFusion@onnxruntime@@
.?AVNchwcTransformer@onnxruntime@@
.?AVNhwcTransformer@onnxruntime@@
.?AVNoopElimination@onnxruntime@@
.?AVNotWhereFusion@onnxruntime@@
.?AVFuseReluClip@onnxruntime@@
.?AVReshapeFusion@onnxruntime@@
.?AVSkipLayerNormFusion@onnxruntime@@
.?AVEliminateSlice@onnxruntime@@
.?AVUnsqueezeElimination@onnxruntime@@
.?AVQDQPropagationTransformer@onnxruntime@@
.?AVQDQS8ToU8Transformer@onnxruntime@@
.?AVReluQuantFusion@onnxruntime@@
.?AVMatmulTransposeFusion@onnxruntime@@
.?AVBiasDropoutFusion@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVNodeArg@3@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_61a830e6f94472550f401a07bc054c29>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_114e4f8c07e367eddb98d202f70e1c27>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_02dc3923ff80c6ae48f6f7d0552bad14>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AVConstantFolding@onnxruntime@@
.?AV?$_Func_base@_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_adedb98ee19cb4d9a4a46a5fd17584b5>@@_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AVFreeDimensionOverrideTransformer@onnxruntime@@
.?AUAction@onnxruntime@@
.?AURemoveNodes@onnxruntime@@
.?AUMergeIntoTarget@onnxruntime@@
.?AUNodeSelector@onnxruntime@@
.?AVQDQSelectorActionTransformer@onnxruntime@@
.?AVSelectorActionTransformer@onnxruntime@@
.?AVBaseSelector@QDQ@onnxruntime@@
.?AVDropDQDNodesSelector@QDQ@onnxruntime@@
.?AVUnarySelector@QDQ@onnxruntime@@
.?AVBinarySelector@QDQ@onnxruntime@@
.?AVVariadicSelector@QDQ@onnxruntime@@
.?AVConvSelector@QDQ@onnxruntime@@
.?AVMatMulSelector@QDQ@onnxruntime@@
.?AVOptimizerExecutionFrame@onnxruntime@@
.?AVIExecutionFrame@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_45c70c0d7c84bb60ff92f35bb1b93d0f>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AUReplaceWithNew@onnxruntime@@
.?AUQDQReplaceWithNew@QDQ@onnxruntime@@
.?AUReplaceWithQLinear@QDQ@onnxruntime@@
.?AUUnaryReplaceWithQLinear@QDQ@onnxruntime@@
.?AUBinaryReplaceWithQLinear@QDQ@onnxruntime@@
.?AUVariadicReplaceWithQLinear@QDQ@onnxruntime@@
.?AUConvReplaceWithQLinear@QDQ@onnxruntime@@
.?AUMatMulReplaceWithQLinear@QDQ@onnxruntime@@
.?AUIExecutionProviderFactory@onnxruntime@@
.?AUCpuProviderFactory@onnxruntime@@
.?AV?$_Ref_count_obj2@UCpuProviderFactory@onnxruntime@@@std@@
.?AUProviderHostCPU@onnxruntime@@
.?AUProviderHostCPUImpl@onnxruntime@@
.?AV?$_Func_impl_no_alloc@P6APEAVOpKernel@onnxruntime@@AEBVOpKernelInfo@2@@ZPEAV12@AEBV32@@std@@
.?AVGather@onnxruntime@@
.?AVGatherBase@onnxruntime@@
.?AV?$_Func_base@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a7f558f1dd0bc6dfbc34073d8010b2d2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9ad4dd46fb7ebf522a3e85e715143745>@@X_J_J@std@@
.?AVUnsqueeze@onnxruntime@@
.?AVUnsqueezeBase@onnxruntime@@
.?AVClip@onnxruntime@@
.?AV?$Clip_6@M@onnxruntime@@
.?AV?$Clip_6Base@M@clip_internal@onnxruntime@@
.?AU?$ElementWiseRangedTransform@M@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$LeakyRelu@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Relu@M@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@N@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Relu@N@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@C@functors@onnxruntime@@
.?AU?$ElementWiseRangedTransform@H@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sigmoid@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sigmoid@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Tanh@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Tanh@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$_Func_impl_no_alloc@U?$Tanh@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Tanh@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sigmoid@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sigmoid@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Relu@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Relu@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$LeakyRelu@M@functors@onnxruntime@@X_J_J@std@@
.?AVPow@onnxruntime@@
.?AV?$Add@M@onnxruntime@@
.?AV?$Add@N@onnxruntime@@
.?AV?$Add@H@onnxruntime@@
.?AV?$Add@_J@onnxruntime@@
.?AV?$Sub@M@onnxruntime@@
.?AV?$Sub@N@onnxruntime@@
.?AV?$Sub@H@onnxruntime@@
.?AV?$Sub@_J@onnxruntime@@
.?AV?$Mul@M@onnxruntime@@
.?AV?$Mul@N@onnxruntime@@
.?AV?$Mul@H@onnxruntime@@
.?AV?$Mul@_J@onnxruntime@@
.?AV?$Div@M@onnxruntime@@
.?AV?$Div@N@onnxruntime@@
.?AV?$Div@H@onnxruntime@@
.?AV?$Div@_J@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@C@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@F@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@F@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@H@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@_J@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@_J@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@E@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@E@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@G@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@G@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@I@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@I@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@_K@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@_K@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Floor@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Reciprocal@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Reciprocal@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sqrt@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sqrt@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Exp@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Exp@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$Sum_8@M@onnxruntime@@
.?AV?$Sum_8@N@onnxruntime@@
.?AV?$Less@M@onnxruntime@@
.?AV?$Less@N@onnxruntime@@
.?AV?$Less@H@onnxruntime@@
.?AV?$Less@_J@onnxruntime@@
.?AV?$Greater@M@onnxruntime@@
.?AV?$Greater@N@onnxruntime@@
.?AV?$Greater@H@onnxruntime@@
.?AV?$Greater@_J@onnxruntime@@
.?AV?$Equal@_N@onnxruntime@@
.?AV?$Equal@H@onnxruntime@@
.?AV?$Equal@_J@onnxruntime@@
.?AV?$Equal@M@onnxruntime@@
.?AV?$Equal@N@onnxruntime@@
.?AV?$Erf@M@onnxruntime@@
.?AV?$PRelu@M@onnxruntime@@
.?AV?$Expand_8@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_95dd41682914710e4e8d31623057e7d3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Exp@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Exp@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sqrt@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sqrt@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Reciprocal@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Reciprocal@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Floor@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@_K@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@I@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@G@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@E@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@_J@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@H@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@F@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@C@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_13046178b359e9c81742cfc406e97a28>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_23a1bb0478ab7117c6dff4712434f02b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_acccfeb1e0041e26bf01c6097464f8c5>@@X_J_J@std@@
.?AV?$Hardmax@M@onnxruntime@@
.?AV?$Softmax@M@onnxruntime@@
.?AV?$Softmax@N@onnxruntime@@
.?AV?$Conv@M@onnxruntime@@
.?AV?$ReduceKernel@$00@onnxruntime@@
.?AV?$ReduceKernelBase@$00@onnxruntime@@
.?AV?$ReduceLogSumExp@M@onnxruntime@@
.?AV?$ReduceLogSumExp@H@onnxruntime@@
.?AV?$ReduceLogSumExp@N@onnxruntime@@
.?AV?$ReduceMax@M@onnxruntime@@
.?AV?$ReduceMax@H@onnxruntime@@
.?AV?$ReduceMax@_J@onnxruntime@@
.?AV?$ReduceMax@N@onnxruntime@@
.?AV?$ReduceMax@C@onnxruntime@@
.?AV?$ReduceMax@E@onnxruntime@@
.?AV?$ReduceMean@M@onnxruntime@@
.?AV?$ReduceMean@H@onnxruntime@@
.?AV?$ReduceMean@N@onnxruntime@@
.?AV?$ReduceMin@M@onnxruntime@@
.?AV?$ReduceMin@H@onnxruntime@@
.?AV?$ReduceMin@_J@onnxruntime@@
.?AV?$ReduceMin@N@onnxruntime@@
.?AV?$ReduceSum@M@onnxruntime@@
.?AV?$ReduceSum@H@onnxruntime@@
.?AV?$ReduceSum@_J@onnxruntime@@
.?AV?$ReduceSum@N@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_cee3b4dd214c58e3bda89cd1d17f2a33>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2e098a1c981ad02f01e4203abb39ccc3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0eb1c82669a9a9098341056a7159769f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_eb610ec4c1ba2ee2f371c8f8541bff95>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_04a053d9287fc146500ea7158f178603>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_de0690e164792b53d65bc1c1d051a1bb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b51cf357ad6acfdf19263dcdcc3d9e57>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_71a7fcf63fe63e7115dc2b32c5b3bde5>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2e36b47c0b35a1b78ab3e2daaa7c5208>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f711efc9e33c8814de65d5fed61d7d7b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9e7e87298c6741b4ec8ed0a6456adc35>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e576f81a67738395c7b2b5774df9a9e6>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0d25eff6968fde540e49da9389ef8701>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bf8e9a99ad926869def2c865754256b2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1516ce509842e7002886a3533819cb83>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0fa14e0c348ed3017a38eb97cee09524>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_765516292e5be57b6b0a4f3fc843dfee>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dacc60142a8d7fe115059ddfa024c65f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_821f1e8c03e1c9965f7043e0547d5d5d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ceb94943cdad79a1266f9792313d7537>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1eeda2d106d394e62d7fd8de2d23ad48>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7fea215feaa82e3153664ad1fcc9f440>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5544c6f775d367a8b22497c127edf5eb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4bec17fbab3a578476488dd028797422>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_74ee6ad543f27310b05a4adf9a7be67d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_116979593b1f64e5f55211fbc71db2d0>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_81a02adb5ff83ba8ab585a5b795b05ad>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_270d1bd9fc78130be8d86e67c8f2ce05>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fa9b4ded894aa76a12ed158813083596>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_78dbc7f6c4933e58e34ef6be1a2ff7a7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d98acd54af1553e36890c98a685b0b7b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b012fd74acd70f9f2681f982ebb30583>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f80caf07313f1968c393099405f1b983>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9f3412b7c8b5e0fcfb6de75e19c2b20a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a220a526da965cfd243a774de182b4f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8e138b7d90664b9b073b07f3b9a88877>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7ad2abdb9d04286d775eb1928c7b7267>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2fd31ca8bad4e5f142a2b5dfaff21801>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_305677983a5a9935addb16bf86321e8d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_349643858d539033044d1d649dec237b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_82a82efebe07e5ae66c1dba7f7b1d0eb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3569b04d379d95c345dffc147f7b94dd>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a983769408c484edae48835df1b06ffa>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0736746d817c31c51fce207b52ada565>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3737cccf52f52050f818e2f26f25ffea>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c6a56551a85732582804098ed80c9fb0>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_35b4ad7503a02f4a81944df838e5a579>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6dcde8f3935fcb410660f26c17172b9a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5e986d8d54ac11e9537c3be07a635569>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_55516238922eb666def71419d606fbee>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0eb6d36a1e572b96903c06e9975f6aa3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1ab7060bf709e6890ff53a0d80bb8cf5>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a5fbe571a251fb604ad2b480580cc76b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2d5080a6f5d70d1027512848632ba44f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59d8acbb35668d76553fcdb87d75be9b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_55c350adfde8ac6bd9a00204b24ba96a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6a4c61f2b4befdad04c4488376ee8ba7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_48813fe4537d3b115d868f99a1d25e0d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0385abfaef506cac5165d4d2b4c7ecc3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ea638a800acf5ef947d9895c94c04562>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4d5e8f52539d7b1512da825129736cac>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_71c3b665db06d94a27cb005b95351a30>@@X_J_J@std@@
.?AVDeepCpuGruOp@onnxruntime@@
.?AV?$_Func_base@XPEAH@std@@
.?AV?$_Func_base@XPEAM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0aeb3b3202e2e34a7d6b98b623e6a327>@@XPEAM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b765106161737954a77d8a171216f44e>@@XPEAH@std@@
.?AVDeepCpuLstmOp@onnxruntime@@
.?AVLSTMBase@onnxruntime@@
.?AVCast@?A0x6a7f63ae@onnxruntime@@
.?AVConcat@onnxruntime@@
.?AVConcatBase@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_7cf9f7011f71cbc7a7f9f1e7bd9d9e44>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_432c0fbab4ccd64eefecf0c6cfc89332>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e5db1942e7340c738b6ebdc5da682efe>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ddd8493ebb39a49cc2643ed4269af499>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4ce86fe204f71dba32306ac9854bc206>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c60aa8fc78ffaf341f1d54c884d3f799>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_02871f30a7ce451399da82fe783f932a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f16edf5cdd807d431b24c8b686f2ae9b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f66e8601ea32ff7b33b7feafbaeaff41>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5a5fc68c4068eb1de24eefff3968df88>@@X_J_J@std@@
.?AV?$IdentityOp@$00@onnxruntime@@
.?AV?$IdentityOp@$0A@@onnxruntime@@
.?AVReshape@onnxruntime@@
.?AVShape@onnxruntime@@
.?AUSlice1@onnxruntime@@
.?AVSliceBase@onnxruntime@@
.?AUSlice10@onnxruntime@@
.?AVSplit@onnxruntime@@
.?AVSplitBase@onnxruntime@@
.?AVSqueeze@onnxruntime@@
.?AVSqueezeBase@onnxruntime@@
.?AUTile@onnxruntime@@
.?AVTranspose@onnxruntime@@
.?AVTransposeBase@onnxruntime@@
.?AV?$Expand@M@onnxruntime@@
.?AV?$Expand@N@onnxruntime@@
.?AV?$Expand@C@onnxruntime@@
.?AV?$Expand@F@onnxruntime@@
.?AV?$Expand@H@onnxruntime@@
.?AV?$Expand@_J@onnxruntime@@
.?AV?$Expand@E@onnxruntime@@
.?AV?$Expand@G@onnxruntime@@
.?AV?$Expand@I@onnxruntime@@
.?AV?$Expand@_K@onnxruntime@@
.?AV?$Expand@_N@onnxruntime@@
.?AV?$Expand@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_3f0ef66d0b0de67b55e854d697da2fff>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fd4f2bbf00caf507fea1cc6053ab984e>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1fd04ff7ed408ca4ebed6e8107f19670>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d0c5713ac46ee06d27e6324a463b7bee>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b9ad0ccbf56c00a46342640cba7cdc2c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f30a6117225d3cb8e4a11f826263726e>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c646dd14edaacae64487e0b96ad575f5>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3b97251de202434e86d007c33f9345a1>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e08a75ecff8a2a27b308be3f8dfddc66>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d48cb9baeb37d51a45fff2e006fd2ed3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_42580b4f3e49f7dcfbf37d76233bd856>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_310ceee0e4c58a7a83d7d00319ed9410>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9800a6d45ddc69dc425addf83da8e9e3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0251dfdaad61cfa5b2a46c99b78d27e8>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e1a7abf114b955966097bd83c14de705>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33215563a6aacb86deff746a6aa28a6c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6e3cb65d29853e95007cf81c805209f2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e77a57374f1e055f8281ce5dd65e8ebd>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5820733bf712edf4856ad2454498e68c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_115059020db09aa13bab825ad518034e>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_30e1101d7025e2d839d1daa9ac434cd1>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_786b2ff03846fcfa21d00bf234deaff2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6c91c6f34bd8327dc22f6b7f8735fd5b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1f8675d15ee5efaa8f5579945c6d118a>@@X_J_J@std@@
.?AVConstantOfShape@?A0x59e2fd99@onnxruntime@@
.?AV?$ConstantOfShapeBase@U?$TypeList@_JUMLFloat16@onnxruntime@@MNCFHEGI_K_N@onnxruntime@@@onnxruntime@@
.?AVIControlFlowKernel@controlflow@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@PEAX_K@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBV?$vector@_KV?$allocator@_K@std@@@std@@AEBVTensor@3@AEAV63@@std@@
.?AV?$_Func_base@V?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@AEBUOrtValue@@_J_J@std@@
.?AV?$_Func_base@V?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@AEAUOrtValue@@_J_J@std@@
.?AVIterator@?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@
.?AV?$Scan@$08@onnxruntime@@
.?AV?$_Func_impl_no_alloc@P6A?AV?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@AEBUOrtValue@@_J1@ZV12@AEBU3@_J_J@std@@
.?AV?$_Func_impl_no_alloc@P6A?AV?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@AEAUOrtValue@@_J1@ZV12@AEAU3@_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_138b12d2a19d941ed2e5665ad50fc6cb>@@VStatus@common@onnxruntime@@AEBV?$vector@_KV?$allocator@_K@std@@@std@@AEBVTensor@4@AEAV74@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0f619f3ff08e9e7659a763308b991cbe>@@VStatus@common@onnxruntime@@PEAX_K@std@@
.?AV?$Where@E@onnxruntime@@
.?AV?$Where@H@onnxruntime@@
.?AV?$Where@_J@onnxruntime@@
.?AV?$Where@M@onnxruntime@@
.?AV?$Where@N@onnxruntime@@
.?AV?$Where@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$Gemm@M@onnxruntime@@
.?AVGemmBase@onnxruntime@@
.?AV?$Gemm@N@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_4bd02c7b372889e26c922fb97a0c9ac3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bbed65651851398ae9e91eb41072a5f9>@@X_J_J@std@@
.?AV?$MatMul@M@onnxruntime@@
.?AV?$MatMul@N@onnxruntime@@
.?AV?$MatMul@H@onnxruntime@@
.?AV?$MatMul@_J@onnxruntime@@
.?AV?$DequantizeLinear@C@onnxruntime@@
.?AV?$DequantizeLinear@E@onnxruntime@@
.?AV?$DequantizeLinear@H@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_e7ad5c511f7f0ca88484948ab82410f1>@@X_J_J@std@@
.?AVMatMulIntegerBase@onnxruntime@@
.?AVMatMulInteger@onnxruntime@@
.?AVConvInteger@onnxruntime@@
.?AV?$CumSum@M@onnxruntime@@
.?AV?$CumSum@N@onnxruntime@@
.?AV?$CumSum@H@onnxruntime@@
.?AV?$CumSum@_J@onnxruntime@@
.?AV?$Round@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$Round@M@onnxruntime@@
.?AV?$Round@N@onnxruntime@@
.?AV?$DynamicQuantizeLinear@E@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_86dd40270c718f299cd5113909653b31>@@X_J_J@std@@
.?AVRange@onnxruntime@@
.?AV?$_Func_base@X_J@std@@
.?AV?$TopK@$0L@M@onnxruntime@@
.?AV?$TopK@$0L@N@onnxruntime@@
.?AV?$TopK@$0L@H@onnxruntime@@
.?AV?$TopK@$0L@_J@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_8f0d91faf2fd476a9a61179d9b72837d>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8ffce33af8696a7a42fa073f6875aacb>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a3f9f19c48a100998729328075237dc>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_03e7406b29b220fa131a6585ce48dcd2>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8205a59784c4f81abae5636754370a87>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_88f211d79a091f6a481688e49635f453>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1221b4097effa32a8dd388b4455dd2c1>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_51f7b34ad2d14ff9bfb03559ccadc81f>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33ab9233a6e2a6fe6c24d1963cbc3111>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_88cacdca8b660ada94d8f522e9f11bdd>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f8dbfaed9d55440bb15cbf009ac934a6>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_038eb253b7f4e93118566e43dda81530>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7b13e0aa9183a7266252ed7dbdd54f99>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ecc9b9120eb4793427a94169f5623a5b>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_11002e821957b929b79aa649ecf0a381>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc7060560dae87f5475ce357b0faca8e>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a32f11f3f6edc3a900d9d34015d67705>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f2842527842316c8394eef731b560fea>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b2b5b00a4ad3647a9a40b4f0dbb0745d>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c6728963f8bb91595df67d14c61fd8fa>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f55fed088cc6887bf534564a0809769f>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_72e83488395612e0f6a2602b726a187c>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1cd5cfe6b76bb3ba1c53203d58a4eedd>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a1b033c1238f74f04d136673bf3141a7>@@X_J@std@@
.?AVReorderInput@contrib@onnxruntime@@
.?AVReorderOutput@contrib@onnxruntime@@
.?AVNchwcConv@contrib@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_ef1755d3dc9c2a6da40e08422cf4f664>@@X_J@std@@
.?AVMLAS_QGEMM_OUTPUT_PROCESSOR@@
.?AVMLAS_QGEMM_SCALE_BIAS_OUTPUT_PROCESSOR@@
.?AVMatMulIntegerToFloatBase@contrib@onnxruntime@@
.?AVDynamicQuantizeMatMul@contrib@onnxruntime@@
.?AVMatMulIntegerToFloat@contrib@onnxruntime@@
.?AVDynamicQuantizeLSTM@contrib@onnxruntime@@
.?AVFusedConvFloat@contrib@onnxruntime@@
.?AV?$Gelu@M@contrib@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_95c74ffd32a4d994a62a191daf0fff27>@@X_J@std@@
.?AV?$LayerNorm@M$0A@@contrib@onnxruntime@@
.?AV?$LayerNorm@M$00@contrib@onnxruntime@@
.?AV?$LayerNorm@N$0A@@contrib@onnxruntime@@
.?AV?$LayerNorm@N$00@contrib@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_95aae9bbb822c713ca9677b3a07b3381>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e4fd1e1090be16100e1685f2f4877667>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ee954de93bf759bd8b1f4b4c9716ded3>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_337593ad4f874bae98bb3aa9ea22758d>@@X_J@std@@
.?AV?$_Func_base@MMMM@std@@
.?AV?$_Func_impl_no_alloc@P6AMMMM@ZMMMM@std@@
.?AVIterator@?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVTensorShape@3@AEBUOrtMemoryInfo@@AEAUOrtValue@@AEA_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7d40fd05acaf32e2efee452cda59a5a2>@@VStatus@common@onnxruntime@@AEBVTensorShape@4@AEBUOrtMemoryInfo@@AEAUOrtValue@@AEA_N@std@@
.?AV?$_Func_base@XPEAE@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0f2ad18a551e793a8bddf1de1dc21689>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3410038a349fbad62fb0cd42ca2fc595>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9cf24a11d7a47ec83a2235f766fd2a5c>@@XPEAE@std@@
.?AVDataTypeImpl@onnxruntime@@
.?AVTensorTypeBase@onnxruntime@@
.?AVSparseTensorTypeBase@onnxruntime@@
.?AVSequenceTensorTypeBase@onnxruntime@@
.?AVNonTensorTypeBase@onnxruntime@@
.?AVPrimitiveDataTypeBase@onnxruntime@@
.?AV?$_Func_base@XPEBVDataTypeImpl@onnxruntime@@@std@@
.?AV?$TensorType@H@onnxruntime@@
.?AV?$TensorType@M@onnxruntime@@
.?AV?$TensorType@_N@onnxruntime@@
.?AV?$TensorType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$TensorType@C@onnxruntime@@
.?AV?$TensorType@E@onnxruntime@@
.?AV?$TensorType@G@onnxruntime@@
.?AV?$TensorType@F@onnxruntime@@
.?AV?$TensorType@_J@onnxruntime@@
.?AV?$TensorType@N@onnxruntime@@
.?AV?$TensorType@I@onnxruntime@@
.?AV?$TensorType@_K@onnxruntime@@
.?AV?$TensorType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$TensorType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SparseTensorType@H@onnxruntime@@
.?AV?$SparseTensorType@M@onnxruntime@@
.?AV?$SparseTensorType@_N@onnxruntime@@
.?AV?$SparseTensorType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$SparseTensorType@C@onnxruntime@@
.?AV?$SparseTensorType@E@onnxruntime@@
.?AV?$SparseTensorType@G@onnxruntime@@
.?AV?$SparseTensorType@F@onnxruntime@@
.?AV?$SparseTensorType@_J@onnxruntime@@
.?AV?$SparseTensorType@N@onnxruntime@@
.?AV?$SparseTensorType@I@onnxruntime@@
.?AV?$SparseTensorType@_K@onnxruntime@@
.?AV?$SparseTensorType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SparseTensorType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@U?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@U?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_JU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_JU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@NU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@NU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@_J@2@V?$allocator@U?$pair@$$CB_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@_J@2@V?$allocator@U?$pair@$$CB_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_J_JU?$less@_J@std@@V?$allocator@U?$pair@$$CB_J_J@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_J_JU?$less@_J@std@@V?$allocator@U?$pair@$$CB_J_J@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JNU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JN@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JNU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JN@std@@@2@@std@@@onnxruntime@@
.?AV?$SequenceTensorType@M@onnxruntime@@
.?AV?$SequenceTensorType@N@onnxruntime@@
.?AV?$SequenceTensorType@C@onnxruntime@@
.?AV?$SequenceTensorType@E@onnxruntime@@
.?AV?$SequenceTensorType@F@onnxruntime@@
.?AV?$SequenceTensorType@G@onnxruntime@@
.?AV?$SequenceTensorType@H@onnxruntime@@
.?AV?$SequenceTensorType@I@onnxruntime@@
.?AV?$SequenceTensorType@_J@onnxruntime@@
.?AV?$SequenceTensorType@_K@onnxruntime@@
.?AV?$SequenceTensorType@_N@onnxruntime@@
.?AV?$SequenceTensorType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$SequenceTensorType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SequenceTensorType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@V?$allocator@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@V?$allocator@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@V?$allocator@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@V?$allocator@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$PrimitiveDataType@H@onnxruntime@@
.?AV?$PrimitiveDataType@M@onnxruntime@@
.?AV?$PrimitiveDataType@_N@onnxruntime@@
.?AV?$PrimitiveDataType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$PrimitiveDataType@C@onnxruntime@@
.?AV?$PrimitiveDataType@E@onnxruntime@@
.?AV?$PrimitiveDataType@G@onnxruntime@@
.?AV?$PrimitiveDataType@F@onnxruntime@@
.?AV?$PrimitiveDataType@_J@onnxruntime@@
.?AV?$PrimitiveDataType@N@onnxruntime@@
.?AV?$PrimitiveDataType@I@onnxruntime@@
.?AV?$PrimitiveDataType@_K@onnxruntime@@
.?AV?$PrimitiveDataType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$PrimitiveDataType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8a9ac16dd775f4bb1f670ae469711dc>@@XPEBVDataTypeImpl@onnxruntime@@@std@@
.?AV?$_Func_base@XPEAX@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d63de458c7355252fdf7dac6af546a6c>@@XPEAX@std@@
.?AVIExecutor@onnxruntime@@
.?AVSequentialExecutor@onnxruntime@@
.?AVOpKernelContext@onnxruntime@@
.?AV?$_Ref_count_resource@PEAVBFCArena@onnxruntime@@U?$default_delete@VBFCArena@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAVIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c9c94e4a7d5ae844e1f9d0f784dced0b>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_base@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e1a8783767138f2900763c385a76ace5>@@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d77ac61f6238a68ec5589d982d5615ac>@@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_535c714f3912f6e19812f86aced1c234>@@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f7fefea6bfb8182e95c707a77e7f4a8f>@@X_K_K@std@@
.?AVISequentialPlannerContext@onnxruntime@@
.?AVSequentialPlannerContext@onnxruntime@@
.?AV?$_Func_base@V?$shared_ptr@VIAllocator@onnxruntime@@@std@@HW4OrtMemType@@@std@@
.?AV?$_Func_base@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@HAEBUOrtValue@@AEBUOrtCallback@3@_N_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0443539308e5b1117b55e6de227ed40c>@@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_50c8fe897e68e43b1818d88f70a689d9>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a641b8f1e5dd6615c70f20c32f700fce>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_31e4b4a2d49d229e0e58bbade49550ff>@@VStatus@common@onnxruntime@@HAEBUOrtValue@@AEBUOrtCallback@4@_N_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_46f2340c6974a9abf9bf427b63a5b9bc>@@V?$shared_ptr@VIAllocator@onnxruntime@@@std@@HW4OrtMemType@@@std@@
.?AVBFCArena@onnxruntime@@
.?AVFunctionKernel@onnxruntime@@
.?AVExecutionFrame@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_c21643d1fb44758b12325da46a2d32c5>@@_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_base@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_957302132dd7fea31b11af321304eee3>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1123ca3288c22333dcfbc6780e56f3b6>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d5d62f4b858abcded92348c54a906570>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4404716c35945f1da6a07154c932397d>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_base@X$$V@std@@
.?AVParallelExecutor@onnxruntime@@
.?AVOpKernelContextInternal@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_9de7ed3747c068fd694551112d802911>@@X$$V@std@@
.?AV?$_Func_base@HPEAUComputeContext@onnxruntime@@PEAPEAX@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@PEAXPEBUOrtApi@@PEAUOrtKernelContext@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c8a671616559eac778e178004f6bff38>@@VStatus@common@onnxruntime@@PEAXPEBUOrtApi@@PEAUOrtKernelContext@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2369f292b0f42fbecffef8359e85ebdc>@@HPEAUComputeContext@onnxruntime@@PEAPEAX@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2e668c941b29e0c58674cef7fa23f2c>@@XPEAX@std@@
.?AVExecutionPlanBase@onnxruntime@@
.?AUSequentialExecutionPlan@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_47e575137926bdb4c6da3cd254bbf347>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_76259788010337ce84c7523a6ac9ea2f>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_56112085461402060b9fcd1813ada6f0>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AVITensorAllocator@onnxruntime@@
.?AVTensorAllocatorWithMemPattern@onnxruntime@@
.?AVSimpleTensorAllocator@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_f663e1cb5f92583d40a80c3711b532b4>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2314020bbb2bcb9dacfa0af3f7ebfa1d>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AVGraph@onnxruntime@@
.?AVGraphInferencer@onnx@@
.?AUInferenceContext@onnx@@
.?AUFunctionBodyBuildContext@onnx@@
.?AUFunctionBodyBuildContextImpl@onnx@@
.?AVGraphInferencerImpl@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVNode@3@AEAVGraph@3@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV67@AEBUResolveOptions@53@@std@@
.?AVInferenceContextImpl@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAVGraph@3@@std@@
.?AV?$_Func_impl_no_alloc@P6A?AVStatus@common@onnxruntime@@AEBVNode@3@AEAVGraph@3@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV67@AEBUResolveOptions@53@@ZV123@AEBV43@AEAV53@AEBV67@AEAV67@AEBU853@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e318b9a1ac6011cec45976779008bc1d>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c007df17e8115f08c5c6e2ce7e2201c0>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_854a3a76655e0ae1c9e2878289036568>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_base@_N_K@std@@
.?AV?$_Func_base@_NPEBVNode@onnxruntime@@PEBV12@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0a3d98e003a8310444f50c395f4ee870>@@_N_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a047e4fa7a019da5da5dcb5093bd2da9>@@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@UNodeCompare@onnxruntime@@_NPEBVNode@2@PEBV32@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0457fc55cb15f22bdcba75f54e0aa1c1>@@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@UPriorityNodeCompare@onnxruntime@@_NPEBVNode@2@PEBV32@@std@@
.?AVSchemaRegistryManager@onnxruntime@@
.?AV?$_Ref_count_obj2@VSchemaRegistryManager@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VModel@onnxruntime@@@std@@
.?AV?$_Ref_count@VModel@onnxruntime@@@std@@
.?AV?$_Func_base@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@2@AEAVFunctionProto@2@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4ee11195e6ac34d8802828c9de8931d7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a9ad92a14c7791713a13c8f77948b581>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_03c395c29c547f11867e2aba27fc822a>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_71ef653055b00e102f19330e0f78a252>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc4bc3c6927d9351454759e8077d0a48>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_893ec3becb9cd41d9efbc7eea98d41c9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e15d10c4385b9adab7c3b2967076a5a0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_423c7f4514cb0f580d17c1969d94ab4d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6a32611970906250c6b47d8292ad00e7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1c17b461588ff1b22a6f9497bff5b28b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_26de9b5e95466f00708e3ae83a84c608>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_98f67966096a245ba60cb535f4355420>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2d30aee68f6d7fc70a227ffb90481678>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_104e5d4f3c346a5807a7db11389af990>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_12dd4c4dcfd6c2d8effe6071c823bd43>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e7f381725b47e4a5cf7649db595fbdf3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d49bbfb4942fd85adb6441f849e70bf8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9d8771d050eb3774da949f76ff7b2f7a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e74921842af68f126d6a963647d9b662>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_29460ba72c9a9f61937f695b212c2385>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9a36e00d72a5d737ec77f3dedc2d9072>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bce84f647e20c57856d03ed6208ba6c9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9e039da5781458d9f2e0d572b3cc8d18>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_860b5cff89ff5f292872db2aaa19c52a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_78621caf55ac03a4deb4ebb6d320ce8f>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_076f399d54601fd1059236c6a3813828>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7d629299b17d3241cda0057fa57cac3b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_814de60c7177af03b3ddc9e5c36d561a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1cd6b5a2cebd273f7225f466512c43d5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9390aed8e2d795f49afe09f731079323>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_70a7cafce997c1d7f642703664353219>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_49ccb288b38bc111b2959e907bfdd8e7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5a471c0e331ecac30327327b781715bc>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_56c3ac63d8a5c9a2d5ed84f082ef3cf5>@@XAEAUInferenceContext@onnx@@@std@@
.?AVFunction@onnxruntime@@
.?AVFunctionImpl@onnxruntime@@
.?AVViewerFunctionImpl@onnxruntime@@
.?AVGraphInferencerImpl@shape_inference@onnx@@
.?AUInferenceContextImpl@shape_inference@onnx@@
.?AV?$_Func_base@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV12@AEBV12@@std@@
.?AV?$_Func_impl_no_alloc@P6A?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV12@0@ZV12@AEBV12@AEBV12@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3b79ba1930d9045b1d0a1c3e7b558aa7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_base@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a7a0686f23e7f9337eaa10f069ee321b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c2fef1cfbd08e9e21bcb74b985df87e6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_680b87823779380f32485d5ed8cbcf84>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f0be09c6ec8e17e7ac33afa3db53ce78>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_581e172f6e6bf6d53a792d4f2adbb4c0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@P6AXAEAVOpSchema@onnx@@@ZXAEAV12@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bcef20d2b13b7b49fdebd823a7e734e1>@@XAEAUInferenceContext@onnx@@@std@@
.?AVNhwcInferenceContext@contrib@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_b58abd66dfb794261458d2caeeba2a75>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fc59cfd6180e7962f9dbfcf6d01970a3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2ed99b1b7f84cedcec6ea06ce6c01dc5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c7733fbf1e7357c5a2b00aac2ede4865>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a8b00e76dfe980214923eafc43926fd4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ef5c424a4193a85193eb7ea4c70aae69>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_14407bcf8cfc66db9a85fd2745a31d94>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b3cbfd0276cf0ad6f3b58532d60f239f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_672376956558218714cb97c30f1f09fd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7361ba811d5ff92bf50e102c73312480>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_85740bb65c1a7256d972833e138b25dd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_77bbe4874254ed84a312b5fa826a83d3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7a5892277686c5fc70de8922cd945035>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f9fcc66b14829c5756eb43c20bdf984b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9289ae269610356b68d5c3f46e89bf66>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_08db83bf9ac8665fc4de47cb08668b85>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b48de96003057f4b051b72f0b9baa2ee>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_539862c5b8039ccfff5acf2ed512ba97>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3361a7c3c06ae8fda0091b29a15bc377>@@X_J@std@@
.?AVerror_category@std@@
.?AV_Generic_error_category@std@@
.?AV_System_error_category@std@@
.?AVEnvThread@onnxruntime@@
.?AVWindowsThread@?A0x23245f68@onnxruntime@@
.?AVWindowsEnv@?A0x23245f68@onnxruntime@@
.?AVEnv@onnxruntime@@
.?AVcodecvt_base@std@@
.?AVfacet@locale@std@@
.?AV_Facet_base@std@@
.?AU_Crt_new_delete@std@@
.?AV?$codecvt@_WDU_Mbstatet@@@std@@
.?AVThreadPoolInterface@Eigen@@
.?AVExtendedThreadPoolInterface@concurrency@onnxruntime@@
.?AV?$ThreadPoolTempl@VEnv@onnxruntime@@@concurrency@onnxruntime@@
.?AV?$_Func_base@XI@std@@
.?AV?$codecvt_utf8@_W$0BAPPPP@$0A@@std@@
.?AV?$wstring_convert@V?$codecvt_utf8@_W$0BAPPPP@$0A@@std@@_WV?$allocator@_W@2@V?$allocator@D@2@@std@@
.?AV?$_Func_base@_N$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_429bffec90bbca49494510e27e518b79>@@XI@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0b4cc153b058489c05500d0b394c47a0>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9cfecf4c86183e59841b56095d1dec6f>@@XI@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ad8ca076531a0e62bdc4758313aec8ec>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1c511d989171b0ae840c900d36af6cdf>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3525a67688acab3a16549c70f50b343d>@@_N$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5033badb7240167b30b90523bec68adf>@@X$$V@std@@
.?AVOStreamSink@logging@onnxruntime@@
.?AVCLogSink@logging@onnxruntime@@
.?AVTelemetry@onnxruntime@@
.?AVWindowsTelemetry@onnxruntime@@
.?AV?$numpunct@D@std@@
.?AVWindowsEnvTime@?A0x2f037b66@onnxruntime@@
.?AVEnvTime@onnxruntime@@
.?AVOpSchemaRegistry@onnx@@
.?AV?$_Func_impl_no_alloc@V<lambda_59d0c8449581e17e31aa5d36d4e1dfcc>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fe5b044a59055ca66e7af958ee5f5bc3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fcf7b72cb8688ac639f6066c6f9347c9>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_922ea2af44b61076061b9738fd44abd8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fbf4f22e77a262ac13623763b425fa95>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a345bf27d2a96610b3b006a123df813d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_58fbb8df4116cc5ed49a05a90528c0bc>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_27a631d2450c357a52927c1dfbd2efda>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9c03d71b3e2a72420d0112f6f3840dd4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_43d76a454d7e446551a32b163679964a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d08789fec1ddb2ea31a7e42b01821aaa>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c9fe283d46d2f293dcb8573f075d3809>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4015e490e3e9078f9108a810d677815>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2f4103e1c4a1773101a6c1f055d56df4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6f05a8b4f6851ad7c85a3a3bcb9b9104>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@P6A_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@2@AEAVFunctionProto@2@@Z_NAEBU12@AEBV32@AEAV42@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6f010deb824d03b6370449d6f782b9da>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_458163864faccd230ccf1ce10d3e187d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1249aa664b6dd8c7cf40d23fbaec080e>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_22aeb0e20ec618f43aaa785665edaa1d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2e20e62e8d812957e92321838accac54>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fd266a9166d0b10d35a0d8f14994daa2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5c5ac1f6c71d812ad45802a5c8ea5757>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aec81523952d967a50c07470b5814993>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0af4c846dd5af6632beb77ffbd6469c9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33763db33c7430e0074fd25b65b4479f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c6cc7a538d9c817426d2f4671032805a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_be82f0d3082d1770e6fe9b6560ab180a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_abb9581c367ec240a8c0e5afd8181e99>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5fe773ac1f878f81aadf16bc155901d0>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_655336b29940dd8dbdcd42ec2ee05996>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6bb3fafba21860621ead2400f83d0ab0>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7c61692eadeb4ccd34c8bb00529bfb83>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8dc767ccba8e089e41f89b04cb108c10>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_51967558c7fd075e660195f4e6702ce2>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6711c07c0f8ab9cb8e9a7125cbe3a01a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d3c7976f3f38539a50838a16dd62ccb2>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_727130accb380845b50f2c19a2b46d02>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4cd868df938477ea9946d2d55c43c695>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6b0122b627329aed747a7281e017781a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aa88e462824a3ef64606c92b2b205d10>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fdb0134f4d01b5f723238dd45cc4059f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_556d3d9e1da4d900ac4beace2594775f>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9148a73a32272a5a33edca914c11c2a4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0afff8b6c40408852605b1495798325e>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9cc2379234b917d77614797746e75684>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ef1b5ee9690bf60d6d8ba03dec70f0fc>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_242966bc823a6ea57016299e4846b19a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d655da6f0498ff82874b3d8a213ddf66>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c9e45910c6dad78e6e958bb0527b44e1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f20c684c9a749a148b4d30f212c71a01>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_af999ce2e03a2039dbf31c1ff13e0675>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_90811df5034c6b064f00ff028e410b34>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_66cabf3c04f8f57705ecc5d1dde38596>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bc30b190ccdc11003b68eaf48bc55331>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a26d879b56b4c4dd33ee8f6ff5f1da50>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3050f982855d87e103d3099ed68136e7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4bfaa77b47cc3b72c0199e4158dcfdd3>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2cdbc5f873c2ce32c36481fab53d6870>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_edad1d56ba5861f241ccb72d3e98208e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2d693a490e9887da5a024c703dc8e3e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_006f042491572090b778a6887556c541>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6aeba50936d3f6c7b11f3c24b58165e0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7c393e0ced2515f63b0674de1e1229b1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_747f5a5054cea5042105b3988bb8e54a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_base@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc810076352af54d8ab1334d58ef2ac8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4dd0efe07882b79b8bac3f8f2023e7c8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f29a7766eb7b22af0fb124b7fabd1324>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f1490410ee527b42f3bd28e691dae2a7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb245b6c588ba3a259962707ee90e1f2>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_da7c0e243075d823e83aad5424aee4f1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_40d7d549b7296d37bd8a375a6a32735f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7dbc984020fde247f30ce0431c9445e7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d30ba908d7a4df45178218a83c8b90aa>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6dd6cf995614bc7c2e490d548728e197>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_42f0399bf2e271e6e951294a5aec23bb>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_577697c65f7f30ab5c890fb5e643c3c6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_031e8dfd8d6a123502d9ec2194443e60>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2bed918e0092d38de095a3dfcc39bb6a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d9adada7822ba67bc618dd6220c7e11e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_64e20fef6bc734aa72d77b8028e3b077>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f9b942c519c5abdf8c9e76770faf15a7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6105a132d5626ddb9b2ed4958c88e1e2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c2634be0290355aa32c42903b822d942>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_913ebb992bc3e09bdf2737529cebbf5a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_40f74427ec28f20a5d59b70a3f7ba162>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6367df6aa050372a33bd7465b9bffebf>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7ca26f875a5bd8018609c044fb5616a1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_522944c70ac483ca59ad2373ac030c86>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_673e4ce19ce5833538c9ec8e56f2275c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc9e076beb57119667e5b07bb3c48707>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4c81a7b179f9e26e2d05ebefbb83c381>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_af2c39467b4484bc2a2f611cf533daa7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_048b899a3305cb2c0c070dd18e5b4d17>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_36945aef9b69b8bc246158e60ded74ff>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_845fb0d365668e61a65e09bae6280c09>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d125101b1e77d289ab0937ad814f16d4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_08b89006bb2cd45177aec966a5a64a25>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5151cdb5e2d0e967b0ff9b516f4dde5e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_45e1f6e47762148b282b3bb16964d9a7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_acdb2664af6229da1e4c43d330c314d8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6665c408830d0dff611752f43635ad2f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dec8978adb68f88cd37c14b215792fcb>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4fb1c1b5f905e04c31cbbe6c165878a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8bbb4bb940b6248f0079a061cca5209e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_13bf14abed62c4ddb7d24aa834c66cd3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0f569c3741dec4cbd25547f5cfa47a1f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_90e67d7cf9c8fca59bac4a84fc304da2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_50bf1563c4f2a658d5a1f8997cf7d841>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4ae79009ffed4baaf3b13205e614d6ec>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4c0d5472c0e9893aea307d804bd55070>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1d7aed3977eb6b0e8500a44cbf6dc587>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b79d623619c8b488913a18719fb07ba7>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e3ece229d743061e7008260e800aa786>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dfdd7885f2409b865180b051dead44b8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d70c00502c59385fd81a95257fd26b78>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b86aa8ef1de0593a5547f08d792c1565>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1abf5a492f2ce98320288d0a19f9a732>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_113fc5cdb3f9f5e45a498eccec03db60>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f01e87ef597d7dc3f33e6877997ee749>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_57b4e734a8f319c201f732e76dc19318>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d401a94f28006a3b3118d2e8218a3957>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_92e611cd061380e16cd955fad14a7b28>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_712b3a1726a5ab1ce39d1b3e7f50d979>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_253a3836eec6c1ddbcb7d28211e21bd6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4ad4e98f1a94b9237ebaa976e8eb831>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4b94da34bdfcb505ddcef5cb50b95e3d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_61155733672bad5b1a1677020dbf30f2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0847b334bbfd42737aafe7ba61663e74>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2369389c848e11c0cf2fa8c55ee9bc1b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_be9619b5fb1d1db7cf718b1fda3d5e82>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_918e9ac22ca80c25edd2a286064c2722>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f78d8769dd40946ef61ad5956cbf10fe>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3354f944db7877754471d985be3fe29b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_486023130535c54dc87259934f24df6e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_85b8c9439e9295f048404909acdf29d3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53687b87e8fc26669694bb154ed06213>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_47f0845d7b66643be4c58515f34249ea>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2bf767e58fd6076f82b597352ebe6a94>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6a3bd940152ae2677fd2b897f7b984e8>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_62f1ce9bc208e37c7e5739c8f36388ed>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9c23f807f5b88acf4c74334fd51de3b9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc94c000691b360f8686beca1108599b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_65ea036252223d30a37862dfd4f7bc69>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d6d6a472b26fc7f192d382e93bba1d57>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f4d85bd911255cc25b789888dd092506>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5e0f6565dc7aa7f6ebc79fe2fd37d8ea>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_16aeacf7ad4b53ba550defbc9c03abde>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_874d535e153c7e2cc7bc8cf3f159ba49>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1f77acb4e34034b00a5a2150384c9d77>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_510b48fcc953c4af1dbcb4b8cf19756a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3f849c6f51e31293c619565ac636bda7>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b0ef8716b08a7c90da37b162fe225b7a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_68f8064281287c2a20e44f23c72be5d5>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_84e0d1c8300760043597f8486883bb16>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f013722fb06ba87b6ded393d910c85c6>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c9cc85b6189178098c01bbceb71ba127>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2dc16cf30de15202e0434934c8ec0571>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dcbbb46dcb2ccb38f1b7e3e89a0ca172>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0031e1631721c75a1f7a0e71cb748ed7>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b6dee4d13517d8cf66ef1e240c3ec6a4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aecfda1830c0ee30e0e4a23c265062da>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1f3bf02585dcf20edf66f391042bccc5>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_57db475e5df80ef36653d188ca9951ac>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_edcbc83438e6dd39d1d927db086748d9>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d0fdf4211aa9516cbe57f435cdbb747f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5e0adb550519bb305a282a49bc052ff5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c765ee4079d8132e5b64fd41ad2c9a7d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_16bdac8a01801cd7a5fcb1f21cc7a9f0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3ce4407e5879111e6c1a6435d36077e4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_348952d4e8cb4d6ca40b91f67d9fe4cc>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_03c53d5c540d06d25e58298bd3e2675f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1e6c58f2c47fbfdcb340ca8aa595e354>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b881ee6a3336741e3e3697374c374936>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c6a4c758ec4a05da2df0a96bda1f195f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_18e0b70d8d5a276d72055cc8661094dd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1147aa6d38b42c0a8559813b3004180f>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_20ce3835ea17537cf13d089eb1a443c1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8226f92ae14eb377c8291a622693e68d>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_28d76a4078a4a8dbd4ec44ed08d36b25>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a131928ffa9f4254777de03dab7a31a7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_217211e0b9216fbae93bbaf0026e78ee>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_58e45bcf81f2eb4f6ae6b3f124defb13>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_56054d16adda54f2046f2f8778fd36d1>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8da27afb1f9e2f39230ce8504a3b22f1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e6687d53b2ff8a73e462a3df53da446b>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d86f3bcde641b4c18df519c60bc10d09>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b3ffb2b19f45444139b13fc0568f9537>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b24067cfb776b28c2465a46fad4c39cd>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_348a4c4053fb0e4fb238401e94ac3418>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1cdda74d195f4dc7bbdbaed3ee174bf7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6db08e7b535fdfa2ab543d6397b422f2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ec38228ee8b8eb97ec41ac102234721a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_91fdf8e96bd0363c4307fa79933bf9ee>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8a900b8b41180a41f1571bb2c4cf6f8e>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0a786afdc494302a03a8347211af4f5e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_81de0b469ab0f1e7bc6d7cfef2665991>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6d0547d7d9e564311a780ca9dc7db655>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ee988755aabf6d6b8cbe1162f42f9b60>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_939f4702fdcc80c80258913a08838422>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_965a3b769c39b0bedf189a3ea0545ea9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_19a25a0e0bced01a01388502a5fb897a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c277816ed3e96f001ac0003fb11da190>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_88b1496ecc213c07fd24b30bb5c856e7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3bf9d7b5239a137326d2c5fa821fa737>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0b84cd883df2cf8f5da7751da99be58c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a6d62ed7a3aadce21a3a08f0b111f7e9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6bf7af48e7a4158e20b4f833c15de130>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_221457049dd6e599b1e592be3898266a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5a03cad439a535c73c9479bab198ff8a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8059ce711ce14c36533947d64fa5a34>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3e2860b55958cf532cc6672e843fd5e5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b0f9e3c706f87be7af57692823441e06>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5169332acacd2cda6014329563a49097>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_82b38e81208f4cf45ccff9cab1f1ab56>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb618da91ef45dc5293c089a74c35488>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c5677617c2b0074bdccd3f6596388b76>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4e978ba75a8a0f3f4d2d1e75d74ac4de>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_64826d400df5e2683a863a4dbb954602>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2106de50a90423f7f3e101a627b3ccb6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cd453f5abbb4020fb3775475830cd8d1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_96fe9f03daad80a6076c498e634c5f49>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5dddc316c01bb02791c37b03fa523bb0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2aedfced5017e33ef2fd58df23b739b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c4dc4b2967ca7204e8ba49b0607e0250>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b1c0cff63caf505f6536baee30943a62>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d73f309e1e17ba4988eef7d15e33e2b5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ddff9a77cb22aafff303a88b4705bee2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_06e5eb766e97cbbd1e9836fc044820b5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_37fc46271b5a9d577e78557058b76819>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2d779c3a3c8b726adf3efb1bfd3cbb40>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_00b59445cb71ad9abff9006cdec65ab0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a935037996bf9e3d7f1925320992d343>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e41de5887194c6f47359224ea1f4265d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_52be072c62487a4543b8a1a3d2fbad23>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1d718ae1c6eee88a5015989ae3eac075>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_02cf852cc5a543f808433f03632ba155>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a976ac88d60c988f6c82762c8669484>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9283763b81fbf1c4441399956127b6eb>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aa831217bcc44892538d39aae8c330f6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0aa1cbb10b7e27c8eaa9e1c4d936a012>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1476157c6a284e4f379191854345eea5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53958a524045125d538038a834c170f9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a45f274125d5aab3ada44bd6d91ed7f6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9f22cccb787c8b0be66f7b40706128ae>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d7d65f11678621cb189879800cf53faf>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_73119717ae86d28cb548ac4543eb73ed>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_62526b7eac31a4fea5091c2f348a5e23>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2997ea06f466f3cb7af7580139e0e9b1>@@XAEAUInferenceContext@onnx@@@std@@
.?AUDataPropagationContext@onnx@@
.?AUDataPropagationContextImpl@shape_inference@onnx@@
.?AV?$_Func_impl_no_alloc@P6AXAEAUDataPropagationContext@onnx@@@ZXAEAU12@@std@@
.?AVAttributeProto@onnx@@
.?AVFunctionProto@onnx@@
.?AVGraphProto@onnx@@
.?AVModelProto@onnx@@
.?AVNodeProto@onnx@@
.?AVOperatorSetIdProto@onnx@@
.?AVSparseTensorProto@onnx@@
.?AVStringStringEntryProto@onnx@@
.?AVTensorAnnotation@onnx@@
.?AVTensorProto@onnx@@
.?AVTensorProto_Segment@onnx@@
.?AVTensorShapeProto@onnx@@
.?AVTensorShapeProto_Dimension@onnx@@
.?AVTrainingInfoProto@onnx@@
.?AVTypeProto@onnx@@
.?AVTypeProto_Map@onnx@@
.?AVTypeProto_Opaque@onnx@@
.?AVTypeProto_Optional@onnx@@
.?AVTypeProto_Sequence@onnx@@
.?AVTypeProto_SparseTensor@onnx@@
.?AVTypeProto_Tensor@onnx@@
.?AVValueInfoProto@onnx@@
.?AVMapProto@onnx@@
.?AVOptionalProto@onnx@@
.?AVSequenceProto@onnx@@
H0*d*
H@>p>
VS_VERSION_INFO
StringFileInfo
040904E4
CompanyName
Microsoft Corporation
FileDescription
ONNX Runtime
FileVersion
Internal Build
InternalName
ONNX Runtime
LegalCopyright
 Microsoft Corporation. All rights reserved.
OriginalFilename
onnxruntime.dll
ProductName
Microsoft
 Windows
 Operating System
ProductVersion
Internal Build
VarFileInfo
Translation
Washington1
Redmond1
Microsoft Corporation1(0&
Microsoft Code Signing PCA 20110
210902183300Z
220901183300Z0t1
Washington1
Redmond1
Microsoft Corporation1
Microsoft Corporation0
z*Xfb/B
I0G1-0+
$Microsoft Ireland Operations Limited1
230012+4675980
M0K0I
Chttp://www.microsoft.com/pkiops/crl/MicCodSigPCA2011_2011-07-08.crl0a
U0S0Q
Ehttp://www.microsoft.com/pkiops/certs/MicCodSigPCA2011_2011-07-08.crt0
/De-D
LU%)07Y
![WUT
:BKN3
vbnE4
{\.g\(#l);!|&:
Washington1
Redmond1
Microsoft Corporation1200
)Microsoft Root Certificate Authority 20110
110708205909Z
260708210909Z0~1
Washington1
Redmond1
Microsoft Corporation1(0&
Microsoft Code Signing PCA 20110
S0Q0O
Ihttp://crl.microsoft.com/pki/crl/products/MicRooCerAut2011_2011_03_22.crl0^
R0P0N
Bhttp://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt0
3http://www.microsoft.com/pkiops/docs/primarycps.htm0@
Legal_policy_statement
e_.,>
D=xz#
*?*kXIc
QEX82q'
WqVNHE
Washington1
Redmond1
Microsoft Corporation1(0&
Microsoft Code Signing PCA 2011
Microsof
http://www.microsoft.com0
bA4cI~
IOqD{
20220422162638.459Z0
Washington1
Redmond1
Microsoft Corporation1-0+
$Microsoft Ireland Operations Limited1&0$
Thales TSS ESN:0842-4BE6-C29A1%0#
Microsoft Time-Stamp Service
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 20100
211028192739Z
230126192739Z0
Washington1
Redmond1
Microsoft Corporation1-0+
$Microsoft Ireland Operations Limited1&0$
Thales TSS ESN:0842-4BE6-C29A1%0#
Microsoft Time-Stamp Service0
SF_#C
0w?2WP/
lq0rN
X0V0T
Nhttp://www.microsoft.com/pkiops/crl/Microsoft%20Time-Stamp%20PCA%202010(1).crl0l
`0^0\
Phttp://www.microsoft.com/pkiops/certs/Microsoft%20Time-Stamp%20PCA%202010(1).crt0
3oGmt
FL7t%
_Nl&It
D0$F3
pPUq*
Washington1
Redmond1
Microsoft Corporation1200
)Microsoft Root Certificate Authority 20100
210930182225Z
300930183225Z0|1
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 20100
q\Q17
&S|9a
!]_0t
U0S0Q
3http://www.microsoft.com/pkiops/Docs/Repository.htm0
O0M0K
Ehttp://crl.microsoft.com/pki/crl/products/MicRooCerAut_2010-06-23.crl0Z
N0L0J
>http://www.microsoft.com/pki/certs/MicRooCerAut_2010-06-23.crt0
>NGdx
fg:SM
xSu$W
as.,k{n?,
J>f;O
!TkjE
Washington1
Redmond1
Microsoft Corporation1-0+
$Microsoft Ireland Operations Limited1&0$
Thales TSS ESN:0842-4BE6-C29A1%0#
Microsoft Time-Stamp Service
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 20100
20220422124155Z
20220423124155Z0w0=
1/0-0
1(0&0
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 2010
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 2010
