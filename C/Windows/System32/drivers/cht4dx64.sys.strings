!This program cannot be run in DOS mode.
.text
h.rdata
H.data
.pdata
HPAGEFW
b.rsrc
B.reloc
L$ E3
WATAUAVAWH
A_A^A]A\_
L$ SVWH
@SUVWH
t$ WE3
p AWH
x AVH
x AWE3
|$(A_
x ATAVAWH
 A_A^A\
WAVAWH
 A_A^_
@SUVWAVH
A^_^][
D$@tPL
@SUVWAVH
A^_^][
UVWATAUAVAWH
A_A^A]A\_^]
x ATAVAWH
D$00bA
A_A^A\
@SUVWAVH
H!\$ I
D$(L+
L$hH3
pA^_^][
SUVWATAUAVAWH
8A_A^A]A\_^][
x ATAVAWH
 A_A^A\
UATAUAVAWH
D$PE3
A_A^A]A\]
L$ SH
L$ SH
L$ SH
UVWATAUAVAWH
T$XE3
D!d$8H
A_A^A]A\_^]
k VWAVH
T$HL#
 A^_^
x AVH
t$ WAVAWH
L$`H3
A_A^_
t$ WAVAWH
L$pH3
A_A^_
t$ WAVAWH
L$`H3
A_A^_
WATAUAVAWH
F !l$0H
N(H!l$(
A_A^A]A\_
x UATAUAVAWH
T$ HcH
A_A^A]A\]
` UAVAWH
A_A^]
WATAUAVAWH
 A_A^A]A\_
WAVAWH
0A_A^_
x AVH
\$ UVWATAUAVAWH
I;PPL
A_A^A]A\_^]
WAVAWH
D$hfA
 A_A^_
VWATAVAWH
!|$`3
!|$hD
 A_A^A\_^
\$0E3
WAVAWH
 A_A^_
l$ VWAVH
@USVWATAVAWH
A_A^A\_^[]
t$ WATAUAVAWH
 A_A^A]A\_
L$PH3
t$ WAVAWH
 A_A^_
@SUVWATAVAWH
L$PH3
`A_A^A\_^][
L$PH3
L$PH3
D$HE3
x ATAVAWH
 A_A^A\
@USVWATAUAVAWH
A_A^A]A\_^[]
@SUVWATAUAVAWH
D$DE:
L$`H3
xA_A^A]A\_^][
x AVH
VWATAVAWH
 A_A^A\_^
WATAUAVAWH
0A_A^A]A\_
@SUVWATAUAVAWH
8A_A^A]A\_^][
VWAVH
<@r@$
0A^_^
\$ UVWATAUAVAWH
L$HH3
PA_A^A]A\_^]
@UVWATAUAVAWH
L$@vtD
A_A^A]A\_^]
UVWAVAWH
A_A^_^]
@SVWH
L$PH3
UVWATAUAVAWH
M9&t^E
 A_A^A]A\_^]
T$hI;
T$hD+
UVWATAUAVAWH
|$pD3
A_A^A]A\_^]
fffffff
-fffffff
fffffff
fffffff
fffffff
.fffffff
fffffff
fffffff
After Aligning : virt addr = 0x%lx, physaddr.low = 0x%llx physaddr.high = 0x%lx
dma_mem_alloc failed!! out of pool region!!
dma_mem_alloc: curvirtaddr = 0x%x curphysaddr = 0x%x, size = 0x%x
func_init failed
dump_target_login failed
command %02x received
Did'nt get R2T
Failed to send dataout!! aborting!!
READ SCSI command!!
START_STOP_UNIT SCSI command 0x%x!!
Unhandled SCSI command 0x%x!!
SRB SHUTDOWN
Closed the Dumpmode iscsi session!
Failed to close the Dumpmode iscsi session!!!
Closed the dump mode tcp conn!
Failed to close Dump mode tcp conn!!!
Unhandled Srb function 0x%x
size of uncached extension = %d
Mapped length = %d
DMABLE MEM POOL------
 origvirtaddress = 0x%lx
, origphyaddress.low = 0x%lx origphyaddress.high = 0x%lx
alignedvirtaddress = 0x%lx
, alignedphyaddress.low = 0x%lx alignedphyaddress.high = 0x%lx
curvirtaddress = 0x%lx
, curphyaddress.low = 0x%lx curphyaddress.high = 0x%lx
ChidmpFindAdapter: Failed to setup DMA!!
HW Init Failed!!
IN DUMP MODE!
%02x 
hex string 0x%p (%d), 0x%p (%d).
hex string tlen %d < tolen %d.
hex string length odd %d.
bad hex char %c.
key-value pair %s, missing "=".
key-value pair %s, not terminated with NULL.
Could not find the key %s
CHAP_I
CHAP_C
HeaderDigest
%s: Tgt = %s Ini = %s
DataDigest
MaxRecvDataSegmentLength
%s: Tgt = %d Ini = %d
FirstBurstLength
MaxBurstLength
ImmediateData
InitialR2T
TargetName=%s
InitiatorName=%s
InitiatorAlias=iscsi_ibft1
AuthMethod=CHAP
SessionType=Normal
CHAP_A=5,7
CHAP_N=%s
CHAP_R=%s
CHAP_I=%d
CHAP_C=%s
HeaderDigest=%s
DataDigest=%s
MaxRecvDataSegmentLength=%s
OFMarker=No
IFMarker=No
MaxConnections=1
InitialR2T=%s
MaxOutstandingR2T=1
ImmediateData=%s
FirstBurstLength=%s
MaxBurstLength=%s
DefaultTime2Wait=2
DefaultTime2Retain=20
DataPDUInOrder=Yes
DataSequenceInOrder=Yes
ErrorRecoveryLevel=0
DataSegmentLength = %d
CRC32C
16384
iqn.2004-05.com.chelsio.dumper
statemachine broke at AUTH_INITIATOR_NONE
statemachine broke at AUTH_INITIATOR_CHALLENGE
secured login completed!!
statemachine broke at AUTH_INITIATOR_RESPONSE
We received a non target opcode!!
ISCSI LOGIN RESP got !!! status = %d
Login Failed!!!!
iscsi login response ->
CHAP_N
CHAP_R
ISCSI LOGOUT RESP got !!! status = %d
Logout Failed!!!!
ISCSI REJECT Received !! reason 0x%x
REJECT PDU is --
ISCSI Async message.. doing logout!!
Closed the Dumpmode iscsi session
Closed the dump mode tcp connection
ISCSI_OPCODE_SCSI_DATA_IN got!! status = %d
scsi response ->
more data received!! pldlen = %d expected len = %d
copied response data.. resp payload len = 0x%x
status = 0x%x Failure!!
Crash
During Device Preparation
During Device Configuration
During Device Initialization
Unexpected Event
Insufficient Airflow
Device Shutdown
Reserved
RXNP array parity error
RXPC array parity error
RXCIF array parity error
Rx completions control array parity error
RXFT array parity error
TXPC array parity error
TXNP array parity error
TXFT array parity error
TXCA array parity error
TXCIF array parity error
RXCA array parity error
outbound request TLP discarded
Rx data parity error
Tx uncorrectable data error
MSI AddrL parity error
MSI AddrH parity error
MSI data parity error
MSI-X AddrL parity error
MSI-X AddrH parity error
MSI-X data parity error
MSI-X DI parity error
PCI PIO completion FIFO parity error
PCI PIO request FIFO parity error
PCI PCI target tag FIFO parity error
PCI CMD channel count parity error
PCI CMD channel request parity error
PCI CMD channel response parity error
PCI DMA channel count parity error
PCI DMA channel request parity error
PCI DMA channel response parity error
PCI HMA channel count parity error
PCI HMA channel request parity error
PCI HMA channel response parity error
PCI config snoop FIFO parity error
PCI FID parity error
PCI INTx clear parity error
PCI MA tag parity error
PCI PIO tag parity error
PCI Rx completion parity error
PCI Rx write parity error
PCI replay buffer parity error
PCI core secondary fault
PCI core primary fault
PCI unexpected split completion error
Master Response Read Queue parity error
Master Timeout FIFO parity error
MSI-X STI SRAM parity error
PCI PIO completion Group FIFO parity error
PCI PIO request Group FIFO parity error
PCI master tag queue parity error
PCI DMA channel write request parity error
PCI MA group FIFO parity error
PCI IP Rx header group parity error
PCI IP Rx data group parity error
PCI IP replay buffer parity error
PCI IP SOT buffer parity error
PCI TRGT1 group FIFOs parity error
Outbound read error
TP parity error
TP out of Tx pages
SGE received CPL exceeding IQE size
SGE GTS CIDX increment too large
SGE received 0-length CPL
SGE IQID > 1023 received CPL for FL
SGE DBP 3 pidx increment too large
SGE DBP 2 pidx increment too large
SGE DBP 1 pidx increment too large
SGE DBP 0 pidx increment too large
SGE too many priority ingress contexts
SGE illegal ingress QID
SGE illegal egress QID
SGE PCIe error for a DBP thread
SGE too many priority egress contexts
SGE Actual WRE packet is less than advertized length
CIM control register prefetch drop
CIM OBQ parity error
CIM IBQ parity error
CIM mailbox uP parity error
CIM mailbox host parity error
CIM TIEQ outgoing parity error
CIM TIEQ incoming parity error
CIM TIMER0 interrupt
CIM reserved space access
CIM illegal transaction
CIM illegal write
CIM illegal read
CIM illegal read BE
CIM illegal write BE
CIM single read from boot space
CIM single write to boot space
CIM block write to boot space
CIM single read from flash space
CIM single write to flash space
CIM block write to flash space
CIM single EEPROM read
CIM single EEPROM write
CIM block EEPROM read
CIM block EEPROM write
CIM single read from CTL space
CIM single write to CTL space
CIM block read from CTL space
CIM block write to CTL space
CIM single read from PL space
CIM single write to PL space
CIM block read from PL space
CIM block write to PL space
CIM request FIFO overwrite
CIM response FIFO overwrite
CIM PIF timeout
CIM PIF MA timeout
ULPRX channel 1 context error
ULPRX channel 0 context error
ULPRX parity error
ULPTX channel 3 PBL out of bounds
ULPTX channel 2 PBL out of bounds
ULPTX channel 1 PBL out of bounds
ULPTX channel 0 PBL out of bounds
ULPTX parity error
PMTX channel 0 pcmd too large
PMTX channel 1 pcmd too large
PMTX channel 2 pcmd too large
PMTX 0-length pcmd
PMTX framing error
PMTX oespi parity error
PMTX db_options parity error
PMTX icspi parity error
PMTX c_pcmd parity error
PMRX 0-length pcmd
PMRX framing error
PMRX ocspi parity error
PMRX db_options parity error
PMRX iespi parity error
PMRX e_pcmd parity error
CPLSW CIM op_map parity error
CPLSW CIM overflow
CPLSW TP framing error
CPLSW SGE framing error
CPLSW CIM framing error
CPLSW no-switch error
LE LIP miss
LE 0 LIP error
LE parity error
LE unknown command
LE request queue parity error
MPS Rx parity error
MPS Tx TP FIFO parity error
MPS Tx NC-SI FIFO parity error
MPS Tx data FIFO parity error
MPS Tx desc FIFO parity error
MPS Tx underflow
MPS Tx SOP/EOP error
MPS Tx framing error
MPS TRC filter parity error
MPS TRC packet FIFO parity error
MPS TRC misc parity error
MPS statistics SRAM parity error
MPS statistics Tx FIFO parity error
MPS statistics Rx FIFO parity error
MPS match SRAM parity error
MPS match TCAM parity error
MPS hash SRAM parity error
SMB master Tx FIFO parity error
SMB master Rx FIFO parity error
SMB slave FIFO parity error
NC-SI CIM parity error
NC-SI MPS parity error
NC-SI Tx FIFO parity error
NC-SI Rx FIFO parity error
UART Parity Error
ULP TX Parity Error
SGE Parity Error
HMA Parity Error
CPL Switch Parity Error
ULP RX Parity Error
PM RX Parity Error
PM TX Parity Error
MA Parity Error
TP Parity Error
LE Parity Error
EDC1 Parity Error
EDC0 Parity Error
MC Parity Error
PCIE Parity Error
PMU Parity Error
XGMAC_KR1 Parity Error
XGMAC_KR0 Parity Error
XGMAC1 Parity Error
XGMAC0 Parity Error
SMB Parity Error
SF Parity Error
PL Parity Error
NCSI Parity Error
MPS Parity Error
MI Parity Error
DBG Parity Error
I2CM Parity Error
CIM Parity Error
Fatal parity error
PL VFID_MAP parity error
Fiber_XFI
Fiber_XAUI
BT_SGMII
BT_XFI
BT_XAUI
BP_AP
BP4_AP
QSFP_10G
BP40_BA
KR4_100G
CR4_QSFP
CR_QSFP
CR2_QSFP
SFP28
KR_SFP28
KR_XLAUI
IDMA_IDLE
IDMA_PUSH_MORE_CPL_FIFO
IDMA_PUSH_CPL_MSG_HEADER_TO_FIFO
Not used
IDMA_PHYSADDR_SEND_PCIEHDR
IDMA_PHYSADDR_SEND_PAYLOAD_FIRST
IDMA_PHYSADDR_SEND_PAYLOAD
IDMA_SEND_FIFO_TO_IMSG
IDMA_FL_REQ_DATA_FL_PREP
IDMA_FL_REQ_DATA_FL
IDMA_FL_DROP
IDMA_FL_H_REQ_HEADER_FL
IDMA_FL_H_SEND_PCIEHDR
IDMA_FL_H_PUSH_CPL_FIFO
IDMA_FL_H_SEND_CPL
IDMA_FL_H_SEND_IP_HDR_FIRST
IDMA_FL_H_SEND_IP_HDR
IDMA_FL_H_REQ_NEXT_HEADER_FL
IDMA_FL_H_SEND_NEXT_PCIEHDR
IDMA_FL_H_SEND_IP_HDR_PADDING
IDMA_FL_D_SEND_PCIEHDR
IDMA_FL_D_SEND_CPL_AND_IP_HDR
IDMA_FL_D_REQ_NEXT_DATA_FL
IDMA_FL_SEND_PCIEHDR
IDMA_FL_PUSH_CPL_FIFO
IDMA_FL_SEND_CPL
IDMA_FL_SEND_PAYLOAD_FIRST
IDMA_FL_SEND_PAYLOAD
IDMA_FL_REQ_NEXT_DATA_FL
IDMA_FL_SEND_NEXT_PCIEHDR
IDMA_FL_SEND_PADDING
IDMA_FL_SEND_COMPLETION_TO_IMSG
IDMA_FL_SEND_FIFO_TO_IMSG
IDMA_FL_REQ_DATAFL_DONE
IDMA_FL_REQ_HEADERFL_DONE
IDMA_ALMOST_IDLE
IDMA_SGEFLRFLUSH_SEND_PCIEHDR
IDMA_FL_DROP_SEND_INC
Link Down
Remote Fault
Auto-negotiation Failure
Unable To Determine Reason
No RX Signal Detected
Firmware reports adapter error: %s
FW assertion at %.16s:%u, val0 %#x, val1 %#x
found VALID command in mbox %u: %llx %llx %llx %llx %llx %llx %llx %llx
command %#x in mailbox %d timed out
Unable to read PCI-E Memory Window Base[%d]
Requested Port Capabilities %#x exceed Physical Port Capabilities %#x
Requested Port Capabilities %#x rejected, error %d
%s (0x%x)
TP E2C Channel Port Index %d >= Nports %d
Device didn't become ready for access, whoami = %#x
Unknown Flash Part, ID = %#x, assuming 4MB
WARNING: Flash Part ID %#x, size %#x < %#x
Device %d is not supported
T4 rev 1 chip is no longer supported
Unable to retrieve Flash parameters ret = %d
 *** CH_ERROR *** %s
 *** CH_WARN *** %s
 *** CH_ALERT *** %s
Failed to allocate DMA buffer
Failed to alloc mem for ring
prepare_fw_iq_cmd: fwevtq = 0x%x, intridx = 0x%x
Failed to alloc fl dma ring
Failed to alloc dma hdl ring
Failed to alloc dma handle for entry %d
Failed to alloc fl buffer %d
Failed to send mbox command ret = %d!!
Failed to alloc fl buffers
fl0cntxt = 0x%x
Created iq: cntxtid = 0x%x, abs_id = 0x%x, msi_idx = 0x%x
Failed to alloc ofld txq ring
Failed to alloc ctrl txq ring
Failed to alloc eth txq ring
build_rxq: ofldrxq: failed!!
Creating ofld txQ
alloc-txq ofldq failed!!
Creating ctrl txQ
alloc-txq ctrlq failed!!
Creating eth txQ
alloc-txq ethq failed!!
t4_link_l1cfg failed ret %d
t4_set_rxmode failed
t4_change_mac failed
enable_vi failed
func_init failed
ethpkt exceeds max wr length!!
tun tx q is full!!!
ofld q is full
CPL_L2T_WRITE_RPL got!!
CPL_ACT_ESTABLISH: tid = 0x%x atid 0x%x sendseq = 0x%x rcvseq = 0x%x
CPL_ACT_OPEN_RPL: atid = 0x%x status = %d
CPL_CLOSE_CON_RPL got!!
CPL_PEER_CLOSE got!!
CPL_SET_TCB_RPL got!!
CPL_GET_TCB_RPL got!!
new cpl 0x%x
Did'nt get the response! Expecting Storport to resend this IO!!
Failed to add l2t entry
configured l2t entry
Failed to write smt entry
configured smt entry
vlanid = %d
hdigest = %d ddigest = %d
Established TCP Conn with srcport = %d
dump connection tid = %d
auth type = %d
Failed login authentication!!
vid = 0x%x
Found a Chelsio Device!!
 NicSgeInitSoft: bad SGE CPL MODE
 SgeInitSoft: bad SGE FL page buffer sizes [%d, %d]
 SgeInitSoft: bad SGE FL MTU sizes [%d, %d]
SgeInitSoft failed
NicLoadCfgFile
%s: Loading BuiltIn T5/T6 Cfg file
%s: Successfully configured using Firmware Configuration File "Firmware Default" 
Failed to alloc mem for adapter
could'nt find a Chelsio Device!!
T4 prep adapter failed err %d
Incorrect SGE EGRESS QUEUES_PER_PAGE configuration, continuing in debug mode
T4 memwin setup
T5 memwin setup
BusInit: Could not contact firmware %d
No Config File support..todo
BusInit: Firmware reset failed %d
BusInit: Error loading config file %d
adapter cfgfile maddr = 0x%x
Error in parsing cfg file %d
 Configuration File checksum mismatch: [fini] csum=%#x, computed csum=%#x
Error using config file %d
BusInit: t4_fw_initialize error %d
BusInit: t4_query_params error %d
 BusInit: Port Vector:0x%08X NumPorts:%d
BusInit: t4_port_init error %d
BusInit: t4_alloc_vi_func error %d
cht4dx64.pdb
.text$mn
.text$mn$00
.text$mn$21
.text$s
.idata$5
.00cfg
.gfids
.rdata
.rdata$zzzdbg
.xdata
.data
.pdata
PAGEFW
.idata$2
.idata$3
.idata$4
.idata$6
.rsrc$01
.rsrc$02
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=
MC/MC0
ddddddd
 !"#dddddd
# Chelsio T6 SMB direct configuration file.
# Copyright (C) 2010-2017 Chelsio Communications.  All rights reserved.
#   DO NOT MODIFY THIS FILE UNDER ANY CIRCUMSTANCES.  MODIFICATION OF THIS FILE
#   WILL RESULT IN A NON-FUNCTIONAL ADAPTER AND MAY RESULT IN PHYSICAL DAMAGE
#   TO ADAPTERS.
# This file provides the default, power-on configuration for 2-port T6-based
# adapters shipped from the factory.  These defaults are designed to address
# the needs of the vast majority of Terminator customers.  The basic idea is to
# have a default configuration which allows a customer to plug a Terminator
# adapter in and have it work regardless of OS, driver or application except in
# the most unusual and/or demanding customer applications.
# Many of the Terminator resources which are described by this configuration
# are finite.  This requires balancing the configuration/operation needs of
# device drivers across OSes and a large number of customer application.
# Some of the more important resources to allocate and their constaints are:
#  1. Virtual Interfaces: 256.
#  2. Ingress Queues with Free Lists: 1024.
#  3. Egress Queues: 128K.
#  4. MSI-X Vectors: 1088.
#  5. Multi-Port Support (MPS) TCAM: 336 entries to support MAC destination
#     address matching on Ingress Packets.
# Some of the important OS/Driver resource needs are:
#  6. Some OS Drivers will manage all resources through a single Physical
#     Function (currently PF4 but it could be any Physical Function).
#  7. Some OS Drivers will manage different ports and functions (NIC,
#     storage, etc.) on different Physical Functions.  For example, NIC
#     functions for ports 0-1 on PF0-3, FCoE on PF4, iSCSI on PF5, etc.
# Some of the customer application needs which need to be accommodated:
#  8. Some customers will want to support large CPU count systems with
#     good scaling.  Thus, we'll need to accommodate a number of
#     Ingress Queues and MSI-X Vectors to allow up to some number of CPUs
#     to be involved per port and per application function.  For example,
#     in the case where all ports and application functions will be
#     managed via a single Unified PF and we want to accommodate scaling up
#     to 8 CPUs, we would want:
#         4 ports *
#         3 application functions (NIC, FCoE, iSCSI) per port *
#         16 Ingress Queue/MSI-X Vectors per application function
#     for a total of 96 Ingress Queues and MSI-X Vectors on the Unified PF.
#     (Plus a few for Firmware Event Queues, etc.)
#  9. Some customers will want to use PCI-E SR-IOV Capability to allow Virtual
#     Machines to directly access T6 functionality via SR-IOV Virtual Functions
#     and "PCI Device Passthrough" -- this is especially true for the NIC
#     application functionality.
# Global configuration settings.
[global]
rss_glb_config_mode = basicvirtual
rss_glb_config_options = tnlmapen,hashtoeplitz,tnlalllkp
rss_keymode = idxvf_key #Other modes: glb_key, glbvf_key, pfvf_key
# PL_TIMEOUT register
pl_timeout_value = 200
# the timeout value in units of us
# The following Scatter Gather Engine (SGE) settings assume a 4KB Host
# Page Size and a 64B L1 Cache Line Size. It programs the
# EgrStatusPageSize and IngPadBoundary to 64B and the PktShift to 2.
# If a Master PF Driver finds itself on a machine with different
# parameters, then the Master PF Driver is responsible for initializing
# these parameters to appropriate values.
# Notes:
#  1. The Free List Buffer Sizes below are raw and the firmware will
#     round them up to the Ingress Padding Boundary.
#  2. The SGE Timer Values below are expressed below in microseconds.
#     The firmware will convert these values to Core Clock Ticks when
#     it processes the configuration parameters.
reg[0x1008] = 0x40800/0x21c70
# SGE_CONTROL
reg[0x100c] = 0x22222222
# SGE_HOST_PAGE_SIZE
reg[0x10a0] = 0x01040810
# SGE_INGRESS_RX_THRESHOLD
reg[0x1044] = 4096
# SGE_FL_BUFFER_SIZE0
reg[0x1048] = 65536
# SGE_FL_BUFFER_SIZE1
reg[0x104c] = 1536
# SGE_FL_BUFFER_SIZE2
reg[0x1050] = 9024
# SGE_FL_BUFFER_SIZE3
reg[0x1054] = 9216
# SGE_FL_BUFFER_SIZE4
reg[0x1058] = 2048
# SGE_FL_BUFFER_SIZE5
reg[0x105c] = 128
# SGE_FL_BUFFER_SIZE6
reg[0x1060] = 8192
# SGE_FL_BUFFER_SIZE7
reg[0x1064] = 16384
# SGE_FL_BUFFER_SIZE8
sge_timer_value = 5, 10, 20, 50, 100, 200 # SGE_TIMER_VALUE* in usecs
reg[0x10c4] = 0x20000000/0x20000000 # GK_CONTROL, enable 5th thread
# enable TP_OUT_CONFIG.IPIDSPLITMODE
reg[0x7d04] = 0x00010000/0x00010000
# TP_SHIFT_CNT - set SYN shift count to 4 for quicker connect timeouts
reg[0x7dc0] = 0x042f8849
# TP_SHIFT_CNT
#Tick granularities in kbps
tsch_ticks = 100000, 10000, 1000, 10
# TP_VLAN_PRI_MAP to select filter tuples and enable ServerSram
# filter control: compact, fcoemask
# server sram   : srvrsram
# filter tuples : fragmentation, mpshittype, macmatch, ethertype,
  protocol, tos, vlan, vnic_id, port, fcoe
# valid filterModes are described the Terminator 5 Data Book
filterMode = fcoemask, fragmentation, mpshittype, macmatch, protocol, tos, port, fcoe
# filter tuples enforced in LE active region (equal to or subset of filterMode)
filterMask = protocol, fcoe
# Percentage of dynamic memory (in either the EDRAM or external MEM)
# to use for TP RX payload
tp_pmrx = 20
# TP RX payload page size
tp_pmrx_pagesize = 64K
# TP number of RX channels
tp_nrxch = 0
# 0 (auto) = 1
# Percentage of dynamic memory (in either the EDRAM or external MEM)
# to use for TP TX payload
tp_pmtx = 30
# TP TX payload page size
tp_pmtx_pagesize = 64K
# TP number of TX channels
tp_ntxch = 0
# 0 (auto) = equal number of ports
# TP OFLD MTUs
tp_mtus = 88, 256, 512, 576, 808, 1024, 1280, 1488, 1500, 2002, 2048, 4096, 4352, 8192, 9000, 9600
# enable TP_OUT_CONFIG.IPIDSPLITMODE and CRXPKTENC
reg[0x7d04] = 0x00010008/0x00010008
# TP TCP hardware stack tuning
tp_tcptuning = cluster
# wan, lan or cluster
# TP_GLOBAL_CONFIG
reg[0x7d08] = 0x00000800/0x00000800 # set IssFromCplEnable
# TP_PC_CONFIG
reg[0x7d48] = 0x00000000/0x00000400 # clear EnableFLMError
# TP_PARA_REG0
reg[0x7d60] = 0x06000000/0x07000000 # set InitCWND to 6
# LE_DB_CONFIG
reg[0x19c04] = 0x00000000/0x00440000 # LE Server SRAM disabled
     # LE IPv4 compression disabled 
# LE_DB_HASH_CONFIG
reg[0x19c28] = 0x00800000/0x01f00000 # LE Hash bucket size 8
# ULP_TX_CONFIG
reg[0x8dc0] = 0x00000004/0x00000004 # Enable more error msg for ...
    # TPT error.
# ULP_RX_MISC_FEATURE_ENABLE
#reg[0x1925c] = 0x01003400/0x01003400 # iscsi tag pi bit
                                             # Enable offset decrement after ...
     # PI extraction and before DDP
     # ulp insert pi source info in DIF
     # iscsi_eff_offset_en
#Enable iscsi completion moderation feature
reg[0x1925c] = 0x000041c0/0x000031c0
# Enable offset decrement after
# PI extraction and before DDP.
# ulp insert pi source info in
# DIF.
# Enable iscsi hdr cmd mode.
# iscsi force cmd mode.
# Enable iscsi cmp mode.
# HMA configuration
hma_size = 96
# Size (in MBs) of host memory expected
hma_regions = stag,pbl,rq
# What all regions to place in host memory
# Some "definitions" to make the rest of this a bit more readable.  We support
# 4 ports, 3 functions (NIC, FCoE and iSCSI), scaling up to 8 "CPU Queue Sets"
# per function per port ...
# NMSIX = 1088
# available MSI-X Vectors
# NVI = 256
# available Virtual Interfaces
# NMPSTCAM = 336
# MPS TCAM entries
# NPORTS = 2
# ports
# NCPUS = 16
# CPUs we want to support scalably
# NFUNCS = 3
# functions per port (NIC, FCoE, iSCSI)
# RSSNSECRET = 16
# available 320b entries in rss secret table
# Breakdown of Virtual Interface/Queue/Interrupt resources for the "Unified
# PF" which many OS Drivers will use to manage most or all functions.
# Each Ingress Queue can use one MSI-X interrupt but some Ingress Queues can
# use Forwarded Interrupt Ingress Queues.  For these latter, an Ingress Queue
# would be created and the Queue ID of a Forwarded Interrupt Ingress Queue
# will be specified as the "Ingress Queue Asynchronous Destination Index."
# Thus, the number of MSI-X Vectors assigned to the Unified PF will be less
# than or equal to the number of Ingress Queues ...
# NVI_NIC = 4
# NIC access to NPORTS
# NFLIQ_NIC = 32
# NIC Ingress Queues with Free Lists
# NETHCTRL_NIC = 32
# NIC Ethernet Control/TX Queues
# NEQ_NIC = 64
# NIC Egress Queues (FL, ETHCTRL/TX)
# NMPSTCAM_NIC = 16
# NIC MPS TCAM Entries (NPORTS*4)
# NMSIX_NIC = 32
# NIC MSI-X Interrupt Vectors (FLIQ)
# NVI_OFLD = 0
# Offload uses NIC function to access ports
# NFLIQ_OFLD = 16
# Offload Ingress Queues with Free Lists
# NETHCTRL_OFLD = 0
# Offload Ethernet Control/TX Queues
# NEQ_OFLD = 16
# Offload Egress Queues (FL)
# NMPSTCAM_OFLD = 0
# Offload MPS TCAM Entries (uses NIC's)
# NMSIX_OFLD = 16
# Offload MSI-X Interrupt Vectors (FLIQ)
# NVI_RDMA = 0
# RDMA uses NIC function to access ports
# NFLIQ_RDMA = 4
# RDMA Ingress Queues with Free Lists
# NETHCTRL_RDMA = 0
# RDMA Ethernet Control/TX Queues
# NEQ_RDMA = 4
# RDMA Egress Queues (FL)
# NMPSTCAM_RDMA = 0
# RDMA MPS TCAM Entries (uses NIC's)
# NMSIX_RDMA = 4
# RDMA MSI-X Interrupt Vectors (FLIQ)
# NEQ_WD = 128
# Wire Direct TX Queues and FLs
# NETHCTRL_WD = 64
# Wire Direct TX Queues
# NFLIQ_WD = 64
# Wire Direct Ingress Queues with Free Lists
# NVI_ISCSI = 4
# ISCSI access to NPORTS
# NFLIQ_ISCSI = 4
# ISCSI Ingress Queues with Free Lists
# NETHCTRL_ISCSI = 0
# ISCSI Ethernet Control/TX Queues
# NEQ_ISCSI = 4
# ISCSI Egress Queues (FL)
# NMPSTCAM_ISCSI = 4
# ISCSI MPS TCAM Entries (NPORTS)
# NMSIX_ISCSI = 4
# ISCSI MSI-X Interrupt Vectors (FLIQ)
# NVI_FCOE = 4
# FCOE access to NPORTS
# NFLIQ_FCOE = 34
# FCOE Ingress Queues with Free Lists
# NETHCTRL_FCOE = 32
# FCOE Ethernet Control/TX Queues
# NEQ_FCOE = 66
# FCOE Egress Queues (FL)
# NMPSTCAM_FCOE = 32 
# FCOE MPS TCAM Entries (NPORTS)
# NMSIX_FCOE = 34
# FCOE MSI-X Interrupt Vectors (FLIQ)
# Two extra Ingress Queues per function for Firmware Events and Forwarded
# Interrupts, and two extra interrupts per function for Firmware Events (or a
# Forwarded Interrupt Queue) and General Interrupts per function.
# NFLIQ_EXTRA = 6
# "extra" Ingress Queues 2*NFUNCS (Firmware and
#   Forwarded Interrupts
# NMSIX_EXTRA = 6
# extra interrupts 2*NFUNCS (Firmware and
#   General Interrupts
# Microsoft HyperV resources.  The HyperV Virtual Ingress Queues will have
# their interrupts forwarded to another set of Forwarded Interrupt Queues.
# NVI_HYPERV = 16
# VMs we want to support
# NVIIQ_HYPERV = 2
# Virtual Ingress Queues with Free Lists per VM
# NFLIQ_HYPERV = 40
# VIQs + NCPUS Forwarded Interrupt Queues
# NEQ_HYPERV = 32
# VIQs Free Lists
# NMPSTCAM_HYPERV = 16
# MPS TCAM Entries (NVI_HYPERV)
# NMSIX_HYPERV = 8
# NCPUS Forwarded Interrupt Queues
# Adding all of the above Unified PF resource needs together: (NIC + OFLD +
# RDMA + ISCSI + FCOE + EXTRA + HYPERV)
# NVI_UNIFIED = 28
# NFLIQ_UNIFIED = 106
# NETHCTRL_UNIFIED = 32
# NEQ_UNIFIED = 124
# NMPSTCAM_UNIFIED = 40
# The sum of all the MSI-X resources above is 74 MSI-X Vectors but we'll round
# that up to 128 to make sure the Unified PF doesn't run out of resources.
# NMSIX_UNIFIED = 128
# The Storage PFs could need up to NPORTS*NCPUS + NMSIX_EXTRA MSI-X Vectors
# which is 34 but they're probably safe with 32.
# NMSIX_STORAGE = 32
# Note: The UnifiedPF is PF4 which doesn't have any Virtual Functions
# associated with it.  Thus, the MSI-X Vector allocations we give to the
# UnifiedPF aren't inherited by any Virtual Functions.  As a result we can
# provision many more Virtual Functions than we can if the UnifiedPF were
# one of PF0-3.
# All of the below PCI-E parameters are actually stored in various *_init.txt
# files.  We include them below essentially as comments.
# For PF0-3 we assign 8 vectors each for NIC Ingress Queues of the associated
# ports 0-3.
# For PF4, the Unified PF, we give it an MSI-X Table Size as outlined above.
# For PF5-6 we assign enough MSI-X Vectors to support FCoE and iSCSI
# storage applications across all four possible ports.
# Additionally, since the UnifiedPF isn't one of the per-port Physical
# Functions, we give the UnifiedPF and the PF0-3 Physical Functions
# different PCI Device IDs which will allow Unified and Per-Port Drivers
# to directly select the type of Physical Function to which they wish to be
# attached.
# Note that the actual values used for the PCI-E Intelectual Property will be
# 1 less than those below since that's the way it "counts" things.  For
# readability, we use the number we actually mean ...
# PF0_INT = 8
# NCPUS
# PF1_INT = 8
# NCPUS
# PF2_INT = 8
# NCPUS
# PF3_INT = 8
# NCPUS
# PF0_3_INT = 32
# PF0_INT + PF1_INT + PF2_INT + PF3_INT
# PF4_INT = 128
# NMSIX_UNIFIED
# PF5_INT = 32
# NMSIX_STORAGE
# PF6_INT = 32
# NMSIX_STORAGE
# PF7_INT = 0
# Nothing Assigned
# PF4_7_INT = 192
# PF4_INT + PF5_INT + PF6_INT + PF7_INT
# PF0_7_INT = 224
# PF0_3_INT + PF4_7_INT
# With the above we can get 17 VFs/PF0-3 (limited by 336 MPS TCAM entries)
# but we'll lower that to 16 to make our total 64 and a nice power of 2 ...
# NVF = 16
# Some OS Drivers manage all application functions for all ports via PF4.
# Thus we need to provide a large number of resources here.  For Egress
# Queues we need to account for both TX Queues as well as Free List Queues
# (because the host is responsible for producing Free List Buffers for the
# hardware to consume).
[function "4"]
wx_caps = all
# write/execute permissions for all commands
r_caps = all
# read permissions for all commands
nvi = 34
# NVI_UNIFIED
rssnsecret = 16
# all 16 table entries to PF 4
rssnvi = 32
niqflint = 170
# NFLIQ_UNIFIED + NLFIQ_WD
nethctrl = 100
# NETHCTRL_UNIFIED + NETHCTRL_WD
neq = 256
# NEQ_UNIFIED + NEQ_WD
nexactf = 256
# NMPSTCAM_UNIFIED
nrawf = 2
nqpcq = 12288
cmask = all
# access to all channels
pmask = all
# access to all four ports ...
nclip = 384
# number of clip region entries
nfilter = 368
# number of filter region entries
nserver = 128
# number of server region entries
nhash = 14336
# number of hash region entries
protocol = nic_vm, ofld, rddp, rdmac, iscsi_initiator_pdu
tp_l2t = 4096
tp_ddp = 1
tp_ddp_iscsi = 1
tp_stag = 5
tp_pbl = 34
tp_rq = 10
[function "6"]
wx_caps = all
# write/execute permissions for all commands
r_caps = all
# read permissions for all commands
nvi = 4
# NPORTS
niqflint = 34
# NPORTS*NCPUS + NMSIX_EXTRA
nethctrl = 32
# NPORTS*NCPUS
neq = 66
# NPORTS*NCPUS * 2 (FL, ETHCTRL/TX) + 2 (EXTRA)
nexactf = 32
# NPORTS + adding 28 exact entries for FCoE
# which is OK since < MIN(SUM PF0..3, PF4)
# and we never load PF0..3 and PF4 concurrently
cmask = all
# access to all channels
pmask = all
# access to all four ports ...
nhash = 2048
tp_l2t = 4
protocol = fcoe_initiator
tp_ddp = 2
fcoe_nfcf = 16
fcoe_nvnp = 32
fcoe_nssn = 1024
# The following function, 1023, is not an actual PCIE function but is used to
# configure and reserve firmware internal resources that come from the global
# resource pool.
[function "1023"]
wx_caps = all
# write/execute permissions for all commands
r_caps = all
# read permissions for all commands
nvi = 4
# NVI_UNIFIED
cmask = all
# access to all channels
pmask = all
# access to all four ports ...
nexactf = 8
# NPORTS + DCBX +
nfilter = 16
# number of filter region entries
# For Virtual functions, we only allow NIC functionality and we only allow
# access to one port (1 << PF).  Note that because of limitations in the
# Scatter Gather Engine (SGE) hardware which checks writes to VF KDOORBELL
# and GTS registers, the number of Ingress and Egress Queues must be a power
# of 2.
[function "0/*"]
# NVF
nvi = 1
# 1 port
rssnvi = 0
[function "1/*"]
# NVF
nvi = 1
# 1 port
rssnvi = 0
[function "2/*"]
# NVF
nvi = 1
# 1 port
rssnvi = 0
[function "3/*"]
# NVF
nvi = 1
# 1 port
rssnvi = 0
[function "4/*"]
# NVF
wx_caps = 0x82
# DMAQ | VF
r_caps = 0x86
# DMAQ | VF | PORT
nvi = 1
# 1 port
rssnvi = 1
niqflint = 11
# 8 "Queue Sets" + CIQ + FWEVTQ + FWDINTRQ 
nethctrl = 8
# 8 "Queue Sets"
neq = 16
# 8 "Queue Sets" * 2
nexactf = 4
cmask = all
# access to all channels
pmask = all 
# access to all ports
nqpcq = 78
protocol = ofld, rdmac
# MPS features a 196608 bytes ingress buffer that is used for ingress buffering
# for packets from the wire as well as the loopback path of the L2 switch. The
# folling params control how the buffer memory is distributed and the L2 flow
# control settings:
# bg_mem:
%-age of mem to use for port/buffer group
# lpbk_mem:
%-age of port/bg mem to use for loopback
# hwm:
high watermark; bytes available when starting to send pause
frames (in units of 0.1 MTU)
# lwm:
low watermark; bytes remaining when sending 'unpause' frame
(in inuits of 0.1 MTU)
# dwm:
minimum delta between high and low watermark (in units of 100
Bytes)
[port "0"]
dcb = ppp, dcbx
# configure for DCB PPP and enable DCBX offload
dcb_dcbx_protocol = auto
hwm = 60
lwm = 15
dwm = 30
dcb_app_tlv[0] = 0x8906, ethertype, 3
dcb_app_tlv[1] = 0x8914, ethertype, 3
dcb_app_tlv[2] = 3260, socketnum, 5
[port "1"]
dcb = ppp, dcbx
dcb_dcbx_protocol = auto
hwm = 60
lwm = 15
dwm = 30
dcb_app_tlv[0] = 0x8906, ethertype, 3
dcb_app_tlv[1] = 0x8914, ethertype, 3
dcb_app_tlv[2] = 3260, socketnum, 5
[fini]
version = 0x08000025
checksum = 0x7632c817
# Total resources used by above allocations:
#   Virtual Interfaces: 104
#   Ingress Queues/w Free Lists and Interrupts: 526
#   Egress Queues: 702
#   MPS TCAM Entries: 336
#   MSI-X Vectors: 736
#   Virtual Functions: 64
# Chelsio T5 SMB configuration file.
# Copyright (C) 2010-2017 Chelsio Communications.  All rights reserved.
#   DO NOT MODIFY THIS FILE UNDER ANY CIRCUMSTANCES.  MODIFICATION OF THIS FILE
#   WILL RESULT IN A NON-FUNCTIONAL ADAPTER AND MAY RESULT IN PHYSICAL DAMAGE
#   TO ADAPTERS.
# This file provides the default, power-on configuration for 4-port T5-based
# adapters shipped from the factory.  These defaults are designed to address
# the needs of the vast majority of Terminator customers.  The basic idea is to
# have a default configuration which allows a customer to plug a Terminator
# adapter in and have it work regardless of OS, driver or application except in
# the most unusual and/or demanding customer applications.
# Many of the Terminator resources which are described by this configuration
# are finite.  This requires balancing the configuration/operation needs of
# device drivers across OSes and a large number of customer application.
# Some of the more important resources to allocate and their constaints are:
#  1. Virtual Interfaces: 256.
#  2. Ingress Queues with Free Lists: 1024.
#  3. Egress Queues: 128K.
#  4. MSI-X Vectors: 1088.
#  5. Multi-Port Support (MPS) TCAM: 336 entries to support MAC destination
#     address matching on Ingress Packets.
# Some of the important OS/Driver resource needs are:
#  6. Some OS Drivers will manage all resources through a single Physical
#     Function (currently PF4 but it could be any Physical Function).
#  7. Some OS Drivers will manage different ports and functions (NIC,
#     storage, etc.) on different Physical Functions.  For example, NIC
#     functions for ports 0-3 on PF0-3, FCoE on PF4, iSCSI on PF5, etc.
# Some of the customer application needs which need to be accommodated:
#  8. Some customers will want to support large CPU count systems with
#     good scaling.  Thus, we'll need to accommodate a number of
#     Ingress Queues and MSI-X Vectors to allow up to some number of CPUs
#     to be involved per port and per application function.  For example,
#     in the case where all ports and application functions will be
#     managed via a single Unified PF and we want to accommodate scaling up
#     to 8 CPUs, we would want:
#         4 ports *
#         3 application functions (NIC, FCoE, iSCSI) per port *
#         8 Ingress Queue/MSI-X Vectors per application function
#     for a total of 96 Ingress Queues and MSI-X Vectors on the Unified PF.
#     (Plus a few for Firmware Event Queues, etc.)
#  9. Some customers will want to use PCI-E SR-IOV Capability to allow Virtual
#     Machines to directly access T6 functionality via SR-IOV Virtual Functions
#     and "PCI Device Passthrough" -- this is especially true for the NIC
#     application functionality.
# Global configuration settings.
[global]
rss_glb_config_mode = basicvirtual
rss_glb_config_options = tnlmapen,hashtoeplitz,tnlalllkp
rss_keymode = idxvf_key #Other modes: glb_key, glbvf_key, pfvf_key
# PL_TIMEOUT register
pl_timeout_value = 10000
# the timeout value in units of us
# The following Scatter Gather Engine (SGE) settings assume a 4KB Host
# Page Size and a 64B L1 Cache Line Size. It programs the
# EgrStatusPageSize and IngPadBoundary to 64B and the PktShift to 2.
# If a Master PF Driver finds itself on a machine with different
# parameters, then the Master PF Driver is responsible for initializing
# these parameters to appropriate values.
# Notes:
#  1. The Free List Buffer Sizes below are raw and the firmware will
#     round them up to the Ingress Padding Boundary.
#  2. The SGE Timer Values below are expressed below in microseconds.
#     The firmware will convert these values to Core Clock Ticks when
#     it processes the configuration parameters.
reg[0x1008] = 0x40010/0x21c70
# SGE_CONTROL
reg[0x100c] = 0x22222222
# SGE_HOST_PAGE_SIZE
reg[0x10a0] = 0x01040810
# SGE_INGRESS_RX_THRESHOLD
reg[0x1044] = 4096
# SGE_FL_BUFFER_SIZE0
reg[0x1048] = 65536
# SGE_FL_BUFFER_SIZE1
reg[0x104c] = 1536
# SGE_FL_BUFFER_SIZE2
reg[0x1050] = 9024
# SGE_FL_BUFFER_SIZE3
reg[0x1054] = 9216
# SGE_FL_BUFFER_SIZE4
reg[0x1058] = 2048
# SGE_FL_BUFFER_SIZE5
reg[0x105c] = 128
# SGE_FL_BUFFER_SIZE6
reg[0x1060] = 8192
# SGE_FL_BUFFER_SIZE7
reg[0x1064] = 16384
# SGE_FL_BUFFER_SIZE8
reg[0x10a4] = 0x00280000/0x3ffc0000 # SGE_DBFIFO_STATUS
reg[0x1118] = 0x00002800/0x00003c00 # SGE_DBFIFO_STATUS2
reg[0x10a8] = 0x402000/0x402000
# SGE_DOORBELL_CONTROL
# SGE_THROTTLE_CONTROL
bar2throttlecount = 500
# bar2throttlecount in us
sge_timer_value = 5, 10, 20, 50, 100, 200 # SGE_TIMER_VALUE* in usecs
reg[0x1124] = 0x00000400/0x00000400 # SGE_CONTROL2, enable VFIFO; if
# SGE_VFIFO_SIZE is not set, then
# firmware will set it up in function
# of number of egress queues used
reg[0x1130] = 0x00d5ffeb
# SGE_DBP_FETCH_THRESHOLD, fetch
# threshold set to queue depth
# minus 128-entries for FL and HP
# queues, and 0xfff for LP which
# prompts the firmware to set it up
# in function of egress queues
# used
reg[0x113c] = 0x0002ffc0
# SGE_VFIFO_SIZE, set to 0x2ffc0 which
# prompts the firmware to set it up in
# function of number of egress queues
# used 
# enable TP_OUT_CONFIG.IPIDSPLITMODE
reg[0x7d04] = 0x00010000/0x00010000
# disable TP_PARA_REG3.RxFragEn
reg[0x7d6c] = 0x00000000/0x00007000
# enable TP_PARA_REG6.EnableCSnd
reg[0x7d78] = 0x00000400/0x00000000
# TP_SHIFT_CNT - set SYN shift count to 4 for quicker connect timeouts
reg[0x7dc0] = 0x042f8849
# TP_SHIFT_CNT
# TP_VLAN_PRI_MAP to select filter tuples and enable ServerSram
# filter control: compact, fcoemask
# server sram   : srvrsram
# filter tuples : fragmentation, mpshittype, macmatch, ethertype,
  protocol, tos, vlan, vnic_id, port, fcoe
# valid filterModes are described the Terminator 5 Data Book
filterMode = fcoemask, fragmentation, mpshittype, macmatch, protocol, tos, port, fcoe
# filter tuples enforced in LE active region (equal to or subset of filterMode)
filterMask = protocol, fcoe
# Percentage of dynamic memory (in either the EDRAM or external MEM)
# to use for TP RX payload
tp_pmrx = 20
# TP RX payload page size
tp_pmrx_pagesize = 64K
# TP number of RX channels
tp_nrxch = 0
# 0 (auto) = 1
# Percentage of dynamic memory (in either the EDRAM or external MEM)
# to use for TP TX payload
tp_pmtx = 30
# TP TX payload page size
tp_pmtx_pagesize = 64K
# TP number of TX channels
tp_ntxch = 0
# 0 (auto) = equal number of ports
# TP OFLD MTUs
tp_mtus = 88, 256, 512, 576, 808, 1024, 1280, 1488, 1500, 2002, 2048, 4096, 4352, 8192, 9000, 9600
# TP TCP hardware stack tuning
tp_tcptuning = cluster
# wan, lan or cluster
# TP_GLOBAL_CONFIG
reg[0x7d08] = 0x00000800/0x00000800 # set IssFromCplEnable
# TP_PC_CONFIG
reg[0x7d48] = 0x00000000/0x00000400 # clear EnableFLMError
# TP_PARA_REG0
reg[0x7d60] = 0x06000000/0x07000000 # set InitCWND to 6
# ULPRX iSCSI Page Sizes
reg[0x19168] = 0x04020100 # 64K, 16K, 8K and 4K
# MC configuration
mc_mode_brc[0] = 1
# mc0 - 1: enable BRC, 0: enable RBC
mc_mode_brc[1] = 1
# mc1 - 1: enable BRC, 0: enable RBC
# ULP_TX_CONFIG
reg[0x8dc0] = 0x00000004/0x00000004 # Enable more error msg for ...
    # TPT error.
# Some "definitions" to make the rest of this a bit more readable.  We support
# 4 ports, 3 functions (NIC, FCoE and iSCSI), scaling up to 8 "CPU Queue Sets"
# per function per port ...
# NMSIX = 1088
# available MSI-X Vectors
# NVI = 128
# available Virtual Interfaces
# NMPSTCAM = 336
# MPS TCAM entries
# NPORTS = 4
# ports
# NCPUS = 8
# CPUs we want to support scalably
# NFUNCS = 3
# functions per port (NIC, FCoE, iSCSI)
# RSSNSECRET = 16
# available 320b entries in rss secret table
# Breakdown of Virtual Interface/Queue/Interrupt resources for the "Unified
# PF" which many OS Drivers will use to manage most or all functions.
# Each Ingress Queue can use one MSI-X interrupt but some Ingress Queues can
# use Forwarded Interrupt Ingress Queues.  For these latter, an Ingress Queue
# would be created and the Queue ID of a Forwarded Interrupt Ingress Queue
# will be specified as the "Ingress Queue Asynchronous Destination Index."
# Thus, the number of MSI-X Vectors assigned to the Unified PF will be less
# than or equal to the number of Ingress Queues ...
# NVI_NIC = 4
# NIC access to NPORTS
# NFLIQ_NIC = 32
# NIC Ingress Queues with Free Lists
# NETHCTRL_NIC = 32
# NIC Ethernet Control/TX Queues
# NEQ_NIC = 64
# NIC Egress Queues (FL, ETHCTRL/TX)
# NMPSTCAM_NIC = 16
# NIC MPS TCAM Entries (NPORTS*4)
# NMSIX_NIC = 32
# NIC MSI-X Interrupt Vectors (FLIQ)
# NVI_OFLD = 0
# Offload uses NIC function to access ports
# NFLIQ_OFLD = 16
# Offload Ingress Queues with Free Lists
# NETHCTRL_OFLD = 0
# Offload Ethernet Control/TX Queues
# NEQ_OFLD = 16
# Offload Egress Queues (FL)
# NMPSTCAM_OFLD = 0
# Offload MPS TCAM Entries (uses NIC's)
# NMSIX_OFLD = 16
# Offload MSI-X Interrupt Vectors (FLIQ)
# NVI_RDMA = 0
# RDMA uses NIC function to access ports
# NFLIQ_RDMA = 4
# RDMA Ingress Queues with Free Lists
# NETHCTRL_RDMA = 0
# RDMA Ethernet Control/TX Queues
# NEQ_RDMA = 4
# RDMA Egress Queues (FL)
# NMPSTCAM_RDMA = 0
# RDMA MPS TCAM Entries (uses NIC's)
# NMSIX_RDMA = 4
# RDMA MSI-X Interrupt Vectors (FLIQ)
# NEQ_WD = 128
# Wire Direct TX Queues and FLs
# NETHCTRL_WD = 64
# Wire Direct TX Queues
# NFLIQ_WD = 64
# Wire Direct Ingress Queues with Free Lists
# NVI_ISCSI = 4
# ISCSI access to NPORTS
# NFLIQ_ISCSI = 4
# ISCSI Ingress Queues with Free Lists
# NETHCTRL_ISCSI = 0
# ISCSI Ethernet Control/TX Queues
# NEQ_ISCSI = 4
# ISCSI Egress Queues (FL)
# NMPSTCAM_ISCSI = 4
# ISCSI MPS TCAM Entries (NPORTS)
# NMSIX_ISCSI = 4
# ISCSI MSI-X Interrupt Vectors (FLIQ)
# NVI_FCOE = 4
# FCOE access to NPORTS
# NFLIQ_FCOE = 34
# FCOE Ingress Queues with Free Lists
# NETHCTRL_FCOE = 32
# FCOE Ethernet Control/TX Queues
# NEQ_FCOE = 66
# FCOE Egress Queues (FL)
# NMPSTCAM_FCOE = 32 
# FCOE MPS TCAM Entries (NPORTS)
# NMSIX_FCOE = 34
# FCOE MSI-X Interrupt Vectors (FLIQ)
# Two extra Ingress Queues per function for Firmware Events and Forwarded
# Interrupts, and two extra interrupts per function for Firmware Events (or a
# Forwarded Interrupt Queue) and General Interrupts per function.
# NFLIQ_EXTRA = 6
# "extra" Ingress Queues 2*NFUNCS (Firmware and
#   Forwarded Interrupts
# NMSIX_EXTRA = 6
# extra interrupts 2*NFUNCS (Firmware and
#   General Interrupts
# Microsoft HyperV resources.  The HyperV Virtual Ingress Queues will have
# their interrupts forwarded to another set of Forwarded Interrupt Queues.
# NVI_HYPERV = 16
# VMs we want to support
# NVIIQ_HYPERV = 2
# Virtual Ingress Queues with Free Lists per VM
# NFLIQ_HYPERV = 40
# VIQs + NCPUS Forwarded Interrupt Queues
# NEQ_HYPERV = 32
# VIQs Free Lists
# NMPSTCAM_HYPERV = 16
# MPS TCAM Entries (NVI_HYPERV)
# NMSIX_HYPERV = 8
# NCPUS Forwarded Interrupt Queues
# Adding all of the above Unified PF resource needs together: (NIC + OFLD +
# RDMA + ISCSI + FCOE + EXTRA + HYPERV)
# NVI_UNIFIED = 28
# NFLIQ_UNIFIED = 106
# NETHCTRL_UNIFIED = 32
# NEQ_UNIFIED = 124
# NMPSTCAM_UNIFIED = 40
# The sum of all the MSI-X resources above is 74 MSI-X Vectors but we'll round
# that up to 128 to make sure the Unified PF doesn't run out of resources.
# NMSIX_UNIFIED = 128
# The Storage PFs could need up to NPORTS*NCPUS + NMSIX_EXTRA MSI-X Vectors
# which is 34 but they're probably safe with 32.
# NMSIX_STORAGE = 32
# Note: The UnifiedPF is PF4 which doesn't have any Virtual Functions
# associated with it.  Thus, the MSI-X Vector allocations we give to the
# UnifiedPF aren't inherited by any Virtual Functions.  As a result we can
# provision many more Virtual Functions than we can if the UnifiedPF were
# one of PF0-3.
# All of the below PCI-E parameters are actually stored in various *_init.txt
# files.  We include them below essentially as comments.
# For PF0-3 we assign 8 vectors each for NIC Ingress Queues of the associated
# ports 0-3.
# For PF4, the Unified PF, we give it an MSI-X Table Size as outlined above.
# For PF5-6 we assign enough MSI-X Vectors to support FCoE and iSCSI
# storage applications across all four possible ports.
# Additionally, since the UnifiedPF isn't one of the per-port Physical
# Functions, we give the UnifiedPF and the PF0-3 Physical Functions
# different PCI Device IDs which will allow Unified and Per-Port Drivers
# to directly select the type of Physical Function to which they wish to be
# attached.
# Note that the actual values used for the PCI-E Intelectual Property will be
# 1 less than those below since that's the way it "counts" things.  For
# readability, we use the number we actually mean ...
# PF0_INT = 8
# NCPUS
# PF1_INT = 8
# NCPUS
# PF2_INT = 8
# NCPUS
# PF3_INT = 8
# NCPUS
# PF0_3_INT = 32
# PF0_INT + PF1_INT + PF2_INT + PF3_INT
# PF4_INT = 128
# NMSIX_UNIFIED
# PF5_INT = 32
# NMSIX_STORAGE
# PF6_INT = 32
# NMSIX_STORAGE
# PF7_INT = 0
# Nothing Assigned
# PF4_7_INT = 192
# PF4_INT + PF5_INT + PF6_INT + PF7_INT
# PF0_7_INT = 224
# PF0_3_INT + PF4_7_INT
# With the above we can get 17 VFs/PF0-3 (limited by 336 MPS TCAM entries)
# but we'll lower that to 16 to make our total 64 and a nice power of 2 ...
# NVF = 16
# Some OS Drivers manage all application functions for all ports via PF4.
# Thus we need to provide a large number of resources here.  For Egress
# Queues we need to account for both TX Queues as well as Free List Queues
# (because the host is responsible for producing Free List Buffers for the
# hardware to consume).
[function "4"]
wx_caps = all
# write/execute permissions for all commands
r_caps = all
# read permissions for all commands
nvi = 34
# NVI_UNIFIED
rssnsecret = 16
# all 16 table entries to PF 4
rssnvi = 32
niqflint = 170
# NFLIQ_UNIFIED + NLFIQ_WD
nethctrl = 100
# NETHCTRL_UNIFIED + NETHCTRL_WD
neq = 256
# NEQ_UNIFIED + NEQ_WD
nexactf = 128
# NMPSTCAM_UNIFIED
nqpcq = 12288 
cmask = all
# access to all channels
pmask = all
# access to all four ports ...
nclip = 32
# number of clip region entries
nfilter = 368
# number of filter region entries
nserver = 128
# number of server region entries
nhash = 14336
# number of hash region entries
protocol = nic_vm, ofld, rddp, rdmac, iscsi_initiator_pdu
tp_l2t = 4096
tp_ddp = 1
tp_ddp_iscsi = 1
tp_stag = 5 
tp_pbl = 34 
tp_rq = 10
[function "6"]
wx_caps = all
# write/execute permissions for all commands
r_caps = all
# read permissions for all commands
nvi = 4
# NPORTS
niqflint = 34
# NPORTS*NCPUS + NMSIX_EXTRA
nethctrl = 32
# NPORTS*NCPUS
neq = 66
# NPORTS*NCPUS * 2 (FL, ETHCTRL/TX) + 2 (EXTRA)
nexactf = 32
# NPORTS + adding 28 exact entries for FCoE
# which is OK since < MIN(SUM PF0..3, PF4)
# and we never load PF0..3 and PF4 concurrently
cmask = all
# access to all channels
pmask = all
# access to all four ports ...
nhash = 2048
tp_l2t = 4
protocol = fcoe_initiator
tp_ddp = 2
fcoe_nfcf = 16
fcoe_nvnp = 32
fcoe_nssn = 1024
# The following function, 1023, is not an actual PCIE function but is used to
# configure and reserve firmware internal resources that come from the global
# resource pool.
[function "1023"]
wx_caps = all
# write/execute permissions for all commands
r_caps = all
# read permissions for all commands
nvi = 4
# NVI_UNIFIED
cmask = all
# access to all channels
pmask = all
# access to all four ports ...
nexactf = 8
# NPORTS + DCBX +
nfilter = 16
# number of filter region entries
# For Virtual functions, we only allow NIC functionality and we only allow
# access to one port (1 << PF).  Note that because of limitations in the
# Scatter Gather Engine (SGE) hardware which checks writes to VF KDOORBELL
# and GTS registers, the number of Ingress and Egress Queues must be a power
# of 2.
[function "0/*"]
# NVF
nvi = 1
# 1 port
rssnvi = 0
[function "1/*"]
# NVF
nvi = 1
# 1 port
rssnvi = 0
[function "2/*"]
# NVF
nvi = 1
# 1 port
rssnvi = 0
[function "3/*"]
# NVF
nvi = 1
# 1 port
rssnvi = 0
[function "4/*"]
# NVF
wx_caps = 0x82
# DMAQ | VF
r_caps = 0x86
# DMAQ | VF | PORT
nvi = 1
# 1 port
rssnvi = 1
niqflint = 11
# 8 "Queue Sets" + CIQ + FWEVTQ + FWDINTRQ 
nethctrl = 8
# 8 "Queue Sets"
neq = 16
# 8 "Queue Sets" * 2
nexactf = 4
cmask = all
# access to all channels
pmask = all 
# access to all ports
nqpcq = 78
protocol = ofld, rdmac
# MPS features a 196608 bytes ingress buffer that is used for ingress buffering
# for packets from the wire as well as the loopback path of the L2 switch. The
# folling params control how the buffer memory is distributed and the L2 flow
# control settings:
# bg_mem:
%-age of mem to use for port/buffer group
# lpbk_mem:
%-age of port/bg mem to use for loopback
# hwm:
high watermark; bytes available when starting to send pause
frames (in units of 0.1 MTU)
# lwm:
low watermark; bytes remaining when sending 'unpause' frame
(in inuits of 0.1 MTU)
# dwm:
minimum delta between high and low watermark (in units of 100
Bytes)
[port "0"]
dcb = ppp, dcbx
# configure for DCB PPP and enable DCBX offload
dcb_dcbx_protocol = auto
bg_mem = 25
lpbk_mem = 25 
hwm = 30
lwm = 15
dwm = 30
dcb_app_tlv[0] = 0x8906, ethertype, 3
dcb_app_tlv[1] = 0x8914, ethertype, 3
dcb_app_tlv[2] = 3260, socketnum, 5
[port "1"]
dcb = ppp, dcbx
dcb_dcbx_protocol = auto
bg_mem = 25
lpbk_mem = 25
hwm = 30
lwm = 15
dwm = 30
dcb_app_tlv[0] = 0x8906, ethertype, 3
dcb_app_tlv[1] = 0x8914, ethertype, 3
dcb_app_tlv[2] = 3260, socketnum, 5
[port "2"]
dcb = ppp, dcbx
dcb_dcbx_protocol = auto
bg_mem = 25
lpbk_mem = 25
hwm = 30
lwm = 15
dwm = 30
dcb_app_tlv[0] = 0x8906, ethertype, 3
dcb_app_tlv[1] = 0x8914, ethertype, 3
dcb_app_tlv[2] = 3260, socketnum, 5
[port "3"]
dcb = ppp, dcbx
dcb_dcbx_protocol = auto
bg_mem = 25
lpbk_mem = 25
hwm = 30
lwm = 15
dwm = 30
dcb_app_tlv[0] = 0x8906, ethertype, 3
dcb_app_tlv[1] = 0x8914, ethertype, 3
dcb_app_tlv[2] = 3260, socketnum, 5
[fini]
version = 0x08000025
checksum = 0xd24280b8
# Total resources used by above allocations:
#   Virtual Interfaces: 104
#   Ingress Queues/w Free Lists and Interrupts: 526
#   Egress Queues: 702
#   MPS TCAM Entries: 336
#   MSI-X Vectors: 736
#   Virtual Functions: 64
StorPortInitialize
StorPortGetPhysicalAddress
StorPortGetUncachedExtension
StorPortNotification
storport.sys
DbgPrint
KeStallExecutionProcessor
KeQueryTimeIncrement
_vsnprintf
ntoskrnl.exe
HAL.DLL
memcpy_s
strcmp
StorPortGetBusData
StorPortSetBusDataByOffset
isspace
ExAllocatePoolWithTag
ExFreePoolWithTag
VS_VERSION_INFO
StringFileInfo
040904B0
CompanyName
Chelsio Communications
FileDescription
Chelsio iSCSI Crash Dump Driver
FileVersion
6.11.4.100
InternalName
cht4dx64.sys
LegalCopyright
Copyright 
 2016 Chelsio Communications. All rights reserved.
OriginalFilename
cht4dx64.sys
ProductName
Chelsio Communications iSCSI Crash Dump Driver
ProductVersion
10.0.10011.16384
VarFileInfo
Translation
Washington1
Redmond1
Microsoft Corporation1.0,
%Microsoft Windows Production PCA 20110
210902182341Z
220901182341Z0p1
Washington1
Redmond1
Microsoft Corporation1
Microsoft Windows0
2y80T
I0G1-0+
$Microsoft Ireland Operations Limited1
229879+4675800
M0K0I
Chttp://www.microsoft.com/pkiops/crl/MicWinProPCA2011_2011-10-19.crl0a
U0S0Q
Ehttp://www.microsoft.com/pkiops/certs/MicWinProPCA2011_2011-10-19.crt0
Et,@8
Zof1G
WaNja
T^r|B
uOi@Y
Washington1
Redmond1
Microsoft Corporation1200
)Microsoft Root Certificate Authority 20100
111019184142Z
261019185142Z0
Washington1
Redmond1
Microsoft Corporation1.0,
%Microsoft Windows Production PCA 20110
O0M0K
Ehttp://crl.microsoft.com/pki/crl/products/MicRooCerAut_2010-06-23.crl0Z
N0L0J
>http://www.microsoft.com/pki/certs/MicRooCerAut_2010-06-23.crt0
TlP0X
R!s4Z
Washington1
Redmond1
Microsoft Corporation1.0,
%Microsoft Windows Production PCA 2011
,742bF0ApoWufaKALDYCqQhoYygmkA4TKjLM23FneOQU=0Z
"Microsoft Window
 http://www.microsoft.com/windows0
ywh^2
FiNM$
f+B L
20220507033113.338Z0
Washington1
Redmond1
Microsoft Corporation1-0+
$Microsoft Ireland Operations Limited1&0$
Thales TSS ESN:2AD4-4B92-FA011%0#
Microsoft Time-Stamp Service
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 20100
211028192739Z
230126192739Z0
Washington1
Redmond1
Microsoft Corporation1-0+
$Microsoft Ireland Operations Limited1&0$
Thales TSS ESN:2AD4-4B92-FA011%0#
Microsoft Time-Stamp Service0
6z$WD
IsK6*
L8zp0
X0V0T
Nhttp://www.microsoft.com/pkiops/crl/Microsoft%20Time-Stamp%20PCA%202010(1).crl0l
`0^0\
Phttp://www.microsoft.com/pkiops/certs/Microsoft%20Time-Stamp%20PCA%202010(1).crt0
vFfl|
n{(aM0
"c}FK
^?H4"
g;^z 
Washington1
Redmond1
Microsoft Corporation1200
)Microsoft Root Certificate Authority 20100
210930182225Z
300930183225Z0|1
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 20100
q\Q17
&S|9a
!]_0t
U0S0Q
3http://www.microsoft.com/pkiops/Docs/Repository.htm0
O0M0K
Ehttp://crl.microsoft.com/pki/crl/products/MicRooCerAut_2010-06-23.crl0Z
N0L0J
>http://www.microsoft.com/pki/certs/MicRooCerAut_2010-06-23.crt0
>NGdx
fg:SM
xSu$W
as.,k{n?,
J>f;O
!TkjE
Washington1
Redmond1
Microsoft Corporation1-0+
$Microsoft Ireland Operations Limited1&0$
Thales TSS ESN:2AD4-4B92-FA011%0#
Microsoft Time-Stamp Service
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 20100
20220507035814Z
20220508035814Z0t0:
1,0*0
1(0&0
Wc6H%`
*BBdsa$
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 2010
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 2010
ReEHx1[
Ru"7'
